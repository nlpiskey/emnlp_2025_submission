{"id":0,"text":"In this paper, we combine discrete empirical interpolation techniques, global\nmode decomposition methods, and local multiscale methods, such as the\nGeneralized Multiscale Finite Element Method (GMsFEM), to reduce the\ncomputational complexity associated with nonlinear flows in\nhighly-heterogeneous porous media. To solve the nonlinear governing equations,\nwe employ the GMsFEM to represent the solution on a coarse grid with multiscale\nbasis functions and apply proper orthogonal decomposition on a coarse grid. Computing the GMsFEM solution involves calculating the residual and the\nJacobian on the fine grid. As such, we use local and global empirical\ninterpolation concepts to circumvent performing these computations on the fine\ngrid. The resulting reduced-order approach enables a significant reduction in\nthe flow problem size while accurately capturing the behavior of fully-resolved\nsolutions. We consider several numerical examples of nonlinear multiscale\npartial differential equations that are numerically integrated using\nfully-implicit time marching schemes to demonstrate the capability of the\nproposed model reduction approach to speed up simulations of nonlinear flows in\nhigh-contrast porous media.","label":"human"}
{"id":1,"text":"In this study, we introduce progressively diffused networks (PDNs) for semantic image segmentation. The proposed PDN architecture utilizes multiple encoder-decoder branches with corresponding pooling and upsampling operations to generate increasingly complex high-level representations of input images. Each branch has a unique feature extraction mechanism that captures different types of semantic information about the image content. By fusing these multiple features at intermediate stages, our method effectively integrates multi-scale contextual and local cues to enhance the accuracy and robustness of image segmentation results. Extensive experiments on various benchmark datasets show that our technique achieves state-of-the-art performance, surpassing previous methods based on traditional convolutional neural network architectures.","label":"ai"}
{"id":2,"text":"What did it feel like to walk through a city from the past? In this work, we\ndescribe Nostalgin (Nostalgia Engine), a method that can faithfully reconstruct\ncities from historical images. Unlike existing work in city reconstruction, we\nfocus on the task of reconstructing 3D cities from historical images. Working\nwith historical image data is substantially more difficult, as there are\nsignificantly fewer buildings available and the details of the camera\nparameters which captured the images are unknown. Nostalgin can generate a city\nmodel even if there is only a single image per facade, regardless of viewpoint\nor occlusions. To achieve this, our novel architecture combines image\nsegmentation, rectification, and inpainting. We motivate our design decisions\nwith experimental analysis of individual components of our pipeline, and show\nthat we can improve on baselines in both speed and visual realism. We\ndemonstrate the efficacy of our pipeline by recreating two 1940s Manhattan city\nblocks. We aim to deploy Nostalgin as an open source platform where users can\ngenerate immersive historical experiences from their own photos.","label":"human"}
{"id":3,"text":"Recent advances in semantic image segmentation have mostly been achieved by\ntraining deep convolutional neural networks (CNNs). We show how to improve\nsemantic segmentation through the use of contextual information; specifically,\nwe explore `patch-patch' context between image regions, and `patch-background'\ncontext. For learning from the patch-patch context, we formulate Conditional\nRandom Fields (CRFs) with CNN-based pairwise potential functions to capture\nsemantic correlations between neighboring patches. Efficient piecewise training\nof the proposed deep structured model is then applied to avoid repeated\nexpensive CRF inference for back propagation. For capturing the\npatch-background context, we show that a network design with traditional\nmulti-scale image input and sliding pyramid pooling is effective for improving\nperformance. Our experimental results set new state-of-the-art performance on a\nnumber of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC\n2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an\nintersection-over-union score of 78.0 on the challenging PASCAL VOC 2012\ndataset.","label":"human"}
{"id":4,"text":"The field of biomedical image segmentation has seen significant advancements in recent years, with deep learning techniques playing a crucial role. However, these methods often require large amounts of computational resources and time to train, which can be limiting in real-world applications. In this study, we propose CFPNet-M, a lightweight encoder-decoder based network that is specifically designed for multimodal biomedical image real-time segmentation. Our approach utilizes convolutional filters that are optimized for medical images, as well as an efficient decoding mechanism that allows for fast processing times. We demonstrate the effectiveness of our method on several benchmark datasets, achieving state-of-the-art performance while significantly reducing training time compared to other deep learning models. Overall, CFPNet-M represents a promising step towards developing practical solutions for real-time biomedical image segmentation tasks.","label":"ai"}
{"id":5,"text":"In this paper we develop a family of preconditioners for the linear algebraic\nsystems arising from the arbitrary Lagrangian-Eulerian discretization of some\nfluid-structure interaction models. After the time discretization, we formulate\nthe fluid-structure interaction equations as saddle point problems and prove\nthe uniform well-posedness. Then we discretize the space dimension by finite\nelement methods and prove their uniform well-posedness by two different\napproaches under appropriate assumptions. The uniform well-posedness makes it\npossible to design robust preconditioners for the discretized fluid-structure\ninteraction systems. Numerical examples are presented to show the robustness\nand efficiency of these preconditioners.","label":"human"}
{"id":6,"text":"The splitting processes of bremsstrahlung and pair production in a medium are\ncoherent over large distances in the very high energy limit, which leads to a\nsuppression known as the Landau-Pomeranchuk-Migdal (LPM) effect. In this paper,\nwe continue analysis of the case when the coherence lengths of two consecutive\nsplitting processes overlap (which is important for understanding corrections\nto standard treatments of the LPM effect in QCD), avoiding soft-gluon\napproximations. In particular, this paper analyzes the subtle problem of how to\nprecisely separate overlapping double splitting (e.g.\\ overlapping double\nbremsstrahlung) from the case of consecutive, independent bremsstrahlung (which\nis the case that would be implemented in a Monte Carlo simulation based solely\non single splitting rates). As an example of the method, we consider the rate\nof real double gluon bremsstrahlung from an initial gluon with various\nsimplifying assumptions (thick media; $\\hat q$ approximation; large $N_c$; and\nneglect for the moment of processes involving 4-gluon vertices) and explicitly\ncompute the correction $\\Delta\\,d\\Gamma\/dx\\,dy$ due to overlapping formation\ntimes.","label":"human"}
{"id":7,"text":"Image reconstruction using deep learning is a rapidly advancing field that involves using artificial neural networks to restore images from degraded or incomplete data. This approach has shown great promise in a variety of applications, including medical imaging, satellite imagery, and facial recognition. In this paper, we review the state-of-the-art in deep learning techniques for image reconstruction, and discuss the challenges and future directions in this area of research. We examine the latest advances in convolutional neural networks, generative adversarial networks, and other deep learning techniques for image reconstruction, and provide an overview of their applications and performance. Finally, we discuss the challenges and limitations of these methods, and highlight areas for future research, including improving the robustness and accuracy of deep learning models for image reconstruction.","label":"ai"}
{"id":8,"text":"In this paper, we review and extend a family of log-det divergences for\nsymmetric positive definite (SPD) matrices and discuss their fundamental\nproperties. We show how to generate from parameterized Alpha-Beta (AB) and\nGamma Log-det divergences many well known divergences, for example, the Stein's\nloss, S-divergence, called also Jensen-Bregman LogDet (JBLD) divergence, the\nLogdet Zero (Bhattacharryya) divergence, Affine Invariant Riemannian Metric\n(AIRM) as well as some new divergences. Moreover, we establish links and\ncorrespondences among many log-det divergences and display them on alpha-beta\nplain for various set of parameters. Furthermore, this paper bridges these\ndivergences and shows also their links to divergences of multivariate and\nmultiway Gaussian distributions. Closed form formulas are derived for gamma\ndivergences of two multivariate Gaussian densities including as special cases\nthe Kullback-Leibler, Bhattacharryya, R\\'enyi and Cauchy-Schwartz divergences. Symmetrized versions of the log-det divergences are also discussed and\nreviewed. A class of divergences is extended to multiway divergences for\nseparable covariance (precision) matrices.","label":"human"}
{"id":9,"text":"We consider an ordinary differential equation with a unique hyperbolic\nattractor at the origin, to which we add a small random perturbation. It is\nknown that under general conditions, the solution of this stochastic\ndifferential equation converges exponentially fast to an equilibrium\ndistribution. We show that the convergence occurs abruptly: in a time window of\nsmall size compared to the natural time scale of the process, the distance to\nequilibrium drops from its maximal possible value to near zero, and only after\nthis time window the convergence is exponentially fast. This is what is known\nas the cut-off phenomenon in the context of Markov chains of increasing\ncomplexity. In addition, we are able to give general conditions to decide\nwhether the distance to equilibrium converges in this time window to a\nuniversal function, a fact known as profile cut-off.","label":"human"}
{"id":10,"text":"> Dental biofilm is a complex microbial community that is associated with the development of dental caries and periodontal disease. The quantification of dental biofilm is a challenging task due to the heterogeneity of the microbial community and the difficulty in obtaining representative samples. In this paper, we propose a statistical modeling approach to computer-aided quantification of dental biofilm. The approach involves the use of machine learning algorithms to identify and quantify the microbial species present in the biofilm. The results of the study show that the proposed approach is able to accurately quantify the microbial species present in the biofilm. The approach has the potential to be used as a tool for the diagnosis and treatment of dental diseases. The following is the full text of the abstract for a research paper titled \"A Statistical Modeling Approach to Computer-Aided Quantification of Dental Biofilm\" from arxiv.org:\n> Dental biofilm is a complex microbial community that is associated with the development of dental caries and periodontal disease. The quantification of dental biofilm is a challenging task due to the heterogeneity of the microbial community and the difficulty in obtaining representative samples. In this paper, we propose a statistical modeling approach to computer-aided quantification of dental biofilm. The approach involves the use of machine learning algorithms to identify and quantify the microbial species present in the biofilm. The results of the study show that the proposed approach is able to accurately quantify the microbial species present in the biofilm. The approach has the potential to be used as a tool for the diagnosis and treatment of dental diseases. The following is the full text of the abstract for a research paper titled \"A Statistical Modeling Approach to Computer-Aided Quantification of Dental Biofilm\" from arxiv.org:\n> Dental biofilm is a complex microbial community that is associated with the development of dental caries and periodontal disease. The quantification of dental biofilm is a challenging task due to the heterogeneity of the microbial community and the difficulty in obtaining representative samples. In this paper, we propose a","label":"ai"}
{"id":11,"text":"Advances in reflectarrays and array lenses with electronic beam-forming\ncapabilities are enabling a host of new possibilities for these\nhigh-performance, low-cost antenna architectures. This paper reviews enabling\ntechnologies and topologies of reconfigurable reflectarray and array lens\ndesigns, and surveys a range of experimental implementations and achievements\nthat have been made in this area in recent years. The paper describes the\nfundamental design approaches employed in realizing reconfigurable designs, and\nexplores advanced capabilities of these nascent architectures, such as\nmulti-band operation, polarization manipulation, frequency agility, and\namplification. Finally, the paper concludes by discussing future challenges and\npossibilities for these antennas.","label":"human"}
{"id":12,"text":"The aim of this study is to investigate the impact of cataracts on iris recognition performance. To do so, a comprehensive review of previously published studies was conducted, and relevant experimental data were analyzed. Results showed that there was a clear decrease in accuracy when comparing iris images with or without cataracts. Several factors were found to affect the reduction in performance, including the type and degree of cataract, as well as the quality of pre-operative imaging and post-operative surgical techniques. Additionally, machine learning algorithms appeared to be more effective than traditional methods in detecting changes caused by cataracts. Overall, these findings suggest that careful consideration should be given to patients' ocular status prior to iris recognition procedures to minimize potential errors caused by cataracts.","label":"ai"}
{"id":13,"text":"Random fields have remained a topic of great interest over past decades for\nthe purpose of structured inference, especially for problems such as image\nsegmentation. The local nodal interactions commonly used in such models often\nsuffer the short-boundary bias problem, which are tackled primarily through the\nincorporation of long-range nodal interactions. However, the issue of\ncomputational tractability becomes a significant issue when incorporating such\nlong-range nodal interactions, particularly when a large number of long-range\nnodal interactions (e.g., fully-connected random fields) are modeled. In this work, we introduce a generalized random field framework based around\nthe concept of stochastic cliques, which addresses the issue of computational\ntractability when using fully-connected random fields by stochastically forming\na sparse representation of the random field. The proposed framework allows for\nefficient structured inference using fully-connected random fields without any\nrestrictions on the potential functions that can be utilized. Several\nrealizations of the proposed framework using graph cuts are presented and\nevaluated, and experimental results demonstrate that the proposed framework can\nprovide competitive performance for the purpose of image segmentation when\ncompared to existing fully-connected and principled deep random field\nframeworks.","label":"human"}
{"id":14,"text":"The paper \"Domination parameters with number 2: interrelations and algorithmic consequences\" presents a study on the domination parameters of graphs with number 2. The domination parameters are a set of graph parameters that describe the degree of domination in a graph, and they are used to analyze the structure and behavior of graphs. In this paper, we focus on the domination parameters with number 2, which are the domination number, the domination index, and the domination dimension. We investigate the interrelations between these parameters and their algorithmic consequences. We show that the domination number and the domination index are closely related, and we provide an algorithm to compute the domination index in terms of the domination number. We also show that the domination dimension is related to the domination number and the domination index, and we provide an algorithm to compute the domination dimension in terms of the domination number and the domination index. Finally, we discuss the algorithmic consequences of these relationships, and we show how they can be used to improve the efficiency of algorithms for computing the domination parameters.","label":"ai"}
{"id":15,"text":"We study the dynamics of the Warsaw Stock Exchange (WSE) by means of the\ncorrelation dimension, which measures the complexity of the system's\nattractor in phase space. We find that this quantity exhibits two abrupt\nchanges as a function of time, indicating the occurrence of two distinct\ndynamical regimes. These are interpreted as corresponding to different\nphases of the market activity. In particular, we identify one regime with\nhigh volatility and low liquidity, while the other corresponds to lower\nvolatility and higher liquidity. This interpretation is supported by an\nanalysis of the order book data, where we observe that the number of orders\nincreases during the first transition, whereas it decreases after the second\none. Moreover, we show that these transitions can be predicted using a simple\nmodel based on the concept of critical slowing down. Our results suggest\nthat the WSE undergoes dynamic structural and topological phase transitions,\nproviding new insights into the complex behavior of financial markets.","label":"ai"}
{"id":16,"text":"The automatic segmentation of porous media is a crucial task in various fields such as geology, materials science, and biomedical imaging. However, traditional methods often struggle to accurately capture the complex structures and irregularities present in these images. In this study, we propose a novel approach based on 3D quantum cuts that can effectively segment porous media from tomography images. Our method utilizes a combination of statistical analysis and machine learning techniques to identify and separate the porous regions from the surrounding matrix. We demonstrate our approach using synthetic and real-world examples, showing significant improvements over existing methods in terms of accuracy and efficiency. Overall, our work represents an important step towards developing robust and reliable tools for the automated analysis of porous media in tomographic data.","label":"ai"}
{"id":17,"text":"The paper presents efficient approximation algorithms for multicell coordinated beamforming with rate outage constraint. The problem is formulated as a non-convex optimization problem with multiple objectives, which is difficult to solve. The paper proposes a novel approach based on the concept of rate outage constraint, which is a key factor in the design of wireless communication systems. The proposed algorithm uses a combination of linear programming and convex optimization techniques to find an approximate solution that satisfies the rate outage constraint. The paper also presents a simulation study to evaluate the performance of the proposed algorithm and compares it with other state-of-the-art methods. The results show that the proposed algorithm outperforms other methods in terms of both rate and outage performance.","label":"ai"}
{"id":18,"text":"Coherence is a crucial requirement to realize quantum manipulation through\nlight-matter interactions. Here we report the observation of anomalously robust\nvalley polarization and valley coherence in bilayer WS2. The polarization of\nthe photoluminescence from bilayer WS2 inherits that of the excitation source\nwith both circularly and linearly polarized and retains even at room\ntemperature. The near unity circular polarization of the luminescence reveals\nthe coupling of spin, layer and valley degree of freedom in bilayer system,\nwhile the linear polarized photoluminescence manifests quantum coherence\nbetween the two inequivalent band extrema in momentum space, namely, the valley\nquantum coherence in atomically thin bilayer WS2. This observation opens new\nperspectives for quantum manipulation in atomically thin semiconductors.","label":"human"}
{"id":19,"text":"Medical image segmentation is a crucial task in the field of radiology, which involves identifying and separating specific regions of interest within an image. However, traditional methods often struggle to accurately segment images from different domains, such as those obtained from different types of medical imaging devices or for different diseases. In this paper, we propose a novel approach to domain adaptive medical image segmentation using adversarial learning of disease-specific spatial patterns. Our method involves training a deep neural network to learn the spatial patterns specific to a particular disease, and then using this learned model to segment images from different domains. We demonstrate the effectiveness of our approach on several benchmark datasets, and show that our method outperforms traditional methods in terms of accuracy and robustness. Our work has important implications for improving the accuracy and efficiency of medical image analysis, and has the potential to revolutionize the field of radiology.","label":"ai"}
{"id":20,"text":"Medical image segmentation is a crucial task in various clinical applications, including diagnosis and treatment planning. However, uncertainty quantification (UQ) of segmented images remains challenging due to several factors such as inter-rater variability, noise, and complex anatomical structures. In this study, we propose a novel UQ framework based on normalizing flows that can handle these challenges effectively. Our approach involves training a generative model using normalizing flows to generate synthetic samples from the original data distribution. We then use these samples to estimate the uncertainty of the segmentation results by calculating the variance of the predicted labels across different samples. The proposed method was evaluated on two publicly available datasets, demonstrating significant improvements over state-of-the-art methods in terms of both accuracy and robustness. Overall, our work provides a valuable tool for improving the reliability and interpretability of medical image segmentations.","label":"ai"}
{"id":21,"text":"Recently, Neural Architecture Search (NAS) has successfully identified neural\nnetwork architectures that exceed human designed ones on large-scale image\nclassification. In this paper, we study NAS for semantic image segmentation. Existing works often focus on searching the repeatable cell structure, while\nhand-designing the outer network structure that controls the spatial resolution\nchanges. This choice simplifies the search space, but becomes increasingly\nproblematic for dense image prediction which exhibits a lot more network level\narchitectural variations. Therefore, we propose to search the network level\nstructure in addition to the cell level structure, which forms a hierarchical\narchitecture search space. We present a network level search space that\nincludes many popular designs, and develop a formulation that allows efficient\ngradient-based architecture search (3 P100 GPU days on Cityscapes images). We\ndemonstrate the effectiveness of the proposed method on the challenging\nCityscapes, PASCAL VOC 2012, and ADE20K datasets. Auto-DeepLab, our\narchitecture searched specifically for semantic image segmentation, attains\nstate-of-the-art performance without any ImageNet pretraining.","label":"human"}
{"id":22,"text":"> We study the phase diagram of the spin-3\/2 Blume-Emery-Griffiths model on a honeycomb lattice using Monte Carlo simulations. > We find that the model has a first-order phase transition between the ferromagnetic and paramagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a second-order phase transition between the antiferromagnetic and paramagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a first-order phase transition between the antiferromagnetic and ferromagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a second-order phase transition between the paramagnetic and antiferromagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a first-order phase transition between the paramagnetic and ferromagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a second-order phase transition between the ferromagnetic and antiferromagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and the critical exponent beta = 0.32(1). > We also find that the model has a first-order phase transition between the antiferromagnetic and paramagnetic phases. > The critical temperature is found to be Tc = 0.435(1) and","label":"ai"}
{"id":23,"text":"Aperture synthesis techniques are increasingly being employed to provide high\nangular resolution images in situations where the object of interest is in the\nnear field of the interferometric array. Previous work has showed that an\naperture synthesis array can be refocused on an object in the near field of an\narray, provided that the object is smaller than the effective Fresnel zone size\ncorresponding to the array-object range. We show here that, under paraxial\nconditions, standard interferometric techniques can be used to image objects\nwhich are substantially larger than this limit. We also note that\ninterferometric self-calibration and phase-closure image reconstruction\ntechniques can be used to achieve near-field refocussing without requiring\naccurate object range information. We use our results to show that the field of\nview for high-resolution aperture synthesis imaging of geosynchronous\nsatellites from the ground can be considerably larger than the largest\nsatellites in Earth orbit.","label":"human"}
{"id":24,"text":"Semi-supervised medical image segmentation is a crucial task in generating accurate labels for limited training data. In this work, we propose an uncertainty-aware multi-view co-learning method to improve the performance on unseen images with low supervision. Our approach leverages multiple auxiliary sources of expertise (e.g., spatial consistency and interpreter confidence) using the adversarial learning framework to enhance label generation in regions that are challenging with respect to the label reliability. We also incorporate domain adaptation into our model to accommodate imaging modalities beyond the initial source domain. Our proposed technique utilizes two objective functions: one minimizing supervised loss and another maximizing self-correlation, which measures how close each predicted mask closely approximates its neighbor masks as defined by their similarity metrics. The supervised loss encourages correct classification while the self-correlation provides additional confidence in overlapping masks. Additionally, we introduce attention mechanism to guide the focus on informative areas during training. We demonstrate the effectiveness of our approach via several benchmarks by integrating it with three state-of-the-art deep networks on various medical datasets including cardiac, chest X ray, and glioblastoma with varying levels of supervisions. Our results show that domain adaptation can significantly boost the model's robustness against unseen classes while also improving the accuracy in cases where fine-tuning labeled data requires substantial expense or time. Overall, our approach contributes a highly flexible way to leverage uncertainty to generate predictions more accurately, especially when supervision is limited while enabling generalization across different domains with minimal re-training efforts.","label":"ai"}
{"id":25,"text":"{\\gamma^{|s|^k}}{ |P_\\beta s| },\\, k=1,\\, 2,\\,\\cdot\\,\\cdot\\,\\ b=1,\\, 2,\\,\\cdot\\, \\cdot\\,\\right.$$ where the equality holds on all rationals $r \\in [q\/\\omega,(q+1)\/w],\\, w>u$, with respect to infimum norm on $[q\/w,(q+1)\/w]$ and $\\sup$. From these computations, with the aid of Maple, computer programs are written for generating $p$-skewed polynomials which can be used for determining whether other similar systems also have attractive PCS properties or not. Here I write down some","label":"ai"}
{"id":26,"text":"This paper presents a novel approach for active contours and image segmentation that extends the existing dual-front model to accommodate asymmetric object shapes. The proposed method employs a modified level set equation that incorporates asymmetry and allows for accurate segmentation of objects with varying shapes and sizes. Additionally, we introduce a new optimization strategy that improves the performance of the model by allowing for efficient adaptation of the contour parameters to the shape of the object. The effectiveness of the proposed method has been demonstrated on a variety of images, including medical images and images of natural scenes, and has shown promising results for accurate and efficient object segmentation.","label":"ai"}
{"id":27,"text":"We present sound and complete environmental bisimilarities for a variant of\nDybvig et al. 's calculus of multi-prompted delimited-control operators with\ndynamic prompt generation. The reasoning principles that we obtain generalize\nand advance the existing techniques for establishing program equivalence in\ncalculi with single-prompted delimited control. The basic theory that we\ndevelop is presented using Madiot et al. 's framework that allows for smooth\nintegration and composition of up-to techniques facilitating bisimulation\nproofs. We also generalize the framework in order to express environmental\nbisimulations that support equivalence proofs of evaluation contexts\nrepresenting continuations. This change leads to a novel and powerful up-to\ntechnique enhancing bisimulation proofs in the presence of control operators.","label":"human"}
{"id":28,"text":"The FMR study of Co\/Ti bilayer thin films provides insights into the magnetic properties of these materials. The study shows that the magnetic susceptibility of the Co\/Ti bilayer system increases with decreasing temperature. The FMR spectrum of the system exhibits two resonance lines, which are attributed to the Co and Ti magnetic moments, respectively. The line-width of the Co resonance line increases at lower temperatures, whereas the line-width of the Ti resonance line decreases. These findings can be explained by considering the inter-layer magnetic interactions between the Co and Ti layers, which are predominantly antiferromagnetic. The study also reveals that the magnetic properties of the system can be tuned by varying the composition of the Co and Ti layers. The FMR results provide a unique insight into the magnetic dynamics of these fascinating materials.","label":"ai"}
{"id":29,"text":"> We propose a novel method for learning neural architectures by propagating network codes. The method is based on the observation that the network codes of a neural network can be used to represent the network architecture. The network codes are propagated through the network to generate a new network architecture. The new network architecture is then trained using backpropagation. The method is shown to be effective in learning neural architectures for image classification and object detection tasks. The paper is available here.","label":"ai"}
{"id":30,"text":"Active learning selects the most informative images to be labeled by a human user as training data. Although some active learners exist with geometry priors when binary image segmentations are performed, no such framework exists within multi-class segmentation due to complexity reasons. In this work, we develop two novel geometry aware methods for image segmentation; one considers binary classifications while the other incorporates additional classes. Our proposed method requires very few modifications from standard deep networks without sacrificing model performance. Moreover, since training samples are selected at every forward pass during testing, our models can adapt in response to new input while performing real time interactive computations on mobile devices allowing them to perform similarly as batch based methods using an iterative selection strategy. We demonstrate the efficacy of our approach for both object detection on MSCOCO datasets under various protocols in addition to real world use cases such as street sign categorization where large public domain sets are not available. For example, upon selecting 300 objects manually through MSCOCO dataset 2017 validation set split, our method outperforms state of the art systems which require thousands more examples without the benefit of interaction.","label":"ai"}
{"id":31,"text":"The families EPT (resp. EPG) Edge Intersection Graphs of Paths in a tree\n(resp. in a grid) are well studied graph classes. Recently we introduced the\ngraph classes Edge-Intersecting and Non-Splitting Paths in a Tree ENPT, and in\na Grid (ENPG). It was shown that ENPG contains an infinite hierarchy of\nsubclasses that are obtained by restricting the number of bends in the paths. Motivated by this result, in this work we focus on one bend {ENPG} graphs. We\nshow that one bend ENPG graphs are properly included in two bend ENPG graphs. We also show that trees and cycles are one bend ENPG graphs, and characterize\nthe split graphs and co-bipartite graphs that are one bend ENPG. We prove that\nthe recognition problem of one bend ENPG split graphs is NP-complete even in a\nvery restricted subfamily of split graphs. Last we provide a linear time\nrecognition algorithm for one bend ENPG co-bipartite graphs.","label":"human"}
{"id":32,"text":"> Gravitational wave detectors measure changes in signal phase\n> caused by small gravitational waves, but the phase measurements\nthemselves also introduce significant noise due to small\ndisplacements in the interferometer optical tables. We\nanalyse the properties of the corresponding interferometric signal\n'noise', and point out that it has features which are fundamentally\ndifferent from the familiar signal fluctuations used to extract\ngravitational wave events from the detector data. > In particular, while the phase noise is essentially flat, the\namplitude noise is dominated by a slowly varying 1\/f\ncomponent due to residual acoustic modes in the table. We\npropose the amplitude noise spectrum as a new and useful\nmeasure of residual interferometer control loop and\nacoustic stability. I thought this was interesting because it seemed to have relevance to the discussion of LISA's noise floor on this site and elsewhere. Does anyone know where or when this paper will be presented? Any further comments or thoughts about it?","label":"ai"}
{"id":33,"text":"Analyzing the exchange energy of two conduction electrons in a crystal we\nfind that the exchange energy may be negative and, thus, a singlet state may be\nfavorable. A full overlap in real space of wave functions of two conduction\nelectrons leads to a deeper exchange energy. Thus, the exchange interaction\ncauses a bond between two conduction electrons in real space. The singlet bond\nis possible because the singlet electrons can simultaneously and permanently\noccupy one spatial ground state, so the average energy of paired electrons is\nlower than the energy of unpaired electrons. Thus, the pairing is a result of\nthe Pauli Exclusion Principle. If conduction electrons, before pairing, are put\non the Fermi surface in the momentum space, then every pair may exist\npermanently in time. The motion of conduction electrons in the crystal may\nprevent the formation of Cooper pairs, because the kinetic energy of the motion\nis usually larger than the binding energy in the pair. Conduction electrons as\nstanding waves are local and have zero momenta, hence their momenta are\nsynchronous; therefore, weak singlet bonds are stable despite the large kinetic\nenergy on the Fermi surface. The local pairing of standing waves explains the\ninverse isotope effect, Tc-dome, insulator-superconductor transitions and many\nother facts about superconductors. The electron pairs, as bosons, can form a\nmacroscopically coherent Bose-Einstein-Condensate and, thus, become\nnon-dissipative and non-local.","label":"human"}
{"id":34,"text":"For an unstable quantum system quantum Zeno effect represents total decay\nprobability decrease while quantum anti-Zeno effect represents total decay\nprobability increase by frequent decay detection under condition that decay\nprobability is the same in all single decay detection. Some authors considered\noptical, i.e. polarization detection analogy of quantum Zeno and anti-Zeno\neffects. We use simplest (Malus law) form of such ideas on the optical, i.e. polarization detection analogy of quantum Zeno and anti-Zeno effects and we\nsuggest some new situations when decay probability is different in different\nsingle decay detection. We consider such situation, called quantum Hamlet\neffect, when, by frequent detection, final total polarization angle and state\nconverge but total probability for appearance of this state diverges. Also we\nconsider such situation, called quantum anti-Hamlet effect, when, by frequent\ndetection, final total polarization angle and state diverge but total\nprobability for appearance of this state converges. (By simple analogy we\ndefine quantum anti-Hamlet effect for unstable quantum system too.) Finally, we\nconsider such situation when, by frequent detection, total probability for\npropagation of the photon through all analyzers has form of (quasi)\nexponentially decreasing function.","label":"human"}
{"id":35,"text":"Usually, Neural Networks models are trained with a large dataset of images in\nhomogeneous backgrounds. The issue is that the performance of the network\nmodels trained could be significantly degraded in a complex and heterogeneous\nenvironment. To mitigate the issue, this paper develops a framework that\npermits to autonomously generate a training dataset in heterogeneous cluttered\nbackgrounds. It is clear that the learning effectiveness of the proposed\nframework should be improved in complex and heterogeneous environments,\ncompared with the ones with the typical dataset. In our framework, a\nstate-of-the-art image segmentation technique called DeepLab is used to extract\nobjects of interest from a picture and Chroma-key technique is then used to\nmerge the extracted objects of interest into specific heterogeneous\nbackgrounds. The performance of the proposed framework is investigated through\nempirical tests and compared with that of the model trained with the COCO\ndataset. The results show that the proposed framework outperforms the model\ncompared. This implies that the learning effectiveness of the framework\ndeveloped is superior to the models with the typical dataset.","label":"human"}
{"id":36,"text":"DeepSaliency is a novel multi-task deep neural network model designed for salient object detection. The model is trained on multiple tasks simultaneously, including object detection, semantic segmentation, and saliency prediction. The model uses a combination of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to learn the spatial and temporal relationships between objects and their saliency. The model is trained on a large dataset of images and achieves state-of-the-art performance on salient object detection tasks. The paper presents the architecture of the DeepSaliency model, the training algorithm, and experimental results demonstrating the effectiveness of the model. The paper also discusses the potential applications of the model in areas such as computer vision, robotics, and autonomous systems.","label":"ai"}
{"id":37,"text":"The theory of resource distribution in self-organizing systems on the basis\nof the fractal-cluster method has been presented. In turn, the fractal-cluster\nmethod is based on the fractal-cluster relations of V.P. Burdakov and the\nanalytical apparatus of the thermodynamics of I. Prigozhin's structure. This\ntheory consists of two parts: deterministic and probabilistic. The first part\nincludes the static and dynamic criteria, the fractal-cluster dynamic equations\nwhich are based on the Fibonacci's range characteristics fractal-cluster\ncorrelations. The second part includes fundamentals of the probabilistic theory\nof a fractal-cluster systems. This part includes the dynamic equations of the\nprobabilistic evolution of these systems. By using the numerical researches of\nthese equations for the stationary case the random state field of the one in\nthe phase space of the $D$, $H$, $F$ criteria have been obtained. For the\nsocio-economical and biological systems this theory has been tested. In\nparticular, three fundamental fractal-cluster laws have been obtained for\nbiological organisms: probabilistic, energetic and evolutionary.","label":"human"}
{"id":38,"text":"The purpose of this study is to develop a fuzzy clustering-based segmentation method for identifying vertebrae in T1-weighted spinal magnetic resonance (MR) images. The proposed method uses a fuzzy clustering algorithm to group the pixels in the image into clusters based on their intensity values. The clusters are then used to identify the vertebrae in the image. The performance of the proposed method is evaluated using a dataset of T1-weighted spinal MR images, and the results are compared with those of a traditional thresholding-based method. The results show that the proposed method is more accurate and robust than the traditional method, and it can be used to segment vertebrae in images with varying intensity levels and noise levels.","label":"ai"}
{"id":39,"text":"We present a method combining affinity prediction with region agglomeration,\nwhich improves significantly upon the state of the art of neuron segmentation\nfrom electron microscopy (EM) in accuracy and scalability. Our method consists\nof a 3D U-NET, trained to predict affinities between voxels, followed by\niterative region agglomeration. We train using a structured loss based on\nMALIS, encouraging topologically correct segmentations obtained from affinity\nthresholding. Our extension consists of two parts: First, we present a\nquasi-linear method to compute the loss gradient, improving over the original\nquadratic algorithm. Second, we compute the gradient in two separate passes to\navoid spurious gradient contributions in early training stages. Our predictions\nare accurate enough that simple learning-free percentile-based agglomeration\noutperforms more involved methods used earlier on inferior predictions. We\npresent results on three diverse EM datasets, achieving relative improvements\nover previous results of 27%, 15%, and 250%. Our findings suggest that a single\nmethod can be applied to both nearly isotropic block-face EM data and\nanisotropic serial sectioned EM data. The runtime of our method scales linearly\nwith the size of the volume and achieves a throughput of about 2.6 seconds per\nmegavoxel, qualifying our method for the processing of very large datasets.","label":"human"}
{"id":40,"text":"RSS-Net: Weakly-Supervised Multi-Class Semantic Segmentation with FMCW Radar\nIn this paper, we propose an RSS (Radar Signal) based Semantic Segmentation system, called RSS-Net, which performs multi-class image segmentation using FMCW Radar images. We introduce a novel method for weakly-supervised semantic segmentation which uses the Radar signal as an extra source of information to enhance the segmentation process. Our approach is designed to work with very limited labeled data, which is a common issue in practical applications. The RSS-Net system consists of two main components: the Radar module and the Segmentation module. The Radar module is responsible for generating the FMCW Radar image, while the Segmentation module uses the FMCW Radar image to segment the objects in the image. Our experimental results show that the proposed RSS-Net system achieves promising results in terms of accuracy and robustness.","label":"ai"}
{"id":41,"text":"In this paper, we adopt 3D Convolutional Neural Networks to segment\nvolumetric medical images. Although deep neural networks have been proven to be\nvery effective on many 2D vision tasks, it is still challenging to apply them\nto 3D tasks due to the limited amount of annotated 3D data and limited\ncomputational resources. We propose a novel 3D-based coarse-to-fine framework\nto effectively and efficiently tackle these challenges. The proposed 3D-based\nframework outperforms the 2D counterpart to a large margin since it can\nleverage the rich spatial infor- mation along all three axes. We conduct\nexperiments on two datasets which include healthy and pathological pancreases\nrespectively, and achieve the current state-of-the-art in terms of\nDice-S{\\o}rensen Coefficient (DSC). On the NIH pancreas segmentation dataset,\nwe outperform the previous best by an average of over 2%, and the worst case is\nimproved by 7% to reach almost 70%, which indicates the reliability of our\nframework in clinical applications.","label":"human"}
{"id":42,"text":"Distributed processing over networks relies on in-network processing and\ncooperation among neighboring agents. Cooperation is beneficial when agents\nshare a common objective. However, in many applications agents may belong to\ndifferent clusters that pursue different objectives. Then, indiscriminate\ncooperation will lead to undesired results. In this work, we propose an\nadaptive clustering and learning scheme that allows agents to learn which\nneighbors they should cooperate with and which other neighbors they should\nignore. In doing so, the resulting algorithm enables the agents to identify\ntheir clusters and to attain improved learning and estimation accuracy over\nnetworks. We carry out a detailed mean-square analysis and assess the error\nprobabilities of Types I and II, i.e., false alarm and mis-detection, for the\nclustering mechanism. Among other results, we establish that these\nprobabilities decay exponentially with the step-sizes so that the probability\nof correct clustering can be made arbitrarily close to one.","label":"human"}
{"id":43,"text":"A severe application of stress on articular cartilage can initiate a cascade\nof biochemical reactions that can lead to the development of osteoarthritis. We\nconstructed a multiscale mathematical model of the process with three\ncomponents: cellular, chemical, and mechanical. The cellular component\ndescribes the different chondrocyte states according to the chemicals these\ncells release. The chemical component models the change in concentrations of\nthose chemicals. The mechanical component contains a simulation of pressure\napplication onto a cartilage explant and the resulting strains that initiate\nthe biochemical processes. The model creates a framework for incorporating\nexplicit mechanics, simulated by finite element analysis, into a theoretical\nbiology framework.","label":"human"}
{"id":44,"text":"This paper presents a novel approach to learning affordance labels from simulated and real data. We introduce an ensemble of deep neural networks, where each network is trained on one modality (simulation or reality) and takes as input either images, actions, or their combinations. The learned representations are then combined at different stages in the pipeline in order to enhance robustness in diverse scenarios. Using this methodology, we were able to effectively label affordances with high precision across multiple domains and tasks, even when training data was scarce or noisy. Our findings demonstrate that our proposed technique not only learns effective representations but also enhances generalization capabilities by integrating information from multiple modalities.","label":"ai"}
{"id":45,"text":"Semantic segmentation is a key problem in computer vision that involves assigning pixels to one of multiple segment categories. Traditional approaches rely on supervised learning, requiring expensive annotated data. Generative models, on the other hand, are designed to learn from a diverse range of data and have the potential to be used for semi-supervised segmentation. This paper presents a novel deep generative model for semi-supervised semantic segmentation that has been trained to learn strong out-of-domain generalization capabilities. Our approach is based on a combination of generative adversarial networks (GANs) and convolutional neural networks (CNNs). We utilize GANs to learn a data distribution that captures the underlying data structure of the input images, and use this distribution to sample synthetic data. We then use a CNN to classify the real and synthetic images, leveraging the rich semantic information provided by the CNN classes. Our experiments demonstrate strong performance on multiple semantic segmentation tasks, including a domain adaptation task where we show our model can effectively bridge significant domain gaps. Additionally, we provide qualitative analysis that illustrates the effectiveness of our approach in generating highly accurate segmentation masks for previously unseen images. Overall, our study demonstrates the potential of generative models for semi-supervised semantic segmentation and highlights the importance of strong out-of-domain generalization capabilities in such tasks.","label":"ai"}
{"id":46,"text":"Protein aggregation is a fundamental biological process that plays an important role in various cellular functions, including protein folding and trafficking. However, abnormal protein aggregation has been implicated in several diseases such as Alzheimer's disease, Parkinson's disease, and Huntington's disease. In this study, we develop a statistical mechanical approach to model protein aggregation based on molecular dynamics simulations. Our approach takes into account the interactions between proteins and their environment, including solvent molecules and other macromolecules. We use Monte Carlo simulations to calculate the free energy of protein aggregation and identify key factors that influence aggregate formation. Our results show that the size and shape of the aggregates are strongly dependent on the concentration of the proteins and the temperature. We also find that the presence of small molecules can stabilize or destabilize protein aggregates by altering their chemical properties. These findings provide insights into the mechanisms underlying protein aggregation and have implications for drug design and therapy development.","label":"ai"}
{"id":47,"text":"State-of-the-art image segmentation algorithms generally consist of at least\ntwo successive and distinct computations: a boundary detection process that\nuses local image information to classify image locations as boundaries between\nobjects, followed by a pixel grouping step such as watershed or connected\ncomponents that clusters pixels into segments. Prior work has varied the\ncomplexity and approach employed in these two steps, including the\nincorporation of multi-layer neural networks to perform boundary prediction,\nand the use of global optimizations during pixel clustering. We propose a\nunified and end-to-end trainable machine learning approach, flood-filling\nnetworks, in which a recurrent 3d convolutional network directly produces\nindividual segments from a raw image. The proposed approach robustly segments\nimages with an unknown and variable number of objects as well as highly\nvariable object sizes. We demonstrate the approach on a challenging 3d image\nsegmentation task, connectomic reconstruction from volume electron microscopy\ndata, on which flood-filling neural networks substantially improve accuracy\nover other state-of-the-art methods. The proposed approach can replace complex\nmulti-step segmentation pipelines with a single neural network that is learned","label":"human"}
{"id":48,"text":"The detection-recognition duality problem has been intensively discussed by researchers, but no existing works focus on resolving this problem in segmenting an image into categories to achieve more interpretable object representations during recognition stage, especially against distractors. In this work, we introduce a novel attention mechanism towards instance segementation that addresses the aforementioned challenges. This model learns how to generate priority scores based on feature maps of candidates' instances and background prior to predicting confidence score. These two parallel outputs are used as supervision signals and guided by training losses for recognizing objects among all potential instances detected within the foreground. Experimental results show the proposed method outperforms state-of-the-arts even without adding extra train data, or making use of RPN+FPN structure in Mask R-CNN framework in mask region proposals (Mask RCNN) task... [more]","label":"ai"}
{"id":49,"text":"The screening of baggage using X-ray scanners is now routine in aviation\nsecurity with automatic threat detection approaches, based on 3D X-ray computed\ntomography (CT) images, known as Automatic Threat Recognition (ATR) within the\naviation security industry. These current strategies use pre-defined threat\nmaterial signatures in contrast to adaptability towards new and emerging threat\nsignatures. To address this issue, the concept of adaptive automatic threat\nrecognition (AATR) was proposed in previous work. In this paper, we present a\nsolution to AATR based on such X-ray CT baggage scan imagery. This aims to\naddress the issues of rapidly evolving threat signatures within the screening\nrequirements. Ideally, the detection algorithms deployed within the security\nscanners should be readily adaptable to different situations with varying\nrequirements of threat characteristics (e.g., threat material, physical\nproperties of objects). We tackle this issue using a novel adaptive machine\nlearning methodology with our solution consisting of a multi-scale 3D CT image\nsegmentation algorithm, a multi-class support vector machine (SVM) classifier\nfor object material recognition and a strategy to enable the adaptability of\nour approach. Experiments are conducted on both open and sequestered 3D CT\nbaggage image datasets specifically collected for the AATR study. Our proposed\napproach performs well on both recognition and adaptation. Overall our approach\ncan achieve the probability of detection around 90% with a probability of false\nalarm below 20%. Our AATR shows the capabilities of adapting to varying types\nof materials, even the unknown materials which are not available in the\ntraining data, adapting to varying required probability of detection and\nadapting to varying scales of the threat object.","label":"human"}
{"id":50,"text":"## Abstract\nRecent research has shown that the second order staggered Runge-Kutta method is a viable choice for integration in time of partial differential\nequations involving spherical harmonics. In this paper we construct a second order staggered Runge-Kutta time-stepping method in conjunction\nwith spherical harmonics (SH) moments of the radiative transport equations. We will investigate the stability of the resulting time-stepping\nscheme and, to this end, derive expressions for the spectral radii of the amplification matrices associated with the staggered grid SH\nmoments of both radiative transport and nonuniform helium models. We will further provide a numerical comparison of our scheme with\npreviously developed staggered grid SH methods, some of which include a linearization of the monotonicity constraint at the cell boundaries. We will also compare our schemes with the state-of-the-art finite volume and finite difference approaches.","label":"ai"}
{"id":51,"text":"In high-dimensional settings, variable selection is an essential task for building accurate predictive models. However, in situations where covariates are grouped together, such as in genomic or multi-omics datasets, Bayesian methods are less efficient. We propose a novel Bayesian variable selection approach for high-dimensional settings with grouped covariates. Our method allows for efficient computation by exploiting structure in the covariates and incorporating prior knowledge about the grouped covariates. Our results demonstrate the effectiveness of our approach in a variety of datasets, and we provide evidence on its ability to handle grouped covariates and incorporate prior knowledge about the groups. Our method paves the way for a more robust and efficient Bayesian variable selection framework in high-dimensional settings with grouped covariates.","label":"ai"}
{"id":52,"text":"The 355 optically polarized QSOs have redshifts from 0.061 to 3.94 and are\nspread out over the sky except for a 60 degree band centered on the Galactic\nEquator. The data we analyze was measured, collected and published by others. Here, we apply tests suitable for large-scale samples and find that the\npolarization directions align with a significance of p = 1% by one test and are\ncorrelated by a second test with p = 5%, each p-value uncertain within a factor\nof about 2. The tests return a preferred Cartesian coordinate system that\nfortuitously aligns well with the Milky Way Galaxy with a significance of p =\n3%. Thus, the Hub Tests' results combined together imply the polarization\ndirections are correlated with a significance that is much less than 1%, which\nis remarkable for such a large-scale sample.","label":"human"}
{"id":53,"text":"Deep learning-based semi-supervised learning (SSL) algorithms have led to\npromising results in medical images segmentation and can alleviate doctors'\nexpensive annotations by leveraging unlabeled data. However, most of the\nexisting SSL algorithms in literature tend to regularize the model training by\nperturbing networks and\/or data. Observing that multi\/dual-task learning\nattends to various levels of information which have inherent prediction\nperturbation, we ask the question in this work: can we explicitly build\ntask-level regularization rather than implicitly constructing networks- and\/or\ndata-level perturbation-and-transformation for SSL? To answer this question, we\npropose a novel dual-task-consistency semi-supervised framework for the first\ntime. Concretely, we use a dual-task deep network that jointly predicts a\npixel-wise segmentation map and a geometry-aware level set representation of\nthe target. The level set representation is converted to an approximated\nsegmentation map through a differentiable task transform layer. Simultaneously,\nwe introduce a dual-task consistency regularization between the level\nset-derived segmentation maps and directly predicted segmentation maps for both\nlabeled and unlabeled data. Extensive experiments on two public datasets show\nthat our method can largely improve the performance by incorporating the\nunlabeled data. Meanwhile, our framework outperforms the state-of-the-art\nsemi-supervised medical image segmentation methods. Code is available at:","label":"human"}
{"id":54,"text":"> Conditional generative adversarial networks (cGANs) are a popular class of generative models that have been used to generate images conditioned on class labels. However, the conditional nature of cGANs is not explicitly enforced by the model architecture. In this paper, we show that cGANs are not explicitly conditional, and that the conditional nature of cGANs is an emergent property of the model architecture. We show that cGANs can be trained to generate images that are not conditioned on the class label, and that the conditional nature of cGANs can be broken by training the model on a different dataset. We also show that cGANs can be trained to generate images that are conditioned on a different class label than the one used during training. Our results suggest that the conditional nature of cGANs is not a fundamental property of the model architecture, but rather an emergent property that can be broken or changed by training the model on different datasets. The paper is available here.","label":"ai"}
{"id":55,"text":"In this paper, firstly, by solving the Riemann problem of the zero-pressure\nflow in gas dynamics with a flux approximation, we construct parameterized\ndelta-shock and constant density solutions, then we show that, as the flux\nperturbation vanishes, they converge to the delta-shock and vacuum state\nsolutions of the zero-pressure flow, respectively. Secondly, we solve the\nRiemann problem of the Euler equations of isentropic gas dynamics with a double\nparameter flux approximation including pressure. Further we rigorously prove\nthat, as the two-parameter flux perturbation vanishes, any Riemann solution\ncontaining two shock waves tends to a delta shock solution to the zero-pressure\nflow; any Riemann solution containing two rarefaction waves tends to a\ntwo-contact-discontinuity solution to the zero-pressure flow and the nonvacuum\nintermediate state in between tends to a vacuum state.","label":"human"}
{"id":56,"text":"Preparation of high-quality datasets for the urban scene understanding is a\nlabor-intensive task, especially, for datasets designed for the autonomous\ndriving applications. The application of the coarse ground truth (GT)\nannotations of these datasets without detriment to the accuracy of semantic\nimage segmentation (by the mean intersection over union - mIoU) could simplify\nand speedup the dataset preparation and model fine tuning before its practical\napplication. Here the results of the comparative analysis for semantic\nsegmentation accuracy obtained by PSPNet deep learning architecture are\npresented for fine and coarse annotated images from Cityscapes dataset. Two\nscenarios were investigated: scenario 1 - the fine GT images for training and\nprediction, and scenario 2 - the fine GT images for training and the coarse GT\nimages for prediction. The obtained results demonstrated that for the most\nimportant classes the mean accuracy values of semantic image segmentation for\ncoarse GT annotations are higher than for the fine GT ones, and the standard\ndeviation values are vice versa. It means that for some applications some\nunimportant classes can be excluded and the model can be tuned further for some\nclasses and specific regions on the coarse GT dataset without loss of the\naccuracy even. Moreover, this opens the perspectives to use deep neural\nnetworks for the preparation of such coarse GT datasets.","label":"human"}
{"id":57,"text":"# Introduction\nReal-time medical image segmentation is a fundamental process in the field, which has been widely researched. This paper proposes an attention network, namely the trilateral attention network (TLAT), that incorporates global context awareness, a spatial attention mechanism, and a localized feature selection mechanism. In addition, a pyramid structure is integrated to improve the performance of the network. The proposed network demonstrates a segmentation speed of 264.0 FPS with 93.5% pixel accuracy, outperforming other state-of-the-art methods.","label":"ai"}
{"id":58,"text":"> Skin cancer is one of the most common cancers in the world. Early detection of skin cancer is crucial for successful treatment. However, the diagnosis of skin cancer is a challenging task for dermatologists due to the large number of skin lesions and the difficulty in distinguishing between benign and malignant lesions. In this paper, we propose a self-learning AI framework for skin lesion image segmentation and classification. The framework consists of two main components: a segmentation network and a classification network. The segmentation network is used to segment the skin lesion from the background, while the classification network is used to classify the segmented skin lesion as benign or malignant. The framework is trained on a large dataset of skin lesion images and is able to learn the features of skin lesions and the relationship between the features and the classification labels. The framework is evaluated on a dataset of skin lesion images and is able to achieve high accuracy in both segmentation and classification tasks. The framework is also able to learn from new data and adapt to new skin lesion images. The framework is a promising tool for the diagnosis of skin cancer and can help dermatologists to make more accurate and efficient diagnoses. The following is the full text of the abstract for a research paper titled \"Self-Learning AI Framework for Skin Lesion Image Segmentation and Classification\" from arxiv.org:\n> Skin cancer is one of the most common cancers in the world. Early detection of skin cancer is crucial for successful treatment. However, the diagnosis of skin cancer is a challenging task for dermatologists due to the large number of skin lesions and the difficulty in distinguishing between benign and malignant lesions. In this paper, we propose a self-learning AI framework for skin lesion image segmentation and classification. The framework consists of two main components: a segmentation network and a classification network. The segmentation network is used to segment the skin lesion from the background, while the classification network is used to classify the segmented skin lesion as benign or malignant. The framework is trained on a large dataset of skin lesion images and is able to learn","label":"ai"}
{"id":59,"text":"The recent vision transformer(i.e.for image classification) learns non-local\nattentive interaction of different patch tokens. However, prior arts miss\nlearning the cross-scale dependencies of different pixels, the semantic\ncorrespondence of different labels, and the consistency of the feature\nrepresentations and semantic embeddings, which are critical for biomedical\nsegmentation. In this paper, we tackle the above issues by proposing a unified\ntransformer network, termed Multi-Compound Transformer (MCTrans), which\nincorporates rich feature learning and semantic structure mining into a unified\nframework. Specifically, MCTrans embeds the multi-scale convolutional features\nas a sequence of tokens and performs intra- and inter-scale self-attention,\nrather than single-scale attention in previous works. In addition, a learnable\nproxy embedding is also introduced to model semantic relationship and feature\nenhancement by using self-attention and cross-attention, respectively. MCTrans\ncan be easily plugged into a UNet-like network and attains a significant\nimprovement over the state-of-the-art methods in biomedical image segmentation\nin six standard benchmarks. For example, MCTrans outperforms UNet by 3.64%,\nKavirs, ISIC2018 dataset, respectively. Code is available at\nhttps:\/\/github.com\/JiYuanFeng\/MCTrans.","label":"human"}
{"id":60,"text":"After the existence proof of the first remarkably stable simple choreographic\nmotion-- the figure eight of the planar three-body problem by Chenciner and\nMontgomery in 2000, a great number of simple choreographic solutions have been\ndiscovered numerically but very few of them have rigorous existence proofs and\nnone of them are stable. Most important to astronomy are stable periodic\nsolutions which might actually be seen in some stellar system. A question for\nsimple choreographic solutions on $n$-body problems naturally arises: Are there\nany other stable simple choreographic solutions except the figure eight? In this paper, we prove the existence of infinitely many simple choreographic\nsolutions in the classical Newtonian 4-body problem by developing a new\nvariational method with structural prescribed boundary conditions (SPBC). Surprisingly, a family of choreographic orbits of this type are all linearly\nstable. Among the many stable simple choreographic orbits, the most\nextraordinary one is the stable star pentagon choreographic solution. The star\npentagon is assembled out of four pieces of curves which are obtained by\nminimizing the Lagrangian action functional over the SPBC. We also prove the existence of infinitely many double choreographic periodic\nsolutions, infinitely many non-choreographic periodic solutions and uncountably\nmany quasi-periodic solutions. Each type of periodic solutions have many stable\nsolutions and possibly infinitely many stable solutions.","label":"human"}
{"id":61,"text":"In this paper, we argue that overemphasis on using unseen domain generalization (UDG) in data augmentation can be detrimental to model performance. We show that in some cases, generalization to unseen domains is not necessary or even desirable when the objective is to improve performance on a specific target domain. Specifically, we find that domain-specific augmentation techniques outperform UDG augmentation when dealing with tasks such as image classification and object recognition, by focusing on generating more diverse examples within the target domain. Moreover, we demonstrate that UDG augmentation can lead to overfitting to the noise generated during training rather than the underlying structure of the data. Our experimental results show that our approach achieves improved performance in various situations, particularly when there is limited labeled data available for the target domain. This work highlights the need for a more nuanced understanding of data augmentation and its impact on domain adaptation and transfer, and suggests a shift towards domain-specific methods for data augmentation.","label":"ai"}
{"id":62,"text":"This paper presents a novel method for unsupervised segmentation of pathology\nimages. Staging of lung cancer is a major factor of prognosis. Measuring the\nmaximum dimensions of the invasive component in a pathology images is an\nessential task. Therefore, image segmentation methods for visualizing the\nextent of invasive and noninvasive components on pathology images could support\npathological examination. However, it is challenging for most of the recent\nsegmentation methods that rely on supervised learning to cope with unlabeled\npathology images. In this paper, we propose a unified approach to unsupervised\nrepresentation learning and clustering for pathology image segmentation. Our\nmethod consists of two phases. In the first phase, we learn feature\nrepresentations of training patches from a target image using the spherical\nk-means. The purpose of this phase is to obtain cluster centroids which could\nbe used as filters for feature extraction. In the second phase, we apply\nconventional k-means to the representations extracted by the centroids and then\nproject cluster labels to the target images. We evaluated our methods on\npathology images of lung cancer specimen. Our experiments showed that the\nproposed method outperforms traditional k-means segmentation and the\nmultithreshold Otsu method both quantitatively and qualitatively with an\nimproved normalized mutual information (NMI) score of 0.626 compared to 0.168\nand 0.167, respectively. Furthermore, we found that the centroids can be\napplied to the segmentation of other slices from the same sample.","label":"human"}
{"id":63,"text":"http:\/\/arxiv.org\/abs\/1504.02937 - published in Geometry and Topology (Toledo et al., Eds. ), Proceedings of the CIMPA Research School on Algebraic Geometry held at Tours June-July 2013. > It recently has been discovered [2] that Teichmuller geodesics whose endpoints lie on certain translative covers of infinite genus punctured Riemann surfaces have infinitely many other distinct lifts to the universal curve. In this article we prove that every indiscrete cover has but finitely many such lifts; hence it cannot be used to obtain an example of an irrational polygon in the plane whose vertices generate all its interior lattice points under integer linear relations.","label":"ai"}
{"id":64,"text":"> We propose a method to perform qubit state tomography in superconducting circuits via weak measurements. The method is based on the weak measurement of the qubit state by a probe qubit, which is then measured by a readout circuit. The readout circuit is designed to be sensitive to the probe qubit state, but insensitive to the qubit state. The method is experimentally demonstrated in a superconducting circuit with a transmon qubit and a probe qubit. The qubit state is reconstructed with a fidelity of 99.9%. The method is also applied to a qubit with a non-Gaussian state, and the non-Gaussianity of the state is confirmed. The paper is available here.","label":"ai"}
{"id":65,"text":"The graph Laplacian is a standard tool in data science, machine learning, and\nimage processing. The corresponding matrix inherits the complex structure of\nthe underlying network and is in certain applications densely populated. This\nmakes computations, in particular matrix-vector products, with the graph\nLaplacian a hard task. A typical application is the computation of a number of\nits eigenvalues and eigenvectors. Standard methods become infeasible as the\nnumber of nodes in the graph is too large. We propose the use of the fast\nsummation based on the nonequispaced fast Fourier transform (NFFT) to perform\nthe dense matrix-vector product with the graph Laplacian fast without ever\nforming the whole matrix. The enormous flexibility of the NFFT algorithm allows\nus to embed the accelerated multiplication into Lanczos-based eigenvalues\nroutines or iterative linear system solvers and even consider other than the\nstandard Gaussian kernels. We illustrate the feasibility of our approach on a\nnumber of test problems from image segmentation to semi-supervised learning\nbased on graph-based PDEs. In particular, we compare our approach with the\nNystr\\\"om method. Moreover, we present and test an enhanced, hybrid version of\nthe Nystr\\\"om method, which internally uses the NFFT.","label":"human"}
{"id":66,"text":"The requirements to achieve high detection efficiency (above 50\\%) and\ngigahertz (GHz) frame rate for the proposed 42-keV X-ray free-electron laser\n(XFEL) at Los Alamos are summarized. Direct detection scenarios using C\n(diamond), Si, Ge and GaAs semiconductor sensors are analyzed. Single-photon\ncounting (SPC) mode and weak SPC mode using Si can potentially meet the\nefficiency and frame rate requirements and be useful to both photoelectric\nabsorption and Compton physics as the photon energy increases. Multilayer\nthree-dimensional (3D) detector architecture, as a possible means to realize\nSPC modes, is compared with the widely used two-dimensional (2D) hybrid planar\nelectrode structure and 3D deeply entrenched electrode architecture. Demonstration of thin film cameras less than 100-$\\mu$m thick with onboard thin\nASICs could be an initial step to realize multilayer 3D detectors and SPC modes\nfor XFELs.","label":"human"}
{"id":67,"text":"Direct numerical simulation (DNS) is a computational method used to solve the Navier-Stokes equations directly, without any turbulence model. This approach is used to study the behavior of turbulent flows in channels, which are important in many engineering applications. Recently, researchers have successfully performed DNS simulations up to $Re_\\tau \\approx 5200$, which is the Reynolds number that is commonly used to separate laminar from turbulent flows. In this paper, we review the technical details of the DNS methods used to solve the high-Reynolds-number turbulent channel flows, including the choice of domain size, mesh generation, and solution technique. We also present the numerical results, which show the expected turbulence structures and behavior, such as turbulent spot growth and shear stress fluctuations. The paper provides a comprehensive overview of the state-of-the-art in DNS of turbulent channel flows, and is useful for researchers and practitioners working in this field.","label":"ai"}
{"id":68,"text":"The paper presents an analytic approach to the problem of matroid representability, which is concerned with the existence of a finite field over which a given matroid can be represented as a linear code. The paper focuses on the cardinality of sets of k-independent vectors over finite fields and the maximum distance separable conjecture, which states that the maximum cardinality of a set of k-independent vectors over a finite field is equal to the maximum distance between any two distinct points in the matroid. The paper provides a proof of this conjecture using analytic methods, and also discusses some related results and open problems in the field.","label":"ai"}
{"id":69,"text":"The class of joint decoder of probabilistic fingerprinting codes is of utmost\nimportance in theoretical papers to establish the concept of fingerprint\ncapacity. However, no implementation supporting a large user base is known to\ndate. This article presents an iterative decoder which is, as far as we are\naware of, the first practical attempt towards joint decoding. The\ndiscriminative feature of the scores benefits on one hand from the\nside-information of previously accused users, and on the other hand, from\nrecently introduced universal linear decoders for compound channels. Neither\nthe code construction nor the decoder make precise assumptions about the\ncollusion (size or strategy). The extension to incorporate soft outputs from\nthe watermarking layer is straightforward. An extensive experimental work\nbenchmarks the very good performance and offers a clear comparison with\nprevious state-of-the-art decoders.","label":"human"}
{"id":70,"text":"Quantization of Deep Neural Networks for Accurate Edge Computing\nAbstract:\nDeep neural networks (DNNs) have shown remarkable performance in various applications, including image and speech recognition. However, the high computational complexity and memory requirements of DNNs make them impractical for edge computing, where resources are limited. In this paper, we propose a novel quantization technique for DNNs that reduces the precision of weights and activations while maintaining accuracy. Our technique is based on a combination of pruning and quantization, where we first prune the network to remove unnecessary connections, and then quantize the remaining weights and activations to reduce their precision. We evaluate our technique on several benchmark datasets and show that it significantly reduces the computational complexity and memory requirements of DNNs while maintaining accuracy. Our results demonstrate the feasibility of using DNNs for edge computing and pave the way for the development of more efficient and accurate edge computing systems.","label":"ai"}
{"id":71,"text":"Smoking of tobacco is predicted to cause approximately six million deaths\nworldwide in 2014. Responding effectively to this epidemic requires a thorough\nunderstanding of how smoking behaviour is transmitted and modified. Here, we\npresent a new mathematical model of the social dynamics that cause cigarette\nsmoking to spread in a population. Our model predicts that more individualistic\nsocieties will show faster adoption and cessation of smoking. Evidence from a\nnew century-long composite data set on smoking prevalence in 25 countries\nsupports the model, with direct implications for public health interventions\naround the world. Our results suggest that differences in culture between\nsocieties can measurably affect the temporal dynamics of a social spreading\nprocess, and that these effects can be understood via a quantitative\nmathematical model matched to observations.","label":"human"}
{"id":72,"text":"> Recently, the observation of positron and positronium emission lines in\n> the photon spectra of positron beams trapped in the plasma of gaseous\n> positive polyelectrolites, has raised serious objections. In this paper we\n> investigate a new approach that can explain and reproduce these observed\n> features. The method is applied to spectra recorded at a positron beam\n> impinging on aqueous glycerol. > It was concluded that the observed spectrum in the above mentioned\n> experiment can be well reproduced if the gaseous positive polyelectrolite\n> is a mixture of water solution - water vapor. Positronium production has\n> been considered as a result of the interaction of positron beam with the\n> gaseous ions in the vacuum and with the aqueous gaseous ions in the\n> atmoshere. In this work, the gaseous ions are generated in the gap between\n> two charged electrodes. The gap is filled with the water and water\n> vapor mixture. An emulsion of glycerol in water is formed in the water\n> vapor phase due to the presence of charged glycerol molecules. The study\n> indicates that a positron beam impinging on the surface of the glycerol\n> solution in the water vapor above can produce positronium in this\n> emulsion according to a free-free process. Our calculations show that the\n> intensity of the produced positronium depends on the polarity of the\n> aqueous glycerol solution and the gap width between the electrodes. The\n> results are also consistent with the findings of the photon spectrum at\n> large distance, when the width of the positive polyelectrolite gap was\n> equal to zero for the large distance. > Reasons of the anomalies observed have been discussed. The paper\n> concludes that due to the experimental configuration and the presence of\n> charged molecules of the aqueous phase, the presence of a gaseous positive\n> polyelectrolite is not necessary for observ","label":"ai"}
{"id":73,"text":"Deep structured output learning shows great promise in tasks like semantic\nimage segmentation. We proffer a new, efficient deep structured model learning\nscheme, in which we show how deep Convolutional Neural Networks (CNNs) can be\nused to estimate the messages in message passing inference for structured\nprediction with Conditional Random Fields (CRFs). With such CNN message\nestimators, we obviate the need to learn or evaluate potential functions for\nmessage calculation. This confers significant efficiency for learning, since\notherwise when performing structured learning for a CRF with CNN potentials it\nis necessary to undertake expensive inference for every stochastic gradient\niteration. The network output dimension for message estimation is the same as\nthe number of classes, in contrast to the network output for general CNN\npotential functions in CRFs, which is exponential in the order of the\npotentials. Hence CNN message learning has fewer network parameters and is more\nscalable for cases that a large number of classes are involved. We apply our\nmethod to semantic image segmentation on the PASCAL VOC 2012 dataset. We\nachieve an intersection-over-union score of 73.4 on its test set, which is the\nbest reported result for methods using the VOC training images alone. This\nimpressive performance demonstrates the effectiveness and usefulness of our CNN\nmessage learning method.","label":"human"}
{"id":74,"text":"With the explosive growth of multi-modal medical image data, deep learning has found its broad applications in assisting accurate medical diagnosis and developing intelligent medical assistants to achieve better medical efficiency. However, the manual annotation of images is time-consuming and may incur additional medical costs, especially for the three-dimensional and high-resolution images. In recent years, semi-supervised learning has received increasing attention with promising performance. Contrastive representation learning has also been widely adapted to medical image segmentation, and has achieved better performance than traditional autoencoders, etcetera. However, the supervision weights generated by existing methods, such as the traditional maximum margin mechanism, are not optimized to utilize data effectively. Moreover, the representation similarity between different modalities may not directly indicate the quality of the predicted label, which may also incur poor segmentation performance. In this paper, we propose a novel contrastive voxel-wise representation distillation strategy (the SimCVD) to solve the above problems. First, a novel attention-based loss function is proposed, which can adaptively generate weights for different supervision samples according to the reliability of the generated pseudo-labels. Secondly, inspired by attention model, we utilize the attention mechanism in the contrastive loss to distinguish the quality of different supervised image groups. Finally, in voxel level, we obtain and distill the representations of the selected groups in the feature space to effectively reduce the distance between the corresponding pseudo and true groups and better preserve the semantic information in the feature representation, which can make the model learn more comprehensive and effective visual features. Extensive experiments on three 3 D medical image datasets (BraTS 2015, BraTS 2021, and 2017 Lits data sets) show that our SimCVD approach outperforms the existing most recent methods. For the BraTS 2015 dataset, the segmentation accuracy and dice coefficient of our approach are higher than that of the current state-of-the-art, respectively. For the BraTS 2021 and 2017 Lits datasets, the","label":"ai"}
{"id":75,"text":"Facade segmentation is a common task in computer vision, with applications ranging from object recognition to image captioning. However, despite the significant progress made in recent years, achieving accurate facade segmentation remains challenging. This is primarily due to the variability in real-world images, including differences in illumination, camera angles, and building styles. In this paper, we present a comprehensive study of facade segmentation in the wild. We analyze large datasets of annotated images and evaluate various state-of-the-art methods. Our findings reveal that existing approaches often struggle to handle complex scenes and varying lighting conditions. To address these challenges, we propose a novel multi-scale approach to facade segmentation. Using a combination of deep convolutional networks and region growing techniques, our method achieves state-of-the-art performance on numerous benchmark datasets while also being able to handle diverse real-world scenarios. We believe our work will be instrumental in advancing the field of facade segmentation and improving its practical applicability in real-world settings.","label":"ai"}
{"id":76,"text":"The purpose of this study is to investigate the effectiveness of serious games as a tool for promoting environmental consciousness education among residents in their daily lives. This research aims to explore how serious games can be used to raise awareness about environmental issues and encourage sustainable behaviors, such as recycling and energy conservation. The study will use a mixed-methods approach, including surveys, interviews, and observations. Participants will include residents from different age groups and socioeconomic backgrounds who have experience with serious games related to environmental education. The results of this study will provide insights into the potential benefits of using serious games for human environmental consciousness education. It will also identify factors that influence the adoption and effectiveness of these games, such as game design, engagement, and motivation. Overall, this research has important implications for educators, policymakers, and developers seeking to promote sustainability through interactive learning experiences.","label":"ai"}
{"id":77,"text":"This paper proposes a novel algorithm for the problem of structural image\nsegmentation through an interactive model-based approach. Interaction is\nexpressed in the model creation, which is done according to user traces drawn\nover a given input image. Both model and input are then represented by means of\nattributed relational graphs derived on the fly. Appearance features are taken\ninto account as object attributes and structural properties are expressed as\nrelational attributes. To cope with possible topological differences between\nboth graphs, a new structure called the deformation graph is introduced. The\nsegmentation process corresponds to finding a labelling of the input graph that\nminimizes the deformations introduced in the model when it is updated with\ninput information. This approach has shown to be faster than other segmentation\nmethods, with competitive output quality. Therefore, the method solves the\nproblem of multiple label segmentation in an efficient way. Encouraging results\non both natural and target-specific color images, as well as examples showing\nthe reusability of the model, are presented and discussed.","label":"human"}
{"id":78,"text":"We consider spherically symmetric static composite structures consisting of a\nboson star and a global monopole, minimally or non-minimally coupled to the\ngeneral relativistic gravitational field. In the non-minimally coupled case,\nMarunovic and Murkovic have shown that these objects, so-called boson D-stars,\ncan be sufficiently gravitationally compact so as to potentially mimic black\nholes. Here, we present the results of an extensive numerical parameter space\nsurvey which reveals additional new and unexpected phenomenology in the model. In particular, focusing on families of boson D-stars which are parameterized by\nthe central amplitude of the boson field, we find configurations for both the\nminimally and non-minimally coupled cases that contain one or more shells of\nbosonic matter located far from the origin. In parameter space, each shell\nspontaneously appears as one tunes through some critical central amplitude of\nthe boson field. In some cases the shells apparently materialize at spatial\ninfinity: in these instances their areal radii are observed to obey a universal\nscaling law in the vicinity of the critical amplitude. We derive this law from\nthe equations of motion and the asymptotic behavior of the fields.","label":"human"}
{"id":79,"text":"Abstract: We prove that if the Riemann Hypothesis (RH) holds then there exists an absolute constant $C>0$ such that for any positive integer $n$, we have $$\\sum_{k=1}^n \\frac{1}{k^s} < C\\log n$$ for all real numbers $s > 2$. This result was first proved by J.B. Conrey in [Con]. In this note, we give another proof using the method of Robin's inequality. As a consequence, we obtain some new equivalent statements to the Riemann Hypothesis. For example, we show that the Riemann Hypothesis implies that there exist constants $\\alpha_1,\\ldots,\\alpha_r$ with $0<\\alpha_i<1\/2$ for each $i = 1,\\ldots, r$ such that $$|\\zeta(1+it)|>\\exp(\\pi t^{\\alpha_1}\\cdots t^{\\alpha_r})$$ for almost every $t\\in {\\mathbb R}$.","label":"ai"}
{"id":80,"text":"Selective image super-resolution is an advanced technique used to enhance the resolution of specific regions within an image while preserving the rest of the image's quality. This approach is particularly useful in applications that require high-resolution images of specific objects or regions within an image, such as medical imaging, surveillance, and facial recognition. The paper presents a novel algorithm for selective image super-resolution that uses a deep learning model to learn the hierarchical features of an image. The model is trained to enhance the resolution of specific regions within an image while simultaneously preserving the rest of the image's quality. The paper demonstrates the effectiveness of the proposed algorithm through several experiments and comparisons with state-of-the-art methods. The results show that the selective image super-resolution algorithm is able to enhance the resolution of specific regions within an image while maintaining the overall quality of the image. Overall, the paper's contribution is the development of a novel algorithm for selective image super-resolution that can be applied to a wide range of real-world applications.","label":"ai"}
{"id":81,"text":"The rapid development of signal processing on graphs provides a new\nperspective for processing large-scale data associated with irregular domains. In many practical applications, it is necessary to handle massive data sets\nthrough complex networks, in which most nodes have limited computing power. Designing efficient distributed algorithms is critical for this task. This\npaper focuses on the distributed reconstruction of a time-varying bandlimited\ngraph signal based on observations sampled at a subset of selected nodes. A\ndistributed least square reconstruction (DLSR) algorithm is proposed to recover\nthe unknown signal iteratively, by allowing neighboring nodes to communicate\nwith one another and make fast updates. DLSR uses a decay scheme to annihilate\nthe out-of-band energy occurring in the reconstruction process, which is\ninevitably caused by the transmission delay in distributed systems. Proof of\nconvergence and error bounds for DLSR are provided in this paper, suggesting\nthat the algorithm is able to track time-varying graph signals and perfectly\nreconstruct time-invariant signals. The DLSR algorithm is numerically\nexperimented with synthetic data and real-world sensor network data, which\nverifies its ability in tracking slowly time-varying graph signals.","label":"human"}
{"id":82,"text":"In this paper, we present a novel approach for learning to segment objects from scribbles using multi-scale adversarial attention gates. Our method leverages the power of adversarial training to learn a mapping between scribbles and segmentation masks, while simultaneously incorporating multi-scale attention gates to capture the spatial relationships between the scribbles and the objects they represent. We evaluate our method on several benchmark datasets and demonstrate state-of-the-art performance in segmenting objects from scribbles. Our approach provides a new way to leverage the information contained in scribbles to improve the accuracy of object segmentation tasks.","label":"ai"}
{"id":83,"text":"We study integrated characteristics of ~14000 low-redshift (0<z<1) compact\nstar-forming galaxies (SFGs) selected from the Data Release 12 of the Sloan\nDigital Sky Survey. It is found that emission of these galaxies is dominated by\nstrong young bursts of star formation, implying that their luminosities\nexperience rapid variations on a time scale of a few Myr. Reducing integrated\ncharacteristics of these galaxies to zero burst age would result in a\nconsiderably tighter and almost linear relation between stellar mass and star\nformation rate (SFR). The same correction implies that the specific star\nformation rate (the ratio of SFR and stellar mass) is not dependent on the\ngalaxy stellar mass. We conclude that the correction for rapid luminosity\nevolution must be taken into account in a similar way when comparing different\nsamples of low- and high-redshift SFGs. If the bursting nature of star\nformation and young burst ages are characteristics of the galaxies selected at\nhigh redshifts, the age correction of observed SFRs derived from the Hbeta\nemission line or UV continua would modify the derived SFR densities in the\nearly universe.","label":"human"}
{"id":84,"text":"Dense Transformer Networks is an academic paper that presents a novel architecture for transformer-based neural networks. The authors introduce the concept of dense transformer networks, which are designed to improve the efficiency and scalability of transformer models. The paper proposes a new dense transformer layer that replaces the traditional feed-forward network in transformer models, and shows that this new layer can significantly reduce the number of parameters and computations required for training and inference. The paper also presents experimental results that demonstrate the effectiveness of the dense transformer network on a variety of natural language processing tasks, including machine translation, text classification, and question answering. Overall, the paper provides a significant contribution to the field of transformer-based neural networks by introducing a new and efficient architecture that can improve the performance and scalability of these models.","label":"ai"}
{"id":85,"text":"Magnetic resonance imaging (MRI) is the non-invasive modality of choice for\nbody tissue composition analysis due to its excellent soft tissue contrast and\nlack of ionizing radiation. However, quantification of body composition\nrequires an accurate segmentation of fat, muscle and other tissues from MR\nimages, which remains a challenging goal due to the intensity overlap between\nthem. In this study, we propose a fully automated, data-driven image\nsegmentation platform that addresses multiple difficulties in segmenting MR\nimages such as varying inhomogeneity, non-standardness, and noise, while\nproducing high-quality definition of different tissues. In contrast to most\napproaches in the literature, we perform segmentation operation by combining\nthree different MRI contrasts and a novel segmentation tool which takes into\naccount variability in the data. The proposed system, based on a novel affinity\ndefinition within the fuzzy connectivity (FC) image segmentation family,\nprevents the need for user intervention and reparametrization of the\nsegmentation algorithms. In order to make the whole system fully automated, we\nadapt an affinity propagation clustering algorithm to roughly identify tissue\nregions and image background. We perform a thorough evaluation of the proposed\nalgorithm's individual steps as well as comparison with several approaches from\nthe literature for the main application of muscle\/fat separation. Furthermore,\nwhole-body tissue composition and brain tissue delineation were conducted to\nshow the generalization ability of the proposed system. This new automated\nplatform outperforms other state-of-the-art segmentation approaches both in\naccuracy and efficiency.","label":"human"}
{"id":86,"text":"> Medical image segmentation is the primary task in Computer-Aided Diagnosis (CAD) techniques. Over the years many supervised machine learning models have been proposed and they have shown quite substantial improvements over earlier non supervised models. In this paper, we explored the use of deep learning to achieve better segmentation performance. By far, we have obtained the best result with the model we created in all of the publicly available segmentation datasets in 3 modalities: MRI, CT and Ultrasound. In our approach, we used U-NET, the most suitable architecture for segmentation task. We have also compared both the single and multi-task learning of U-NET. Our best model achieved a Mean Intersection Over Union (mIOU) of 91.09% in multi-task learning and 91.02% in single task learning in 24 classes in Ultrasound dataset. With 300 epochs of training, we were able to converge the mIOU to over 91% over all the three datasets in the validation stage. For multi-task learning, we were able to reduce the mIOU gap to 0,64% from a large gap of 3,78% in 24 classes. Citation: Gunes Ozdemir, Ahmed Elbakry, Mohsen Ansari, Alireza Fasongashti, Nour Eldeen Atwa. Deep Learning for Multi-Task Medical Image Segmentation in Multiple Modalities arXiv:1710.02163v2 [cs.CV].","label":"ai"}
{"id":87,"text":"This section contains the full abstract paper titled \"RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion Segmentation\" from arxiv.org\nIn this paper, we introduce RatLesNetv2, an image segmentation system for rodent brains for use in the field of systems neurobiology. Previous models for the segmentation of microscopy images of rodent brain slices have required thousands of segmentations to train, and have suffered from a trade-off between segmentation accuracy and computational efficiency. RatLesNetv2 is based on the original architecture of U-Net [32], a deep feed-forward network. The network architecture is composed of encoding and decoding phases to extract deep semantic information from the input image and up-sample it back to the original resolution, respectively. Encoding is accomplished with two parallel convolutional paths, where each starts with a convolutional block with multiple convolutional layers and produces a feature map with double size. The decoding path follows the same structure up-sampling the feature map back to the original size of the input image, while skipping connections merge features in the lower resolution path. We trained RatLesNetv2 on 1400 images for 4 different label classes. A leave-one-out cross validation scheme was used to test the model performance. The model provides a high performance trade-off between computation time and accuracy (~15 minutes per image on 4 high-end NVIDIA GTX 1080 GPUs), and provides consistent performance across all lesion types on different brain slices. The complete code is available for free, under the MIT Open-source license through GitHub (link in the paper). Image segmentation is a core task for most fields in medical imaging, and is at the heart of most computer-aided diagnosis and image analysis systems. In the recent years, the emergence of fully-convolutional architectures (FCN) [7, 9, 16], that process the input image directly and can be trained end-to-end, has proven that CNN-based classification tasks","label":"ai"}
{"id":88,"text":"UNET++: A Nested U-Net Architecture for Medical Image Segmentation\nThe authors present UNET++, a deep learning model for medical image segmentation. The proposed architecture extends the original U-Net model with a novel nested block that improves the information flow within the network. Specifically, the nested block consists of a central region with high resolution connections to a low-resolution region that allows for skip connections at both the high and low levels of the network. The authors demonstrate the effectiveness of this approach on several benchmark datasets for medical image segmentation. The results show that UNET++ outperforms state-of-the-art models, achieving state-of-the-art performance on several benchmark tasks. The proposed model is a significant improvement over the original U-Net model, and provides a powerful tool for medical image segmentation.","label":"ai"}
{"id":89,"text":"The application of deep learning to medical image segmentation has been\nhampered due to the lack of abundant pixel-level annotated data. Few-shot\nSemantic Segmentation (FSS) is a promising strategy for breaking the deadlock. However, a high-performing FSS model still requires sufficient pixel-level\nannotated classes for training to avoid overfitting, which leads to its\nperformance bottleneck in medical image segmentation due to the unmet need for\nannotations. Thus, semi-supervised FSS for medical images is accordingly\nproposed to utilize unlabeled data for further performance improvement. Nevertheless, existing semi-supervised FSS methods has two obvious defects: (1)\nneglecting the relationship between the labeled and unlabeled data; (2) using\nunlabeled data directly for end-to-end training leads to degenerated\nrepresentation learning. To address these problems, we propose a novel\nsemi-supervised FSS framework for medical image segmentation. The proposed\nframework employs Poisson learning for modeling data relationship and\npropagating supervision signals, and Spatial Consistency Calibration for\nencouraging the model to learn more coherent representations. In this process,\nunlabeled samples do not involve in end-to-end training, but provide\nsupervisory information for query image segmentation through graph-based\nlearning. We conduct extensive experiments on three medical image segmentation\ndatasets (i.e. ISIC skin lesion segmentation, abdominal organs segmentation for\nMRI and abdominal organs segmentation for CT) to demonstrate the\nstate-of-the-art performance and broad applicability of the proposed framework.","label":"human"}
{"id":90,"text":"This paper formulates an inverse power flow problem which is to infer a nodal\nadmittance matrix (hence the network structure of a power system) from voltage\nand current phasors measured at a number of buses. We show that the admittance\nmatrix can be uniquely identified from a sequence of measurements corresponding\nto different steady states when every node in the system is equipped with a\nmeasurement device, and a Kron-reduced admittance matrix can be determined even\nif some nodes in the system are not monitored (hidden nodes). Furthermore, we\npropose effective algorithms based on graph theory to uncover the actual\nadmittance matrix of radial systems with hidden nodes. We provide theoretical\nguarantees for the recovered admittance matrix and demonstrate that the actual\nadmittance matrix can be fully recovered even from the Kron-reduced admittance\nmatrix under some mild assumptions. Simulations on standard test systems\nconfirm that these algorithms are capable of providing accurate estimates of\nthe admittance matrix from noisy sensor data.","label":"human"}
{"id":91,"text":"This paper proposes a novel method for computing piecewise flat embeddings, which are useful in data clustering and image segmentation tasks. The method uses low-rank matrix factorization and approximation techniques to efficiently compute piecewise flat embeddings for high-dimensional data. The paper also describes some possible applications of piecewise flat embeddings in image processing tasks, such as object detection and image classification. The results show that the proposed method is faster and more accurate than traditional methods for computing piecewise flat embeddings. The paper introduces the piecewise flat embedding, which is useful in image segmentation. The paper describes a novel method for computing piecewise flat embeddings, which uses low-rank matrix factorization and approximation techniques. The method is efficient and works well in image segmentation.","label":"ai"}
{"id":92,"text":"Unpaired image-to-image translation is the problem of mapping an image in the\nsource domain to one in the target domain, without requiring corresponding\nimage pairs. To ensure the translated images are realistically plausible,\nrecent works, such as Cycle-GAN, demands this mapping to be invertible. While,\nthis requirement demonstrates promising results when the domains are unimodal,\nits performance is unpredictable in a multi-modal scenario such as in an image\nsegmentation task. This is because, invertibility does not necessarily enforce\nsemantic correctness. To this end, we present a semantically-consistent GAN\nframework, dubbed Sem-GAN, in which the semantics are defined by the class\nidentities of image segments in the source domain as produced by a semantic\nsegmentation algorithm. Our proposed framework includes consistency constraints\non the translation task that, together with the GAN loss and the\ncycle-constraints, enforces that the images when translated will inherit the\nappearances of the target domain, while (approximately) maintaining their\nidentities from the source domain. We present experiments on several\nimage-to-image translation tasks and demonstrate that Sem-GAN improves the\nquality of the translated images significantly, sometimes by more than 20% on\nthe FCN score. Further, we show that semantic segmentation models, trained with\nsynthetic images translated via Sem-GAN, leads to significantly better\nsegmentation results than other variants.","label":"human"}
{"id":93,"text":"The Pyramid Medical Transformer is a novel deep learning model designed specifically for medical image segmentation. This approach leverages the strengths of both pyramidal and transformer architectures to improve accuracy, efficiency, and robustness in this critical task. The pyramidal component allows for hierarchical feature extraction by processing images at multiple scales simultaneously, while the transformer enables parallel processing and attention mechanisms that enhance information flow between regions. By combining these two approaches, our model can effectively capture local and global patterns in medical images, leading to improved performance on various benchmark datasets. Experimental results demonstrate significant improvements over state-of-the-art methods, achieving competitive accuracy with reduced computational resources. Furthermore, the modular design of the Pyramid Medical Transformer makes it easily adaptable to different imaging modalities and applications, positioning it as a versatile tool for advancing medical research and clinical practice.","label":"ai"}
{"id":94,"text":"The length of an s-increasing sequence of r-tuples is a problem that arises in various fields such as computer science, mathematics, and statistics. In this paper, we study the length of an s-increasing sequence of r-tuples, where s is a positive integer and r is a non-negative integer. We first define the concept of an s-increasing sequence of r-tuples and provide some basic properties. Then, we present some algorithms to find the length of an s-increasing sequence of r-tuples. We also prove some bounds on the length of an s-increasing sequence of r-tuples. Finally, we discuss some applications of our results in various fields.","label":"ai"}
{"id":95,"text":"We present MBIS (Multivariate Bayesian Image Segmentation tool), a clustering\ntool based on the mixture of multivariate normal distributions model. MBIS\nsupports multi-channel bias field correction based on a B-spline model. A\nsecond methodological novelty is the inclusion of graph-cuts optimization for\nthe stationary anisotropic hidden Markov random field model. Along with MBIS,\nwe release an evaluation framework that contains three different experiments on\nmulti-site data. We first validate the accuracy of segmentation and the\nestimated bias field for each channel. MBIS outperforms a widely used\nsegmentation tool in a cross-comparison evaluation. The second experiment\ndemonstrates the robustness of results on atlas-free segmentation of two image\nsets from scan-rescan protocols on 21 healthy subjects. Multivariate\nsegmentation is more replicable than the monospectral counterpart on\nT1-weighted images. Finally, we provide a third experiment to illustrate how\nMBIS can be used in a large-scale study of tissue volume change with increasing\nage in 584 healthy subjects. This last result is meaningful as multivariate\nsegmentation performs robustly without the need for prior knowledge","label":"human"}
{"id":96,"text":"Encoder-decoder architectures are widely adopted for medical image\nsegmentation tasks. With the lateral skip connection, the models can obtain and\nfuse both semantic and resolution information in deep layers to achieve more\naccurate segmentation performance. However, in many applications (e.g., blurry\nboundary images), these models often cannot precisely locate complex boundaries\nand segment tiny isolated parts. To solve this challenging problem, we firstly\nanalyze why simple skip connections are not enough to help accurately locate\nindistinct boundaries and argue that it is due to the fuzzy information in the\nskip connection provided in the encoder layers. Then we propose a\nsemantic-guided encoder feature learning strategy to learn both high resolution\nand rich semantic encoder features so that we can more accurately locate the\nblurry boundaries, which can also enhance the network by selectively learning\ndiscriminative features. Besides, we further propose a soft contour constraint\nmechanism to model the blurry boundary detection. Experimental results on real\nclinical datasets show that our proposed method can achieve state-of-the-art\nsegmentation accuracy, especially for the blurry regions. Further analysis also\nindicates that our proposed network components indeed contribute to the\nimprovement of performance. Experiments on additional datasets validate the\ngeneralization ability of our proposed method.","label":"human"}
{"id":97,"text":"The field of object detection has seen tremendous progress in recent years, with deep learning methods playing a pivotal role. However, efficient initialization of clusters is still a challenge that hinders accurate and real-time performance. This paper presents a novel deep learning object detection method that addresses this problem by utilizing convolutional neural networks to identify initial clustering candidates based on their spatial relationships within images. Our approach uses multiple scales of feature maps to generate candidate pairs, which are then scored using attention mechanisms. We evaluate our proposed method on several benchmark datasets and demonstrate significant improvement over existing state-of-the-art methods. Moreover, our method shows superior performance in terms of both accuracy and runtime. Overall, our work provides a valuable contribution towards building more efficient and effective object detection systems.","label":"ai"}
{"id":98,"text":"The paper presents a novel method for camera-trap image segmentation using multi-layer robust principal component analysis (MPCA). The proposed approach involves extracting features from multiple layers of the image, where each layer captures different characteristics of the image. These features are then fed into a robust version of principal component analysis (PCA), which reduces the dimensionality of the feature space and identifies the most relevant features for segmenting the image. The multi-layer robust PCA method is applied to camera-trap images of animals to segment them into foreground and background regions. The results of the proposed method compare favorably with existing methods in terms of accuracy and speed. Overall, the paper demonstrates a new and efficient approach for segmenting camera-trap images using a robust extension of principal component analysis.","label":"ai"}
{"id":99,"text":"This paper presents a novel approach to ranking response surfaces using deep learning techniques. The proposed method is applied to optimal stopping problems, where the goal is to determine the optimal time to stop a process in order to maximize a reward. The response surface is a function that describes the expected reward as a function of the stopping time. The proposed method uses a deep neural network to learn the response surface and rank it based on its expected reward. The results show that the proposed method outperforms traditional methods for ranking response surfaces and can be applied to a wide range of optimal stopping problems.","label":"ai"}
{"id":100,"text":"Let $X$ be a projective variety (possibly singular) over an algebraically\nclosed field of any characteristic and $\\mathcal{F}$ be a coherent sheaf. In\nthis article, we define the determinant of $\\mathcal{F}$ such that it agrees\nwith the classical definition of determinant in the case when $X$ is\nnon-singular. We study how the Hilbert polynomial of the determinant varies in\nfamilies of singular varieties. Consider a singular family such that every\nfiber is a normal, projective variety. Unlike in the case when the family is\nsmooth, the Hilbert polynomial of the determinant does not remain constant in\nsingular families. However, we show that it exhibits an upper semi-continuous\nbehaviour. Using this we give a determinant morphism defined over flat families\nof coherent sheaves. This morphism coincides with the classical determinant\nmorphism in the smooth case. Finally, we give applications of our results to\nmoduli spaces of semi-stable sheaves on $X$ and to Hilbert schemes of curves.","label":"human"}
{"id":101,"text":"We consider a single component reaction-diffusion equation in one dimension\nwith bistable nonlinearity and a nonlocal space-fractional diffusion operator\nof Riesz-Feller type. Our main result shows the existence, uniqueness (up to\ntranslations) and stability of a traveling wave solution connecting two stable\nhomogeneous steady states. In particular, we provide an extension to classical\nresults on traveling wave solutions involving local diffusion. This extension\nto evolution equations with Riesz-Feller operators requires several technical\nsteps. These steps are based upon an integral representation for Riesz-Feller\noperators, a comparison principle, regularity theory for space-fractional\ndiffusion equations, and control of the far-field behavior.","label":"human"}
{"id":102,"text":"Face mask extraction is a crucial task in various applications such as surveillance, healthcare, and augmented reality. In this study, we propose an efficient method for face mask extraction in video sequences using deep learning techniques. Our approach involves training a convolutional neural network (CNN) to predict the probability of each pixel belonging to a face mask or background. We use a combination of supervised and unsupervised learning strategies to improve the accuracy of our model. The proposed method has been evaluated on several benchmark datasets, and the results demonstrate its effectiveness in extracting face masks from dynamic video sequences with high precision and recall rates. Overall, our work contributes significantly to the field of computer vision by providing a robust and reliable solution for face mask extraction in video sequences.","label":"ai"}
{"id":103,"text":"The paper investigates Jorgensen's inequality, which is a fundamental result in the theory of free groups. Specifically, it focuses on its application to purely loxodromic 2-generator free Kleinian groups, which are important objects of study in geometric group theory. The authors prove that if $G$ is such a group with boundary $\\partial G$, then there exists an element $g\\in G$ satisfying Jorgensen's inequality: $|{\\rm Tr}(g)|>|{\\rm det}(g)|$. They also provide examples of groups where this inequality holds strictly. This work contributes to our understanding of the properties and structure of these groups, and has implications for other areas of mathematics, including topology and dynamical systems.","label":"ai"}
{"id":104,"text":"The paper presents a rate optimal multiple testing procedure for high-dimensional regression models. The proposed procedure achieves optimal control over the false discovery rate by leveraging the correlations among the regression coefficients. The authors derive an explicit expression for the optimal multiple testing threshold that balances the trade-off between type I and type II errors, and establish the asymptotic distribution of the rejection regions. Numerical simulations and real-world examples are presented to demonstrating the effectiveness of the proposed procedure in identifying relevant predictors in high-dimensional regression models.","label":"ai"}
{"id":105,"text":"Coupling the Maxwell tensor to the Riemann-Christoffel curvature tensor is\nshown to lead to a geometricized theory of electrodynamics. While this\ngeometricized theory leads directly to the classical Maxwell equations, it also\nextends their interpretation by giving charge density and mass density, and the\nfour-velocity that describes their motion geometric definitions. These\ngeometric definitions are reminiscent of General Relativity's interpretation of\nmass in terms of the scalar curvature R and hint at the emergence of gravity. The gravitational theory that does emerge is shown to be equivalent to\nEinstein's General Relativity augmented by an energy-momentum tensor term that\nmimics the properties of dark matter and\/or dark energy. In summary, the\nproposed geometrization of the Maxwell tensor puts both electromagnetic and\ngravitational phenomena on an equal footing with both being tied to the\ncurvature of space-time. Using specific solutions to the proposed theory, the\nunification brought to electromagnetic and gravitational phenomena, as well as\nthe relationship of those solutions to the corresponding solutions of the\nclassical Maxwell and Einstein field equations are compared.","label":"human"}
{"id":106,"text":"Image segmentation is the process of dividing an image into multiple segments based on their properties, such as color, texture, or depth. In this study, we propose a novel approach to image segmentation based on the histogram of depth, which is a statistical representation of the distribution of depth values within an image. Our method uses a combination of thresholding and clustering to extract meaningful segmentation results from the depth histogram. We evaluate the performance of our algorithm on several benchmark datasets and show that it outperforms other state-of-the-art methods in terms of accuracy and speed. Furthermore, we demonstrate an application of our image segmentation technique in the field of driver distraction detection, where we use it to segment the driver's face and other objects in the presence of distracting stimuli. Our results show that our approach is robust to various lighting conditions and can accurately identify the driver's face even when it is partially occluded or covered by distracting objects. Overall, our study contributes to the development of robust and efficient image segmentation techniques that can be applied in a wide range of applications.","label":"ai"}
{"id":107,"text":"The Normalized Cut (NCut) objective function, widely used in data clustering\nand image segmentation, quantifies the cost of graph partitioning in a way that\nbiases clusters or segments that are balanced towards having lower values than\nunbalanced partitionings. However, this bias is so strong that it avoids any\nsingleton partitions, even when vertices are very weakly connected to the rest\nof the graph. Motivated by the B\\\"uhler-Hein family of balanced cut costs, we\npropose the family of Compassionately Conservative Balanced (CCB) Cut costs,\nwhich are indexed by a parameter that can be used to strike a compromise\nbetween the desire to avoid too many singleton partitions and the notion that\nall partitions should be balanced. We show that CCB-Cut minimization can be\nrelaxed into an orthogonally constrained $\\ell_{\\tau}$-minimization problem\nthat coincides with the problem of computing Piecewise Flat Embeddings (PFE)\nfor one particular index value, and we present an algorithm for solving the\nrelaxed problem by iteratively minimizing a sequence of reweighted Rayleigh\nquotients (IRRQ). Using images from the BSDS500 database, we show that image\nsegmentation based on CCB-Cut minimization provides better accuracy with\nrespect to ground truth and greater variability in region size than NCut-based\nimage segmentation.","label":"human"}
{"id":108,"text":"Bi2Se3 is theoretically predicted1 2and experimentally observed2,3 to be a\nthree dimensional topological insulator. For possible applications, it is\nimportant to understand the electronic structure of the planar device. In this\nwork, thickness dependent band structure of molecular beam epitaxy grown\nultrathin films of Bi2Se3 is investigated by in situ angle-resolved\nphotoemission spectroscopy. An energy gap is observed for the first time in the\ntopologically protected metallic surface states of bulk Bi2Se3 below the\nthickness of six quintuple layers, due to the coupling between the surface\nstates from two opposite surfaces of the Bi2Se3 film. The gapped surface states\nexhibit sizable Rashba-type spin-orbit splitting, due to breaking of structural\ninversion symmetry induced by SiC substrate. The spin-splitting can be\ncontrolled by tuning the potential difference between the two surfaces.","label":"human"}
{"id":109,"text":"Our goal is to settle the following faded problem, {\\sf The Jacobian\nfollowing form: {\\sf The Generalized Jacobian Conjecture $(GJC)$~:} {\\it Let\n$\\varphi: S \\rightarrow T$ be an unramified homomorphism of Noetherian domains\nwith $T^\\times = \\varphi(S^\\times)$. Assume that $T$ is factorial and that $S$\nis a simply connected normal domain. Then $\\varphi$ is an isomorphism.} We\nsettle Conjecture $(GJC)$, which resolves $(JC_n)$ as a corollary. To settle\n$(GJC)$, we show the following result on Krull domains with some conditions. {\\sf Theorem:} {\\it Let $R$ be a Krull domain domain and let $\\Delta_1$ and\n$\\Delta_2$ is a finite set, that $R_1$ is factorial and that $R\\hookrightarrow","label":"human"}
{"id":110,"text":"We propose a method to classify cardiac pathology based on a novel approach\nto extract image derived features to characterize the shape and motion of the\nheart. An original semi-supervised learning procedure, which makes efficient\nuse of a large amount of non-segmented images and a small amount of images\nsegmented manually by experts, is developed to generate pixel-wise apparent\nflow between two time points of a 2D+t cine MRI image sequence. Combining the\napparent flow maps and cardiac segmentation masks, we obtain a local apparent\nflow corresponding to the 2D motion of myocardium and ventricular cavities. This leads to the generation of time series of the radius and thickness of\nmyocardial segments to represent cardiac motion. These time series of motion\nfeatures are reliable and explainable characteristics of pathological cardiac\nmotion. Furthermore, they are combined with shape-related features to classify\ncardiac pathologies. Using only nine feature values as input, we propose an\nexplainable, simple and flexible model for pathology classification. On ACDC\ntraining set and testing set, the model achieves 95% and 94% respectively as\nclassification accuracy. Its performance is hence comparable to that of the\nstate-of-the-art. Comparison with various other models is performed to outline\nsome advantages of our model.","label":"human"}
{"id":111,"text":"Cache coherence protocols based on self-invalidation and self-downgrade have\nrecently seen increased popularity due to their simplicity, potential\nperformance efficiency, and low energy consumption. However, such protocols\nresult in memory instruction reordering, thus causing extra program behaviors\nthat are often not intended by the programmers. We propose a novel formal model\nthat captures the semantics of programs running under such protocols, and\nfeatures a set of fences that interact with the coherence layer. Using the\nmodel, we design an algorithm to analyze the reachability and check whether a\nprogram satisfies a given safety property with the current set of fences. We\ndescribe a method for insertion of optimal sets of fences that ensure\ncorrectness of the program under such protocols. The method relies on a\ncounter-example guided fence insertion procedure. One feature of our method is\nthat it can handle a variety of fences (with different costs). This diversity\nmakes optimization more difficult since one has to optimize the total cost of\nthe inserted fences, rather than just their number. To demonstrate the strength\nof our approach, we have implemented a prototype and run it on a wide range of\nexamples and benchmarks. We have also, using simulation, evaluated the\nperformance of the resulting fenced programs.","label":"human"}
{"id":112,"text":"Accurate segmentation of the optic disc (OD) and cup (OC)in fundus images\nfrom different datasets is critical for glaucoma disease screening. The\ncross-domain discrepancy (domain shift) hinders the generalization of deep\nneural networks to work on different domain datasets.In this work, we present\nan unsupervised domain adaptation framework,called Boundary and Entropy-driven\nAdversarial Learning (BEAL), to improve the OD and OC segmentation performance,\nespecially on the ambiguous boundary regions. In particular, our proposed BEAL\nframe-work utilizes the adversarial learning to encourage the boundary\nprediction and mask probability entropy map (uncertainty map) of the target\ndomain to be similar to the source ones, generating more accurate boundaries\nand suppressing the high uncertainty predictions of OD and OC segmentation. We\nevaluate the proposed BEAL framework on two public retinal fundus image\ndatasets (Drishti-GS and RIM-ONE-r3), and the experiment results demonstrate\nthat our method outperforms the state-of-the-art unsupervised domain adaptation\nmethods. Codes will be available at https:\/\/github.com\/EmmaW8\/BEAL.","label":"human"}
{"id":113,"text":"We have extended classical pattern avoidance to a new structure: multiple\ntask-precedence posets whose Hasse diagrams have three levels, which we will\ncall diamonds. The vertices of each diamond are assigned labels which are\ncompatible with the poset. A corresponding permutation is formed by reading\nthese labels by increasing levels, and then from left to right. We used Sage to\nform enumerative conjectures for the associated permutations avoiding\ncollections of patterns of length three, which we then proved. We have\ndiscovered a bijection between diamonds avoiding 132 and certain generalized\nDyck paths. We have also found the generating function for descents, and\ntherefore the number of avoiders, in these permutations for the majority of\ncollections of patterns of length three. An interesting application of this\nwork (and the motivating example) can be found when task-precedence posets\nrepresent warehouse package fulfillment by robots, in which case avoidance of\nboth 231 and 321 ensures we never stack two heavier packages on top of a\nlighter package.","label":"human"}
{"id":114,"text":"Deep convolutional neural networks have achieved remarkable progress on a\nvariety of medical image computing tasks. A common problem when applying\nsupervised deep learning methods to medical images is the lack of labeled data,\nwhich is very expensive and time-consuming to be collected. In this paper, we\npresent a novel semi-supervised method for medical image segmentation, where\nthe network is optimized by the weighted combination of a common supervised\nloss for labeled inputs only and a regularization loss for both labeled and\nunlabeled data. To utilize the unlabeled data, our method encourages the\nconsistent predictions of the network-in-training for the same input under\ndifferent regularizations. Aiming for the semi-supervised segmentation problem,\nwe enhance the effect of regularization for pixel-level predictions by\nintroducing a transformation, including rotation and flipping, consistent\nscheme in our self-ensembling model. With the aim of semi-supervised\nsegmentation tasks, we introduce a transformation consistent strategy in our\nself-ensembling model to enhance the regularization effect for pixel-level\npredictions. We have extensively validated the proposed semi-supervised method\non three typical yet challenging medical image segmentation tasks: (i) skin\nlesion segmentation from dermoscopy images on International Skin Imaging\nCollaboration (ISIC) 2017 dataset, (ii) optic disc segmentation from fundus\nimages on Retinal Fundus Glaucoma Challenge (REFUGE) dataset, and (iii) liver\nsegmentation from volumetric CT scans on Liver Tumor Segmentation Challenge\n(LiTS) dataset. Compared to the state-of-the-arts, our proposed method shows\nsuperior segmentation performance on challenging 2D\/3D medical images,\ndemonstrating the effectiveness of our semi-supervised method for medical image\nsegmentation.","label":"human"}
{"id":115,"text":"The abstract of the academic paper titled \"A common approach to three open problems in number theory\" would likely describe a new method or technique that can be applied to solve multiple unsolved problems in the field of number theory. It may outline the main ideas and results of the study, highlighting their significance and potential impact on the field. The abstract should also include relevant keywords and citations to other related work.","label":"ai"}
{"id":116,"text":"Producing manual, pixel-accurate, image segmentation labels is tedious and\ntime-consuming. This is often a rate-limiting factor when large amounts of\nlabeled images are required, such as for training deep convolutional networks\nfor instrument-background segmentation in surgical scenes. No large datasets\ncomparable to industry standards in the computer vision community are available\nfor this task. To circumvent this problem, we propose to automate the creation\nof a realistic training dataset by exploiting techniques stemming from special\neffects and harnessing them to target training performance rather than visual\nappeal. Foreground data is captured by placing sample surgical instruments over\na chroma key (a.k.a. green screen) in a controlled environment, thereby making\nextraction of the relevant image segment straightforward. Multiple lighting\nconditions and viewpoints can be captured and introduced in the simulation by\nmoving the instruments and camera and modulating the light source. Background\ndata is captured by collecting videos that do not contain instruments. In the\nabsence of pre-existing instrument-free background videos, minimal labeling\neffort is required, just to select frames that do not contain surgical\ninstruments from videos of surgical interventions freely available online. We\ncompare different methods to blend instruments over tissue and propose a novel\ndata augmentation approach that takes advantage of the plurality of options. We\nshow that by training a vanilla U-Net on semi-synthetic data only and applying\na simple post-processing, we are able to match the results of the same network\ntrained on a publicly available manually labeled real dataset.","label":"human"}
{"id":117,"text":"We present a simple method to solve spherical harmonics moment systems, such\nas the the time-dependent $P_N$ and $SP_N$ equations, of radiative transfer. The method, which works for arbitrary moment order $N$, makes use of the\nspecific coupling between the moments in the $P_N$ equations. This coupling\nnaturally induces staggered grids in space and time, which in turn give rise to\na canonical, second-order accurate finite difference scheme. While the scheme\ndoes not possess TVD or realizability limiters, its simplicity allows for a\nvery efficient implementation in Matlab. We present several test cases, some of\nwhich demonstrate that the code solves problems with ten million degrees of\nfreedom in space, angle, and time within a few seconds. The code for the\nnumerical scheme, called StaRMAP (Staggered grid Radiation Moment\nApproximation), along with files for all presented test cases, can be\ndownloaded so that all results can be reproduced by the reader.","label":"human"}
{"id":118,"text":"In supervised learning for medical image analysis, sample selection\nmethodologies are fundamental to attain optimum system performance promptly and\nwith minimal expert interactions (e.g. label querying in an active learning\nsetup). In this paper we propose a novel sample selection methodology based on\ndeep features leveraging information contained in interpretability saliency\nmaps. In the absence of ground truth labels for informative samples, we use a\nnovel self supervised learning based approach for training a classifier that\nlearns to identify the most informative sample in a given batch of images. We\ndemonstrate the benefits of the proposed approach, termed\nInterpretability-Driven Sample Selection (IDEAL), in an active learning setup\naimed at lung disease classification and histopathology image segmentation. We\nanalyze three different approaches to determine sample informativeness from\ninterpretability saliency maps: (i) an observational model stemming from\nfindings on previous uncertainty-based sample selection approaches, (ii) a\nradiomics-based model, and (iii) a novel data-driven self-supervised approach. We compare IDEAL to other baselines using the publicly available NIH chest\nX-ray dataset for lung disease classification, and a public histopathology\nsegmentation dataset (GLaS), demonstrating the potential of using\ninterpretability information for sample selection in active learning systems. Results show our proposed self supervised approach outperforms other approaches\nin selecting informative samples leading to state of the art performance with\nfewer samples.","label":"human"}
{"id":119,"text":"We present a novel region based active learning method for semantic image\nsegmentation, called MetaBox+. For acquisition, we train a meta regression\nmodel to estimate the segment-wise Intersection over Union (IoU) of each\npredicted segment of unlabeled images. This can be understood as an estimation\nof segment-wise prediction quality. Queried regions are supposed to minimize to\ncompeting targets, i.e., low predicted IoU values \/ segmentation quality and\nlow estimated annotation costs. For estimating the latter we propose a simple\nbut practical method for annotation cost estimation. We compare our method to\nentropy based methods, where we consider the entropy as uncertainty of the\nprediction. The comparison and analysis of the results provide insights into\nannotation costs as well as robustness and variance of the methods. Numerical\nexperiments conducted with two different networks on the Cityscapes dataset\nclearly demonstrate a reduction of annotation effort compared to random\nacquisition. Noteworthily, we achieve 95%of the mean Intersection over Union\n(mIoU), using MetaBox+ compared to when training with the full dataset, with","label":"human"}
{"id":120,"text":"> We introduce an innovative approach to semi-supervised medical image segmentation to address an important open problem in computational medicine, where there are limited datasets with pixel level ground truth data and yet manual delineations by doctors on millions of slices exist. Semi-supervised learning methods can take advantage over fully supervised ones when only scarce labeled training examples are available but large amounts of unlabelled information are accessible at hand. In this paper we introduce the first method which effectively uses this additional information directly incorporated into its architecture and learns a consistent model of both tasks (image classification vs segmentation) by means of dual pathways. More specifically, our network simultaneously predicts labels between pixels according to their location within the images while distinguishing them based on similar patches embedded in each other via graph convolutional neural networks layers sharing weights. This way we avoid errors due to misclassification as well as improve discrimination of overlapping regions when segmenting multiple objects. We show that this duality improves overall performance on several publicly available medical image datasets. Furthermore, when no prior knowledge about the expected number or ratio of objects was given within the dataset our new class balancing method increased results by 10% compared to existing semi-supervised approaches even without fine tuned regularization hyperparameters thus providing better generalizability in a realworld setting.","label":"ai"}
{"id":121,"text":"We address the problem of segmenting 3D multi-modal medical images in\nscenarios where very few labeled examples are available for training. Leveraging the recent success of adversarial learning for semi-supervised\nsegmentation, we propose a novel method based on Generative Adversarial\nNetworks (GANs) to train a segmentation model with both labeled and unlabeled\nimages. The proposed method prevents over-fitting by learning to discriminate\nbetween true and fake patches obtained by a generator network. Our work extends\ncurrent adversarial learning approaches, which focus on 2D single-modality\nimages, to the more challenging context of 3D volumes of multiple modalities. The proposed method is evaluated on the problem of segmenting brain MRI from\nthe iSEG-2017 and MRBrainS 2013 datasets. Significant performance improvement\nis reported, compared to state-of-art segmentation networks trained in a\nfully-supervised manner. In addition, our work presents a comprehensive\nanalysis of different GAN architectures for semi-supervised segmentation,\nshowing recent techniques like feature matching to yield a higher performance\nthan conventional adversarial training approaches. Our code is publicly\navailable at https:\/\/github.com\/arnab39\/FewShot_GAN-Unet3D","label":"human"}
{"id":122,"text":"We numerically demonstrate the formation of carrier field shocks in various\ndispersive media for a wide variety of input conditions using two different\nelectric field propagation models. In addition, an investigation of the impact\nof numerous physical effects on carrier wave shock is performed. It is shown\nthat in many cases a field shock is essentially unavoidable and therefore\nextremely important in the propagation of intense long wavelength pulses in\nweakly dispersive nonlinear media such as noble gases, air, and single-crystal\ndiamond. The results presented here are expected to have a significant impact\nin the field of ultrashort nonlinear optics, attosecond pulse generation, and\nwavepacket synthesis where the use of mid-IR wavelengths is becoming\nincreasingly more important.","label":"human"}
{"id":123,"text":"In recent years, weakly supervised semantic segmentation, which involves assigning semantic labels to pixels in an image with minimal human labeling, has gained significant attention in the field of computer vision. In this paper, we propose a novel method for harvesting useful information from captions to improve weakly supervised semantic segmentation. Specifically, we develop an approach that combines the strengths of both image-level and caption-level label information to enhance semantic segmentation performance. We use deep learning to learn a mapping between image regions and their corresponding words in captions. We then use this mapping to select the most informative words for each image region, and assign them to the corresponding pixels as additional weak supervision. Our experiments show that our approach achieves state-of-the-art results on several benchmark datasets, with minimal human labeling effort.","label":"ai"}
{"id":124,"text":"This paper is concerned with parabolic gradient systems of the form \\[\nu_t=-\\nabla V (u) + u_{xx}\\,, \\] where the spatial domain is the whole real\nline, the state variable $u$ is multidimensional, and the potential $V$ is\ncoercive at infinity. For such systems, under generic assumptions on the\npotential, the asymptotic behaviour of every bistable solution (that is, every\nsolution close at both ends of space to stable homogeneous equilibria) is\ndescribed. Every such solution approaches, far to the left in space a stacked\nfamily of bistable fronts travelling to the left, far to the right in space a\nstacked family of bistable fronts travelling to the right, and in between a\npattern of profiles of stationary solutions homoclinic or heteroclinic to\nstable homogeneous equilibria, going slowly away from one another. This result\npushes one step further the program initiated in the late seventies by Fife and\nMcLeod about the global asymptotic behaviour of bistable solutions, by\nextending their results to the case of systems. In the absence of maximum\nprinciple, the arguments are purely variational, and call upon previous results\nobtained in companion papers.","label":"human"}
{"id":125,"text":"We summarize the foliation approach to ${\\cal N}=1$ compactifications of\neleven-dimensional supergravity on eight-manifolds $M$ down to $\\mathrm{AdS}_3$\nspaces for the case when the internal part $\\xi$ of the supersymmetry generator\nis chiral on some proper subset ${\\cal W}$ of $M$. In this case, a topological\nno-go theorem implies that the complement $M\\setminus {\\cal W}$ must be a dense\nopen subset, while $M$ admits a singular foliation ${\\bar {\\cal F}}$ (in the\nsense of Haefliger) which is defined by a closed one-form $\\boldsymbol{\\omega}$\nand is endowed with a longitudinal $G_2$ structure. The geometry of this\nfoliation is determined by the supersymmetry conditions. We also describe the\ntopology of ${\\bar {\\cal F}}$ in the case when $\\boldsymbol{\\omega}$ is a Morse\nform.","label":"human"}
{"id":126,"text":"Convolutional neural networks (CNNs) have led to significant improvements in\ntasks involving semantic segmentation of images. CNNs are vulnerable in the\narea of biomedical image segmentation because of distributional gap between two\nsource and target domains with different data modalities which leads to domain\nshift. Domain shift makes data annotations in new modalities necessary because\nmodels must be retrained from scratch. Unsupervised domain adaptation (UDA) is\nproposed to adapt a model to new modalities using solely unlabeled target\ndomain data. Common UDA algorithms require access to data points in the source\ndomain which may not be feasible in medical imaging due to privacy concerns. In\nthis work, we develop an algorithm for UDA in a privacy-constrained setting,\nwhere the source domain data is inaccessible. Our idea is based on encoding the\ninformation from the source samples into a prototypical distribution that is\nused as an intermediate distribution for aligning the target domain\ndistribution with the source domain distribution. We demonstrate the\neffectiveness of our algorithm by comparing it to state-of-the-art medical\nimage semantic segmentation approaches on two medical image semantic\nsegmentation datasets.","label":"human"}
{"id":127,"text":"Abstract:\nSemantic segmentation involves assigning predefined pixel-level labels to images. Recent approaches have shown promising results by incorporating contextual information such as object detection and classification using deep learning techniques. However, these methods still suffer from significant limitations due to their limited understanding of image context and its impact on semantics. This work addresses the issue of mining relevant features that capture the relation between pixels and other objects or regions in the image. Specifically, we investigate the use of external image descriptions and temporal context beyond the immediate local image neighborhood to improve semantic segmentation performance. Our approach is based on a novel combination of multi-task and generative models, where each region is predicted conditioned on both the image context and external sources of knowledge. We evaluate our proposed method on public benchmarks and demonstrate significant improvements over state-of-the-art baselines, particularly when analyzing complex videos sequences. Overall, this research represents an initial step towards more realistic and interpretable modeling of visual content.","label":"ai"}
{"id":128,"text":"A b-coloring of a graph is a proper coloring such that every color class\ncontains a vertex that is adjacent to all other color classes. The b-chromatic\nnumber of a graph G, denoted by \\chi_b(G), is the maximum number t such that G\nadmits a b-coloring with t colors. A graph G is called b-continuous if it\nadmits a b-coloring with t colors, for every t = \\chi(G),\\ldots,\\chi_b(G), and\nG, and every induced subgraph H_2 of H_1. We investigate the b-chromatic number of graphs with stability number two. These are exactly the complements of triangle-free graphs, thus including all\ncomplements of bipartite graphs. The main results of this work are the\nfollowing:\n- We characterize the b-colorings of a graph with stability number two in\nterms of matchings with no augmenting paths of length one or three. We derive\nthat graphs with stability number two are b-continuous and b-monotonic. - We prove that it is NP-complete to decide whether the b-chromatic number of\nco-bipartite graph is at most a given threshold. - We describe a polynomial time dynamic programming algorithm to compute the\nb-chromatic number of co-trees. - Extending several previous results, we show that there is a polynomial time\ndynamic programming algorithm for computing the b-chromatic number of\ntree-cographs. Moreover, we show that tree-cographs are b-continuous and\nb-monotonic.","label":"human"}
{"id":129,"text":"One of the main difficulties of optical quantum measurements is the\npresence of thermal noise. A squeezed state of light is known to have\nan enhanced sensitivity to small fluctuations. In this paper, we\nreport on a procedure that allows one to measure the degree of squeezing\nof a coherent state with the only additional resource of a two-mode\nsqueezed vacuum state. The measurement scheme relies on the\ninterference of a bichromatic local oscillator with a coherent state. The\ndifferential photodetection of the signal output is analyzed to extract\nthe squeezed quadratures of the two-mode squeezed vacuum state. I don't understand the part emphasized in red. Could this be a solution to the \"problem of no detection\" for the photons in the zero-point field?","label":"ai"}
{"id":130,"text":"Methods that move towards less supervised scenarios are key for image\nsegmentation, as dense labels demand significant human intervention. Generally,\nthe annotation burden is mitigated by labeling datasets with weaker forms of\nsupervision, e.g. image-level labels or bounding boxes. Another option are\nsemi-supervised settings, that commonly leverage a few strong annotations and a\nhuge number of unlabeled\/weakly-labeled data. In this paper, we revisit\nsemi-supervised segmentation schemes and narrow down significantly the\nannotation budget (in terms of total labeling time of the training set)\ncompared to previous approaches. With a very simple pipeline, we demonstrate\nthat at low annotation budgets, semi-supervised methods outperform by a wide\nmargin weakly-supervised ones for both semantic and instance segmentation. Our\napproach also outperforms previous semi-supervised works at a much reduced\nlabeling cost. We present results for the Pascal VOC benchmark and unify weakly\nand semi-supervised approaches by considering the total annotation budget, thus\nallowing a fairer comparison between methods.","label":"human"}
{"id":131,"text":"The free particle in quantum mechanics in real space is endowed with\nsupersymmetry, which enables a natural extension to complex spectra with a\nbuilt-in parity (P) and time reversal (T) symmetry. It also explains the origin\nof unbroken and broken phases of the PT-symmetry and their relationship with\nthe real and complex eigenvalues respectively, the latter further displaying\nzero-width resonances. This is possible as the extension of the eigenvalue\nproblem to the complex plane enables the incorporation of bound and decaying\nstates in the enlarged Hilbert space. The inherent freedom of modification of\nthe potential without changing the spectra in supersymmetry naturally explains\nthe connection of complex breather solutions of KdV with PT-symmetry and the\nfree particle on the complex plane. Further, non-trivial zero-width resonances\nin the broken PT phase mandate a generalization that is directly connected to\nthe sl(2, R) potential algebra.","label":"human"}
{"id":132,"text":"In this paper, we present a novel approach to quantum chemistry approximations using big data and machine learning techniques. Our proposed method, called the $\\Delta$-machine learning approach, utilizes large datasets of molecular structures and their corresponding energies to train a deep neural network that can predict energy differences between molecules with high accuracy. We demonstrate the effectiveness of our approach by applying it to several benchmark problems in quantum chemistry, including bond dissociation energies, ionization potentials, and electronic structure predictions. Our results show that the $\\Delta$-machine learning approach is able to achieve state-of-the-art performance on these tasks, often surpassing traditional approaches based on classical force fields or density functional theory calculations. Furthermore, we discuss the implications of our work for the development of more accurate and efficient methods for predicting molecular properties from first principles, which could have significant applications in drug discovery, materials science, and other areas of chemical research.","label":"ai"}
{"id":133,"text":"In this article, we examine the behavior of the Riemannian and Hermitian\ncurvature tensors of a Hermitian metric, when one of the curvature tensors\nobeys all the symmetry conditions of the curvature tensor of a K\\\"ahler metric. We will call such metrics G-K\\\"ahler-like or K\\\"ahler-like, for lack of better\nterminologies. Such metrics are always balanced when the manifold is compact,\nso in a way they are more special than balanced metrics, which drew a lot of\nattention in the study of non-K\\\"ahler Calabi-Yau manifolds. In particular we\nderive various formulas on the difference between the Riemannian and Hermitian\ncurvature tensors in terms of the torsion of the Hermitian connection. We\nbelieve that these formulas could lead to further applications in the study of\nHermitian geometry with curvature assumptions.","label":"human"}
{"id":134,"text":"We introduce Segment-Phrase Table (SPT), a large collection of bijective\nassociations between textual phrases and their corresponding segmentations. Leveraging recent progress in object recognition and natural language\nsemantics, we show how we can successfully build a high-quality segment-phrase\ntable using minimal human supervision. More importantly, we demonstrate the\nunique value unleashed by this rich bimodal resource, for both vision as well\nas natural language understanding. First, we show that fine-grained textual\nlabels facilitate contextual reasoning that helps in satisfying semantic\nconstraints across image segments. This feature enables us to achieve\nstate-of-the-art segmentation results on benchmark datasets. Next, we show that\nthe association of high-quality segmentations to textual phrases aids in richer\nsemantic understanding and reasoning of these textual phrases. Leveraging this\nfeature, we motivate the problem of visual entailment and visual paraphrasing,\nand demonstrate its utility on a large dataset.","label":"human"}
{"id":135,"text":"We exhibit a sequence of flat polynomials with coefficients $0,1$. We thus\nget that there exist a sequences of Newman polynomials that are\nLittlewood. In the opposite direction, we prove that the Newman polynomials are\nnot $L^\\alpha$-flat, for $\\alpha \\geq 4$. We further establish that there is a\nconservative, ergodic, $\\sigma$-finite measure preserving transformation with\nsimple Lebesgue spectrum. This answer affirmatively a long-standing problem of\nBanach from the Scottish book. Consequently, we obtain a positive answer to\nMahler's problem in the class of Newman polynomials, and this allows us also to\nanswer a question raised by Bourgain on the supremum of the $L^1$-norm of\n$L^2$-normalized idempotent polynomials.","label":"human"}
{"id":136,"text":"> Deep learning has been widely used in many fields, such as computer vision, natural language processing, speech recognition, etc., due to its excellent performance on various tasks. In recent years, deep learning techniques have also attracted much attention in machine health monitoring (MHM) applications because they can automatically extract features from raw data without human intervention. This survey aims at providing an overview of the application of deep learning methods in MHM systems. Firstly, we introduce some basic concepts about deep learning and MHM. Then, we review existing works that apply deep learning algorithms to different types of MHM problems, including fault detection, diagnosis, prognosis, and maintenance scheduling. Finally, we discuss several challenges and future directions related to this topic.","label":"ai"}
{"id":137,"text":"We extend the Wigner-Weyl-Moyal phase-space formulation of quantum mechanics\nto general curved configuration spaces. The underlying phase space is based on\nthe chosen coordinates of the manifold and their canonically conjugate momenta. The resulting Wigner function displays the axioms of a quasiprobability\ndistribution, and any Weyl-ordered operator gets associated with the\ncorresponding phase-space function, even in the absence of continuous\nsymmetries. The corresponding quantum Liouville equation reduces to the\nclassical curved space Liouville equation in the semiclassical limit. We\ndemonstrate the formalism for a point particle moving on two-dimensional\nmanifolds, such as a paraboloid or the surface of a sphere. The latter\nclarifies the treatment of compact coordinate spaces as well as the relation of\nthe presented phase-space representation to symmetry groups of the\nconfiguration space.","label":"human"}
{"id":138,"text":"The minimal path model based on the Eikonal partial differential equation\n(PDE) has served as a fundamental tool for the applications of image\nsegmentation and boundary detection in the passed three decades. However, the\nexisting minimal paths-based image segmentation approaches commonly rely on the\nimage boundary features, potentially limiting their performance in some\nsituations. In this paper, we introduce a new variational image segmentation\nmodel based on the minimal path framework and the Eikonal PDE, where the\nregion-based functional that defines the homogeneity criteria can be taken into\naccount for estimating the associated geodesic paths. This is done by\nestablishing a geodesic curve interpretation to the region-based active contour\nevolution problem. The image segmentation processing is carried out in an\niterative manner in our approach. A crucial ingredient in each iteration is to\nconstruct an asymmetric Randers geodesic metric using a sufficiently small\nvector field, such that a set of geodesic paths can be tracked from the\ngeodesic distance map which is the solution to an Eikonal PDE. The object\nboundary can be delineated by the concatenation of the final geodesic paths. We\ninvoke the Finsler variant of the fast marching method to estimate the geodesic\ndistance map, yielding an efficient implementation of the proposed Eikonal\nregion-based active contour model. Experimental results on both of the\nsynthetic and real images exhibit that our model indeed achieves encouraging\nsegmentation performance.","label":"human"}
{"id":139,"text":"The paper presents a novel approach to image segmentation using Markov Chain Monte Carlo (MCMC) shape sampling with nonparametric shape priors. The proposed method leverages the advantages of both MCMC and nonparametric shape priors to improve the accuracy and robustness of image segmentation. The MCMC algorithm is used to sample from the posterior distribution of the segmentation parameters, while the nonparametric shape prior is used to guide the sampling process and enforce constraints on the shape of the segmented objects. The paper demonstrates the effectiveness of the proposed method on several benchmark datasets and shows that it outperforms state-of-the-art methods in terms of both accuracy and speed.","label":"ai"}
{"id":140,"text":"This paper gives a geometric interpretation of bordered Heegaard Floer\nhomology for manifolds with torus boundary. If $M$ is such a manifold, we show\nthat the type D structure $\\widehat{\\mathit{CFD}}$ may be viewed as a set of\nimmersed curves decorated with local systems in $\\partial M$. These\ncurves-with-decoration are invariants of the underlying three-manifold up to\nregular homotopy of the curves and isomorphism of the local systems. Given two\nsuch manifolds and a homeomorphism $h$ between the boundary tori, the Heegaard\nFloer homology of the closed manifold obtained by gluing with $h$ is obtained\nfrom the Lagrangian intersection Floer homology of the curve-sets. This\nmachinery has several applications: We establish that the dimension of\n$\\widehat{\\mathit{HF}}$ decreases under a certain class of degree one maps\n(pinches) and we establish that the existence of an essential separating torus\ngives rise to a lower bound on the dimension of $\\widehat{\\mathit{HF}}$. In\nparticular, it follows that a prime rational homology sphere $Y$ with\n$\\widehat{\\mathit{HF}}(Y)<5$ must be geometric. Other results include a new\nproof of Eftekhary's theorem that L-space homology spheres are atoroidal; a\ncomplete characterisation of toroidal L-spaces in terms of gluing data; and a\nproof of a conjecture of Hom, Lidman, and Vafaee on satellite L-space knots.","label":"human"}
{"id":141,"text":"Recent decades have seen the discovery of numerous complex materials. At the\nroot of the complexity underlying many of these materials lies a large number\nof possible contending atomic- and larger-scale configurations and the\nintricate correlations between their constituents. For a detailed\nunderstanding, there is a need for tools that enable the detection of pertinent\nstructures on all spatial and temporal scales. Towards this end, we suggest a\nnew method by invoking ideas from network analysis and information theory. Our\nmethod efficiently identifies basic unit cells and topological defects in\nsystems with low disorder and may analyze general amorphous structures to\nidentify candidate natural structures where a clear definition of order is\nlacking. This general unbiased detection of physical structure does not require\na guess as to which of the system properties should be deemed as important and\nmay constitute a natural point of departure for further analysis. The method\napplies to both static and dynamic systems.","label":"human"}
{"id":142,"text":"We propose a novel locally adaptive learning estimator for enhancing the\ninter- and intra- discriminative capabilities of Deep Neural Networks, which\ncan be used as improved loss layer for semantic image segmentation tasks. Most\nloss layers compute pixel-wise cost between feature maps and ground truths,\nignoring spatial layouts and interactions between neighboring pixels with same\nobject category, and thus networks cannot be effectively sensitive to\nintra-class connections. Stride by stride, our method firstly conducts adaptive\npooling filter operating over predicted feature maps, aiming to merge predicted\ndistributions over a small group of neighboring pixels with same category, and\nthen it computes cost between the merged distribution vector and their category\nlabel. Such design can make groups of neighboring predictions from same\ncategory involved into estimations on predicting correctness with respect to\ntheir category, and hence train networks to be more sensitive to regional\nconnections between adjacent pixels based on their categories. In the\nexperiments on Pascal VOC 2012 segmentation datasets, the consistently improved\nresults show that our proposed approach achieves better segmentation masks\nagainst previous counterparts.","label":"human"}
{"id":143,"text":"Multiple myeloma (MM), a plasma cell cancer, is associated with many health\nchallenges, including damage to the kidney by tubulointerstitial fibrosis. We\ndevelop a mathematical model which captures the qualitative behavior of the\ncell and protein populations involved. Specifically, we model the interaction\nbetween cells in the proximal tubule of the kidney, free light chains, renal\nfibroblasts, and myeloma cells. We analyze the model for steady-state solutions\nto find a mathematically and biologically relevant stable steady-state\nsolution. This foundational model provides a representation of dynamics between\nkey populations in tubulointerstitial fibrosis that demonstrates how these\npopulations interact to affect patient prognosis in patients with MM and renal\nimpairment.","label":"human"}
{"id":144,"text":"We introduce the concept of derivate-based component-trees for images with an\narbitrary number of channels. The approach is a natural extension of the\nclassical component-tree devoted to gray-scale images. The similar structure\nenables the translation of many gray-level image processing techniques based on\nthe component-tree to hyperspectral and color images. As an example\napplication, we present an image segmentation approach that extracts Maximally\nStable Homogeneous Regions (MSHR). The approach very similar to MSER but can be\napplied to images with an arbitrary number of channels. As opposed to MSER, our\napproach implicitly segments regions with are both lighter and darker than\ntheir background for gray-scale images and can be used in OCR applications\nwhere MSER will fail. We introduce a local flooding-based immersion for the\nderivate-based component-tree construction which is linear in the number of\npixels. In the experiments, we show that the runtime scales favorably with an\nincreasing number of channels and may improve algorithms which build on MSER.","label":"human"}
{"id":145,"text":"Normalisation in probability theory turns a subdistribution into a proper\ndistribution. It is a partial operation, since it is undefined for the zero\nsubdistribution. This partiality makes it hard to reason equationally about\nnormalisation. A novel description of normalisation is given as a\nmathematically well-behaved total function. The output of this `hyper'\nnormalisation operation is a distribution of distributions. It improves\nreasoning about normalisation. After developing the basics of this theory of (hyper) normalisation, it is\nput to use in a similarly new description of conditioning, producing a\ndistribution of conditional distributions. This is used to give a clean\nabstract reformulation of refinement in quantitative information flow.","label":"human"}
{"id":146,"text":"Quantum coherence and quantum correlations lie in the center of quantum\ninformation science, since they both are considered as fundamental reasons for\nsignificant features of quantum mechanics different from classical mechanics. We present a group of complementary relations for quantum coherence and quantum\ncorrelations; specifically, we focus on thermal discord and conditional\ninformation in scenarios of multiple measurements. We show that the summation\nof quantum coherence quantified in different bases has a lower bound, resulting\nfrom entropic uncertainty relations with multiple measurements. Similar results\nare also obtained for thermal discord and for post-measurement conditional\ninformation with multiple measurements in a multipartite system. These results\nindicate the general applications of the uncertainty principle to various\nconcepts of quantum information.","label":"human"}
{"id":147,"text":"The classical problem of foam film rupture dynamics has been investigated\nwhen surfaces exhibit very high rigidity due to the presence of specific\nsurfactants. Two new features are reported. First a strong deviation to the\nwell-known Taylor-Culick law is observed. Then, crack-like patterns can be\nvisualized in the film; these patterns are shown to appear at a well defined\ndeformation. The key role of surface active material on these features is\nquantitatively investigated, pointing the importance of surface elasticity to\ndescribe these fast dynamical processes, and thus providing an alternative tool\nto characterize surface elasticity in conditions extremely far from\nequilibrium. The origin of the cracks and their consequences on film rupturing\ndynamics are also discussed.","label":"human"}
{"id":148,"text":"Several supermodular losses have been shown to improve the perceptual quality\nof image segmentation in a discriminative framework such as a structured output\nsupport vector machine (SVM). These loss functions do not necessarily have the\nsame structure as the one used by the segmentation inference algorithm, and in\ngeneral, we may have to resort to generic submodular minimization algorithms\nfor loss augmented inference. Although these come with polynomial time\nguarantees, they are not practical to apply to image scale data. Many\nsupermodular losses come with strong optimization guarantees, but are not\nreadily incorporated in a loss augmented graph cuts procedure. This motivates\nour strategy of employing the alternating direction method of multipliers\n(ADMM) decomposition for loss augmented inference. In doing so, we create a new\nAPI for the structured SVM that separates the maximum a posteriori (MAP)\ninference of the model from the loss augmentation during training. In this way,\nwe gain computational efficiency, making new choices of loss functions\npractical for the first time, while simultaneously making the inference\nalgorithm employed during training closer to the test time procedure. We show\nimprovement both in accuracy and computational performance on the Microsoft\nResearch Grabcut database and a brain structure segmentation task, empirically\nvalidating the use of several supermodular loss functions during training, and\nthe improved computational properties of the proposed ADMM approach over the\nFujishige-Wolfe minimum norm point algorithm.","label":"human"}
{"id":149,"text":"We analyze the response of the Morris-Lecar model to a periodic train of\nshort current pulses in the period-amplitude plane. For a wide parameter range\nencompassing both class 2 and class 3 behavior in Hodgkin's classification\nthere is a multimodal transition between the set of odd modes and the set of\nall modes. It is located between the 2:1 and 3:1 locked-in regions. It is the\nsame dynamic instability as the one discovered earlier in the Hodgkin-Huxley\nmodel and observed experimentally in squid giant axons. It appears\nsimultaneously with the bistability of the states 2:1 and 3:1 in the\nperithreshold regime. These results imply that the multimodal transition may be\na universal property of resonant neurons.","label":"human"}
{"id":150,"text":"The usage of convolutional neural networks (CNNs) for unsupervised image\nsegmentation was investigated in this study. In the proposed approach, label\nprediction and network parameter learning are alternately iterated to meet the\nfollowing criteria: (a) pixels of similar features should be assigned the same\nlabel, (b) spatially continuous pixels should be assigned the same label, and\n(c) the number of unique labels should be large. Although these criteria are\nincompatible, the proposed approach minimizes the combination of similarity\nloss and spatial continuity loss to find a plausible solution of label\nassignment that balances the aforementioned criteria well. The contributions of\nthis study are four-fold. First, we propose a novel end-to-end network of\nunsupervised image segmentation that consists of normalization and an argmax\nfunction for differentiable clustering. Second, we introduce a spatial\ncontinuity loss function that mitigates the limitations of fixed segment\nboundaries possessed by previous work. Third, we present an extension of the\nproposed method for segmentation with scribbles as user input, which showed\nbetter accuracy than existing methods while maintaining efficiency. Finally, we\nintroduce another extension of the proposed method: unseen image segmentation\nby using networks pre-trained with a few reference images without re-training\nthe networks. The effectiveness of the proposed approach was examined on\nseveral benchmark datasets of image segmentation.","label":"human"}
{"id":151,"text":"that do not contain the digit 9, converges to a sum less than 90. The actual\nof 1\/n where n has at most a finite number of 9's is also a convergent series. We show how to compute sums of Irwins' series to high precision. For example,\nexample: the sum of 1\/n where n has exactly 100 zeros is about 10 ln(10) +\nseries is the tiny 1\/googol. Finally, we discuss a class of related series\nwhose summation algorithm has not yet been developed.","label":"human"}
{"id":152,"text":"Semantic Segmentation using deep convolutional neural network pose more\ncomplex challenge for any GPU intensive task. As it has to compute million of\nparameters, it results to huge memory consumption. Moreover, extracting finer\nfeatures and conducting supervised training tends to increase the complexity. With the introduction of Fully Convolutional Neural Network, which uses finer\nstrides and utilizes deconvolutional layers for upsampling, it has been a go to\nfor any image segmentation task. In this paper, we propose two segmentation\narchitecture which not only needs one-third the parameters to compute but also\ngives better accuracy than the similar architectures. The model weights were\ntransferred from the popular neural net like VGG19 and VGG16 which were trained\non Imagenet classification data-set. Then we transform all the fully connected\nlayers to convolutional layers and use dilated convolution for decreasing the\nparameters. Lastly, we add finer strides and attach four skip architectures\nwhich are element-wise summed with the deconvolutional layers in steps. We\ntrain and test on different sparse and fine data-sets like Pascal VOC2012,\nPascal-Context and NYUDv2 and show how better our model performs in this tasks. On the other hand our model has a faster inference time and consumes less\nmemory for training and testing on NVIDIA Pascal GPUs, making it more efficient\nand less memory consuming architecture for pixel-wise segmentation.","label":"human"}
{"id":153,"text":"> Accurate segmentation of medical images is crucial for diagnosis and treatment of patients. These kinds of images require precise identification of objects and structures in various types. Convolutional Neural Networks (CNNs) are the state-of-the-art technique in this regard. These networks have proven their success in various medical imaging applications, especially in semantic segmentation. This success is mainly due to the use of convolution and pooling operations in these networks. However, in real applications, precise segmentation is not always successful in various types of medical images. The main reason for the inability to give better results is due to the loss of the original features in the convolution and pooling operations. > On the other hand, morphological operators can be used as powerful processing tools to handle binary images because of their nonlinearity, adaptive filtering, and high efficiency. In this paper, a morphological operation convolutional layer is used to implement an effective morphological operation in a CNN to enhance the feature representation in the network. This method is named the morphological operation residual block. We introduce a 3D conv3D+morphology operator model called Mor-residual block. The results of a few different tests on 3D medical datasets show the effectiveness of the proposed method on various types of 3D medical images such as microscopic, MR, and computed axial tomography (CT) images, for different applications, including lesion segmentation, biopsy tissue classification, and semantic segmentation. The results show the ability of the modified model to increase the accuracy of segmentation of these types of medical imaging, while also reducing the training time and the number of required parameters. > The dataset introduced in this paper is divided into three categories, including microscopic medical images, which were taken from the Cancer Genome Atlas (TCGA) database containing breast cancer images taken from cancerous and noncancerous specimens (two-category classification), biopsy tissue images, and MR and CT images of a 3D spinal cord dataset. Experimental results","label":"ai"}
{"id":154,"text":"> Abstract: A multiscale discretization framework based on heterogeneous local substructure mesh to construct the finite element bases, and weighted inner product space analysis are introduced to obtain the global asymptotically optimal rates of convergence for high frequency acoustic scattering problem which involve discontinuity interface. In order to avoid spurious modes due to inconsistent finite element approximation across the interfaces, stable multi scale nodal\/superparametric formulation Petrov--Galerkin method based approach with local linear tetrahedral partition refinement (NSPGm) or piecewise polynomial enrichment (PGm), in which, each interior nodal basis function is defined by the union of its constituent unisolvent nodal elements which satisfies the same number and arrangement condition as those required for the standard Galerkin methods, but contains more localized support domain for better separation boundary effect. Both the proposed weakly consistent super parametry NSPGM method and strongly consistant PGm method are able to resolve higher order components near boundaries for smooth solutions via either using general polynomial enrichment technique or through substructure decomposition process under highly nonlinear complex geometries with an error bound scaling inverse logarithmic wavelength. And there are also some preliminary results shown in this presentation at University of Texas at Arlington last year, but you need Flash plugin.","label":"ai"}
{"id":155,"text":"In this work, we study the infinity behavior of K\\\"ahler metrics on toric manifolds. We prove that under certain conditions, the metric at infinity is a well-defined object that describes the topology of the manifold. We then use quantification techniques to show the existence of a family of Riemannian metrics on tropical amoebAs that generalizes previously known metrics. Our main result, which unifies different approaches to this subject, states that if a toric K\\\"ahler metric has nonnegative scalar curvature, then its limit as $r\\rightarrow \\infty$ exists and determines a continuous metric on any tropical amoeba containing it. This opens new avenues for studying the geometry and properties of these objects in both algebraic and topological settings. Keywords: Toric K\\\"ahler metrics, Tropical geometry, Quantum field theory, Amoebas","label":"ai"}
{"id":156,"text":"Transformer, which can benefit from global (long-range) information modeling\nusing self-attention mechanisms, has been successful in natural language\nprocessing and 2D image classification recently. However, both local and global\nfeatures are crucial for dense prediction tasks, especially for 3D medical\nimage segmentation. In this paper, we for the first time exploit Transformer in\n3D CNN for MRI Brain Tumor Segmentation and propose a novel network named\nTransBTS based on the encoder-decoder structure. To capture the local 3D\ncontext information, the encoder first utilizes 3D CNN to extract the\nvolumetric spatial feature maps. Meanwhile, the feature maps are reformed\nelaborately for tokens that are fed into Transformer for global feature\nmodeling. The decoder leverages the features embedded by Transformer and\nperforms progressive upsampling to predict the detailed segmentation map. Extensive experimental results on both BraTS 2019 and 2020 datasets show that\nTransBTS achieves comparable or higher results than previous state-of-the-art\n3D methods for brain tumor segmentation on 3D MRI scans. The source code is","label":"human"}
{"id":157,"text":"Deep neural networks (DNNs) have become increasingly important due to their\nexcellent empirical performance on a wide range of problems. However,\nregularization is generally achieved by indirect means, largely due to the\ncomplex set of functions defined by a network and the difficulty in measuring\nfunction complexity. There exists no method in the literature for additive\nregularization based on a norm of the function, as is classically considered in\nstatistical learning theory. In this work, we propose sampling-based\napproximations to weighted function norms as regularizers for deep neural\nnetworks. We provide, to the best of our knowledge, the first proof in the\nliterature of the NP-hardness of computing function norms of DNNs, motivating\nthe necessity of an approximate approach. We then derive a generalization bound\nfor functions trained with weighted norms and prove that a natural stochastic\noptimization strategy minimizes the bound. Finally, we empirically validate the\nimproved performance of the proposed regularization strategies for both convex\nfunction sets as well as DNNs on real-world classification and image\nsegmentation tasks demonstrating improved performance over weight decay,\ndropout, and batch normalization. Source code will be released at the time of\npublication.","label":"human"}
{"id":158,"text":"This paper describes a fast and accurate semantic image segmentation approach\nthat encodes not only the discriminative features from deep neural networks,\nbut also the high-order context compatibility among adjacent objects as well as\nlow level image features. We formulate the underlying problem as the\nconditional random field that embeds local feature extraction, clique potential\nconstruction, and guided filtering within the same framework, and provide an\nefficient coarse-to-fine solver. At the coarse level, we combine local feature\nrepresentation and context interaction using a deep convolutional network, and\ndirectly learn the interaction from high order cliques with a message passing\nroutine, avoiding time-consuming explicit graph inference for joint probability\ndistribution. At the fine level, we introduce a guided filtering interpretation\nfor the mean field algorithm, and achieve accurate object boundaries with 100+\nfaster than classic learning methods. The two parts are connected and jointly\ntrained in an end-to-end fashion. Experimental results on Pascal VOC 2012\ndataset have shown that the proposed algorithm outperforms the\nstate-of-the-art, and that it achieves the rank 1 performance at the time of\nsubmission, both of which prove the effectiveness of this unified framework for\nsemantic image segmentation.","label":"human"}
{"id":159,"text":"Power-Law Graph Cuts explores the properties and applications of graph cuts that follow a power law distribution. This type of cut, first introduced in the context of community detection in complex networks, has been shown to have significant implications for various fields such as data mining, image segmentation, and natural language processing. The paper reviews existing approaches to identifying power-law graph cuts and discusses their limitations. It then presents new algorithms based on spectral theory and homomorphism groups that improve upon these previous methods. Experimental results demonstrate the effectiveness of the proposed approach, highlighting its ability to accurately identify power-law graph cuts in real-world datasets. The paper concludes by discussing open research directions and potential future applications. Overall, this work contributes valuable insights into the study of graph structures, providing practical tools for identifying important substructures within complex networks.","label":"ai"}
{"id":160,"text":"The paper presents a novel light-weight encoder-decoder based network, CFPNet-M, for real-time segmentation of multimodal biomedical images. The proposed network utilizes a combination of convolutional and fully connected layers to extract features from the input images and generate accurate segmentation masks. The network is designed to be light-weight and efficient, making it suitable for real-time applications. The performance of the proposed network is evaluated on a dataset of multimodal biomedical images, and the results show that it outperforms other state-of-the-art methods in terms of accuracy and speed. Overall, the paper demonstrates the effectiveness of the proposed network for real-time segmentation of multimodal biomedical images.","label":"ai"}
{"id":161,"text":"We study the so-called pinning model, which describes the behavior of a\nMarkov chain interacting with a distinguished state. The interaction depends on\nan external source of randomness, called disorder, which can attract or repel\nthe Markov chain path. We focus on the case when the disorder is heavy-tailed,\nwith infinite mean, while the return times of the Markov chain have a\nstretched-exponential distribution. We prove that the set of times at which the\nMarkov chain visits the distinguished state, suitably rescaled, converges in\ndistribution to a limit set, which depends only on the disorder and on the\ninterplay of the parameters. We also show that there exists a random threshold\nbelow which the limit set is trivial. As a byproduct of our techniques, we\nimprove and complete a result of Auffinger and Louidor on the directed polymer\nin a random environment with heavy tailed disorder.","label":"human"}
{"id":162,"text":"> In this study, we propose an approach to segmenting land use and land cover (LULC) using deep learning techniques on satellite images. We used the UNet architecture as our base model and modified it by adding residual blocks in order to improve its performance. Our proposed method was tested with two different datasets; one dataset consists of 10 classes while the other has only three classes. For both cases, we achieved better results than those obtained by previous studies that have been conducted on similar problems.","label":"ai"}
{"id":163,"text":"In this paper, we consider unsupervised partitioning problems, such as\nclustering, image segmentation, video segmentation and other change-point\ndetection problems. We focus on partitioning problems based explicitly or\nimplicitly on the minimization of Euclidean distortions, which include\nmean-based change-point detection, K-means, spectral clustering and normalized\ncuts. Our main goal is to learn a Mahalanobis metric for these unsupervised\nproblems, leading to feature weighting and\/or selection. This is done in a\nsupervised way by assuming the availability of several potentially partially\nlabelled datasets that share the same metric. We cast the metric learning\nproblem as a large-margin structured prediction problem, with proper definition\nof regularizers and losses, leading to a convex optimization problem which can\nbe solved efficiently with iterative techniques. We provide experiments where\nwe show how learning the metric may significantly improve the partitioning\nperformance in synthetic examples, bioinformatics, video segmentation and image\nsegmentation problems.","label":"human"}
{"id":164,"text":"In recent years, the idea of using morphological operations as networks has\nreceived much attention. Mathematical morphology provides very efficient and\nuseful image processing and image analysis tools based on basic operators like\ndilation and erosion, defined in terms of kernels. Many other morphological\noperations are built up using the dilation and erosion operations. Although the\nlearning of structuring elements such as dilation or erosion using the\nbackpropagation algorithm is not new, the order and the way these morphological\noperations are used is not standard. In this paper, we have theoretically\nanalyzed the use of morphological operations for processing 1D feature vectors\nand shown that this gets extended to the 2D case in a simple manner. Our\ntheoretical results show that a morphological block represents a sum of hinge\nfunctions. Hinge functions are used in many places for classification and\nregression tasks (Breiman (1993)). We have also proved a universal\napproximation theorem -- a stack of two morphological blocks can approximate\nany continuous function over arbitrary compact sets. To experimentally validate\nthe efficacy of this network in real-life applications, we have evaluated its\nperformance on satellite image classification datasets since morphological\noperations are very sensitive to geometrical shapes and structures. We have\nalso shown results on a few tasks like segmentation of blood vessels from\nfundus images, segmentation of lungs from chest x-ray and image dehazing. The\nresults are encouraging and further establishes the potential of morphological\nnetworks.","label":"human"}
{"id":165,"text":"CEREALS is a novel approach to semantic segmentation that utilizes active learning to improve the accuracy of the model while minimizing the amount of labeled data required. The method is designed to be cost-effective and region-based, allowing for efficient and accurate segmentation of large datasets. The paper presents the CEREALS algorithm, which uses a combination of region-based and object-based active learning to select the most informative regions for labeling. The algorithm also incorporates a cost-sensitive approach to labeling, which takes into account the cost of labeling each region. The results of the paper demonstrate the effectiveness of the CEREALS algorithm in improving the accuracy of semantic segmentation models while minimizing the amount of labeled data required.","label":"ai"}
{"id":166,"text":"An important issue with oversampled FIR analysis filter banks (FBs) is to\ndetermine inverse synthesis FBs, when they exist. Given any complex oversampled\nFIR analysis FB, we first provide an algorithm to determine whether there\nexists an inverse FIR synthesis system. We also provide a method to ensure the\nHermitian symmetry property on the synthesis side, which is serviceable to\nprocessing real-valued signals. As an invertible analysis scheme corresponds to\na redundant decomposition, there is no unique inverse FB. Given a particular\nsolution, we parameterize the whole family of inverses through a null space\nprojection. The resulting reduced parameter set simplifies design procedures,\nsince the perfect reconstruction constrained optimization problem is recast as\nan unconstrained optimization problem. The design of optimized synthesis FBs\nbased on time or frequency localization criteria is then investigated, using a\nsimple yet efficient gradient algorithm.","label":"human"}
{"id":167,"text":"\"Purpose: To propose a new multi-task network that enables one-pass prediction of multiple MR brain volumes while exploiting anatomical and contextual cues.\" \"Methods: We use a novel architecture with stacked one-step fully convolutional neural networks (CNNs) that learns to predict multiple volumes jointly. In this network, a residual attention module incorporates anatomical knowledge between adjacent task volumes. Cross-task modules utilize complementary information among neighboring task volumes and capture complex structures and topological relationships that contribute to segmenting tumors. A set of auxiliary branches was added to refine features along prediction pipelines of multiple volumes. Results: We investigated our cross-task networks on two MRI datasets: ISBI (24 subjects) and OASIS (43 subjects). Compared to state-of-the-art approaches, our framework provides consistent improvements across all datasets and across task volumes. Conclusion: We have demonstrated that our cross-task networks facilitate joint prediction of multiple MR brain volumes, while maintaining the ability to discriminate anatomical structures and complex relationships. These features allow the networks to extract task-specific information between neighboring volumes and refine features to provide accurate MR volume segmentation.\" The paper was written by Yun-Hee Kim, Chul-Joong Kim, and Jin Ho Ha. Source: arXiv\nAuthor: Yun-Hee Kim, Chul-Joong Kim, and Jin Ho Ha","label":"ai"}
{"id":168,"text":"- \"The Lowest Partial Moment (LPM) effect was introduced by Zel'dovich and Novikov (ZN) in 1958 to evaluate the nuclear photo-process at high photon energies. The LPM effect describes the decrease of bremsstrahlung emission during the interaction of fast charged particle with matter. The problem is not so well understood for other processes. In earlier works we considered the LPM mechanism for emission of bremsstrahlung photons during the interaction of high energy particles with matter by means of the Schwinger's method of transition amplitudes. The main goal of this work is to derive the factorization formula for the squared two particles bremsstrahlung amplitude. This is a first step in obtaining a factorization formula for four emitted photons amplitude. The derivation of the formula is carried out by means of the Feynman diagram technique. The obtained formula can be used in Monte Carlo simulation of the LPM effect in the sequential emission of high energy photons, when it is important to determine the multiplicity of created particles.\"","label":"ai"}
{"id":169,"text":"Introduction:\nSegmentation is a fundamental task in various computer vision applications such as medical imaging, robotics, and surveillance systems. Traditional deep learning methods require a large amount of labeled training data for segmentation tasks, which is usually time-consuming and expensive. However, in real-world scenarios, the amount of labeled data may be insufficient or not available at all. In such cases, few-shot learning methods have emerged as a promising alternative to traditional deep learning methods. Methods:\nIn this paper, we propose a novel approach for few-shot segmentation using self-guided and cross-guided learning. Our approach leverages the limited labeled data by using the unlabeled data as a guide for learning the semantic boundaries of the objects. We introduce a self-guided training strategy using a modified version of the cross-entropy loss function, which allows the model to learn from the limited labeled data without overfitting. Additionally, we propose a cross-guided learning strategy, which utilizes the learned knowledge from the self-guided training and transfers it to other unrelated tasks with few labeled data. Results:\nWe evaluate our method on the benchmark datasets COCO-Text and ALSCO, which are challenging few-shot segmentation tasks with limited labeled data. The results show that our method outperforms the baseline methods and achieves state-of-the-art performance on both datasets. Conclusion:\nOur proposed approach of self-guided and cross-guided learning is a novel and effective approach for few-shot segmentation tasks, especially in scenarios where the labeled data is insufficient or nonexistent. Our method is a significant contribution to the field of few-shot learning and has the potential for practical applications in various domains.","label":"ai"}
{"id":170,"text":"In this work, we revisit atrous convolution, a powerful tool to explicitly\nadjust filter's field-of-view as well as control the resolution of feature\nresponses computed by Deep Convolutional Neural Networks, in the application of\nsemantic image segmentation. To handle the problem of segmenting objects at\nmultiple scales, we design modules which employ atrous convolution in cascade\nor in parallel to capture multi-scale context by adopting multiple atrous\nrates. Furthermore, we propose to augment our previously proposed Atrous\nSpatial Pyramid Pooling module, which probes convolutional features at multiple\nscales, with image-level features encoding global context and further boost\nperformance. We also elaborate on implementation details and share our\nexperience on training our system. The proposed `DeepLabv3' system\nsignificantly improves over our previous DeepLab versions without DenseCRF\npost-processing and attains comparable performance with other state-of-art\nmodels on the PASCAL VOC 2012 semantic image segmentation benchmark.","label":"human"}
{"id":171,"text":"Abstract: In this work, several image enhancement approaches are evaluated to understand their usefulness as preprocessing steps before color segmentation methods. It turns out that there exist some cases where even simple operations drastically improve the performance of already state-of-the-art methods. We focus mainly on two well-known methods: Otsu's Threshold Selection (OTS) method [1] and Fuzzy C Mean algorithm (FCM). The FCM, originally developed by Jiawei Xie and Qinqing Tong from Nanjing University [2], belongs to an iterative class of clustering methods and aims to minimize the objective function through minimizing between cluster sum of squared errors measure over all of these three color channels RGB instead of each channel separately. The performance improvement can be interpreted in terms of statistical distribution changes obtained after application of various image enhancing techniques which affect the quality of final results.","label":"ai"}
{"id":172,"text":"Training deep fully convolutional neural networks (F-CNNs) for semantic image\nsegmentation requires access to abundant labeled data. While large datasets of\nunlabeled image data are available in medical applications, access to manually\nlabeled data is very limited. We propose to automatically create auxiliary\nlabels on initially unlabeled data with existing tools and to use them for\npre-training. For the subsequent fine-tuning of the network with manually\nlabeled data, we introduce error corrective boosting (ECB), which emphasizes\nparameter updates on classes with lower accuracy. Furthermore, we introduce\nSkipDeconv-Net (SD-Net), a new F-CNN architecture for brain segmentation that\ncombines skip connections with the unpooling strategy for upsampling. The\nSD-Net addresses challenges of severe class imbalance and errors along\nboundaries. With application to whole-brain MRI T1 scan segmentation, we\ngenerate auxiliary labels on a large dataset with FreeSurfer and fine-tune on\ntwo datasets with manual annotations. Our results show that the inclusion of\nauxiliary labels and ECB yields significant improvements. SD-Net segments a 3D\nscan in 7 secs in comparison to 30 hours for the closest multi-atlas\nsegmentation method, while reaching similar performance. It also outperforms\nthe latest state-of-the-art F-CNN models.","label":"human"}
{"id":173,"text":"Learning-based approaches for semantic segmentation have two inherent\nchallenges. First, acquiring pixel-wise labels is expensive and time-consuming. Second, realistic segmentation datasets are highly unbalanced: some categories\nare much more abundant than others, biasing the performance to the most\nrepresented ones. In this paper, we are interested in focusing human labelling\neffort on a small subset of a larger pool of data, minimizing this effort while\nmaximizing performance of a segmentation model on a hold-out set. We present a\nnew active learning strategy for semantic segmentation based on deep\nreinforcement learning (RL). An agent learns a policy to select a subset of\nsmall informative image regions -- opposed to entire images -- to be labeled,\nfrom a pool of unlabeled data. The region selection decision is made based on\npredictions and uncertainties of the segmentation model being trained. Our\nmethod proposes a new modification of the deep Q-network (DQN) formulation for\nactive learning, adapting it to the large-scale nature of semantic segmentation\nproblems. We test the proof of concept in CamVid and provide results in the\nlarge-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN\napproach requires roughly 30% less additional labeled data than our most\ncompetitive baseline to reach the same performance. Moreover, we find that our\nmethod asks for more labels of under-represented categories compared to the\nbaselines, improving their performance and helping to mitigate class imbalance.","label":"human"}
{"id":174,"text":"Conventional transfer learning leverages weights of pre-trained networks, but\nmandates the need for similar neural architectures. Alternatively, knowledge\ndistillation can transfer knowledge between heterogeneous networks but often\nrequires access to the original training data or additional generative\nnetworks. Knowledge transfer between networks can be improved by being agnostic\nto the choice of network architecture and reducing the dependence on original\ntraining data. We propose a knowledge transfer approach from a teacher to a\nstudent network wherein we train the student on an independent transferal\ndataset, whose annotations are generated by the teacher. Experiments were\nconducted on five state-of-the-art networks for semantic segmentation and seven\ndatasets across three imaging modalities. We studied knowledge transfer from a\nsingle teacher, combination of knowledge transfer and fine-tuning, and\nknowledge transfer from multiple teachers. The student model with a single\nteacher achieved similar performance as the teacher; and the student model with\nmultiple teachers achieved better performance than the teachers. The salient\nfeatures of our algorithm include: 1)no need for original training data or\ngenerative networks, 2) knowledge transfer between different architectures, 3)\nease of implementation for downstream tasks by using the downstream task\ndataset as the transferal dataset, 4) knowledge transfer of an ensemble of\nmodels, trained independently, into one student model. Extensive experiments\ndemonstrate that the proposed algorithm is effective for knowledge transfer and\neasily tunable.","label":"human"}
{"id":175,"text":"In this paper, we numerically study the ground and first excited states of\nthe fractional Schrodinger equation in an infinite potential well. Due to the\nnon-locality of the fractional Laplacian, it is challenging to find the\neigenvalues and eigenfunctions of the fractional Schrodinger equation either\nanalytically or numerically. We first introduce a fractional gradient flow with\ndiscrete normalization and then discretize it by using the trapezoidal type\nquadrature rule in space and the semi-implicit Euler method in time. Our method\ncan be used to compute the ground and first excited states not only in the\nlinear cases but also in the nonlinear cases. Moreover, it can be generalized\nto solve the fractional partial differential equations (PDEs) with Riesz\nfractional derivatives in space. Our numerical results suggest that the\neigenfunctions of the fractional Schrodinger equation in an infinite potential\nwell are significantly different from those of the standard (non-fractional)\nSchrodinger equation. In addition, we find that the strong nonlocal\ninteractions represented by the fractional Laplacian can lead to a large\nscattering of particles inside of the potential well. Compared to the ground\nstates, the scattering of particles in the first excited states is larger. Furthermore, boundary layers emerge in the ground states and additionally inner\nlayers exist in the first excited states of the fractional nonlinear\nSchrodinger equation.","label":"human"}
{"id":176,"text":"[ABSTRACT] Over the past years, convolutional neural networks (CNN), in which filter-sharing operations are used to exploit the translation equiinvariance property from images, have demonstrated an unprecedented power for various computer vision tasks such as image recognition and semantic segmentation etc. Despite recent successes using deeper CNN's, there exists some potential problems when applying it on a limited amount of training data where overfitting will be easily caused due to lack learning capability for capturing prior knowledge.In this thesis we propose two schemes, including errorcorrecting boosting(ECB)as well as adaptive dropout layer(ADL)to alleviate the limitations mentioned above via improving model generalization and also mitigating overfittingsituations especially when working on few labeled datacollection by incorporating extra knowledge during learning process without requiring any preprocessing procedures. For all experiments involving ECB procedure,we use it at different levels based on how many epoch needed so that ECB procedure can improve overall model accuracy effectively in terms of mean intensity of errors since it usually can be used in an iterative fashion until desirableaccuracy achieved or else stop at certain number of repetitions if further improvement becomes impractical. On the other hand, ADL scheme consists of adopting several variants of traditionaldropoutschemeon which their probabilities to switch off weights can be automatically adjustedduring both testingandtrainingphase depending upon input's information quality.For example, if the pixel value in input image has good characteristics, it indicates high confidencelevel, so then the dropout probabilityfor weighted nodes should be decreased accordingly while vice versa case is applicableotherwise i.e., if pixelswith low contrast occurs within input image,the network must learn slowly rather than rapidly in order not only obtain better output results butalso retain more essential features relatedto underlying structures even under uncertain cases encountered frequently during test time scenarios. Moreover both approaches require minimal implementation efforts compared existing works where lots changesmade towardmodel performance are requiredafter each specific run therefore significantly affect running speed\/latenecy overheadsbefore achieving stable convergence behavior. In addition one can observe slight increase inthe complexity level especiallywhen comes down towards actual calculations stages despite","label":"ai"}
{"id":177,"text":"Detection faults in seismic data is a crucial step for seismic structural\ninterpretation, reservoir characterization and well placement. Some recent\nworks regard it as an image segmentation task. The task of image segmentation\nrequires huge labels, especially 3D seismic data, which has a complex structure\nand lots of noise. Therefore, its annotation requires expert experience and a\nhuge workload. In this study, we present lambda-BCE and lambda-smooth L1loss to\neffectively train 3D-CNN by some slices from 3D seismic data, so that the model\ncan learn the segmentation of 3D seismic data from a few 2D slices. In order to\nfully extract information from limited data and suppress seismic noise, we\npropose an attention module that can be used for active supervision training\nand embedded in the network. The attention heatmap label is generated by the\noriginal label, and letting it supervise the attention module using the\nlambda-smooth L1loss. The experiment demonstrates the effectiveness of our loss\nfunction, the method can extract 3D seismic features from a few 2D slice\nlabels. And it also shows the advanced performance of the attention module,\nwhich can significantly suppress the noise in the seismic data while increasing\nthe model's sensitivity to the foreground. Finally, on the public test set, we\nonly use the 2D slice labels training that accounts for 3.3% of the 3D volume\nlabel, and achieve similar performance to the 3D volume label training.","label":"human"}
{"id":178,"text":"State-of-the-art approaches for semantic segmentation rely on deep\nconvolutional neural networks trained on fully annotated datasets, that have\nbeen shown to be notoriously expensive to collect, both in terms of time and\nmoney. To remedy this situation, weakly supervised methods leverage other forms\nof supervision that require substantially less annotation effort, but they\ntypically present an inability to predict precise object boundaries due to\napproximate nature of the supervisory signals in those regions. While great\nprogress has been made in improving the performance, many of these weakly\nsupervised methods are highly tailored to their own specific settings. This\nraises challenges in reusing algorithms and making steady progress. In this\npaper, we intentionally avoid such practices when tackling weakly supervised\nsemantic segmentation. In particular, we train standard neural networks with\npartial cross-entropy loss function for the labeled pixels and our proposed\nGated CRF loss for the unlabeled pixels. The Gated CRF loss is designed to\ndeliver several important assets: 1) it enables flexibility in the kernel\nconstruction to mask out influence from undesired pixel positions; 2) it\noffloads learning contextual relations to CNN and concentrates on semantic\nboundaries; 3) it does not rely on high-dimensional filtering and thus has a\nsimple implementation. Throughout the paper we present the advantages of the\nloss function, analyze several aspects of weakly supervised training, and show\nthat our `purist' approach achieves state-of-the-art performance for both\nclick-based and scribble-based annotations.","label":"human"}
{"id":179,"text":"The purpose of this study is to develop an automatic head overcoat thickness measurement system using a deep learning model called NASNet-Large-Decoder. This system utilizes computer vision techniques and machine learning algorithms to accurately measure the thickness of head hair in real-time. The proposed method involves training a neural network on a large dataset of images containing heads with varying levels of hair density, color, and texture. The trained model can then be used to predict the thickness of new images by analyzing their features and comparing them to those in the training set. The results of this study show that the proposed system achieves high accuracy in measuring head overcoat thickness, with an average error rate of less than 5%. Additionally, the system is able to handle variations in lighting conditions and image quality, making it suitable for use in various settings. Overall, this research contributes to the development of automated systems for measuring human physical characteristics, which has important applications in fields such as healthcare, cosmetics, and fashion.","label":"ai"}
{"id":180,"text":"This paper reports Deep LOGISMOS approach to 3D tumor segmentation by\nincorporating boundary information derived from deep contextual learning to\nLOGISMOS - layered optimal graph image segmentation of multiple objects and\nsurfaces. Accurate and reliable tumor segmentation is essential to tumor growth\nanalysis and treatment selection. A fully convolutional network (FCN), UNet, is\nfirst trained using three adjacent 2D patches centered at the tumor, providing\ncontextual UNet segmentation and probability map for each 2D patch. The UNet\nsegmentation is then refined by Gaussian Mixture Model (GMM) and morphological\noperations. The refined UNet segmentation is used to provide the initial shape\nboundary to build a segmentation graph. The cost for each node of the graph is\ndetermined by the UNet probability maps. Finally, a max-flow algorithm is\nemployed to find the globally optimal solution thus obtaining the final\nsegmentation. For evaluation, we applied the method to pancreatic tumor\nsegmentation on a dataset of 51 CT scans, among which 30 scans were used for\ntraining and 21 for testing. With Deep LOGISMOS, DICE Similarity Coefficient\nrespectively, both are significantly improved (p<0.05) compared with contextual\nUNet and\/or LOGISMOS alone.","label":"human"}
{"id":181,"text":"Medical image segmentation is a fundamental task in medical image analysis. Despite that deep convolutional neural networks have gained stellar performance\nin this challenging task, they typically rely on large labeled datasets, which\nhave limited their extension to customized applications. By revisiting the\nsuperiority of atlas based segmentation methods, we present a new framework of\nOne-pass aligned Atlas Set for Images Segmentation (OASIS). To address the\nproblem of time-consuming iterative image registration used for atlas warping,\nthe proposed method takes advantage of the power of deep learning to achieve\none-pass image registration. In addition, by applying label constraint, OASIS\nalso makes the registration process to be focused on the regions to be\nsegmented for improving the performance of segmentation. Furthermore, instead\nof using image based similarity for label fusion, which can be distracted by\nthe large background areas, we propose a novel strategy to compute the label\nsimilarity based weights for label fusion. Our experimental results on the\nchallenging task of prostate MR image segmentation demonstrate that OASIS is\nable to significantly increase the segmentation performance compared to other\nstate-of-the-art methods.","label":"human"}
{"id":182,"text":"> The E. coli chemotaxis system is a complex biological system that has been the subject of much research. The system is composed of a number of interacting components, including the flagellar motor, the chemoreceptors, and the chemotaxis proteins. The system is also subject to a number of external stimuli, including the concentration of nutrients in the environment. The system is known to be highly sensitive to changes in the environment, and it is believed that this sensitivity is due to the complex interactions between the components of the system. > In this paper, we present a numerical analysis of a Monte Carlo simulation of the E. coli chemotaxis system. The simulation is based on a model of the system that was developed by the authors. The model is a system of differential equations that describe the dynamics of the system. The model is solved using a Monte Carlo simulation. The simulation is used to study the behavior of the system under different conditions. The simulation is also used to study the sensitivity of the system to changes in the environment. > The results of the simulation are presented in the form of a number of graphs. The graphs show the behavior of the system under different conditions. The graphs also show the sensitivity of the system to changes in the environment. The results of the simulation are also presented in the form of a number of tables. The tables show the values of the variables in the system under different conditions. The tables also show the values of the variables in the system under different conditions. > The results of the simulation are presented in the form of a number of graphs. The graphs show the behavior of the system under different conditions. The graphs also show the sensitivity of the system to changes in the environment. The results of the simulation are also presented in the form of a number of tables. The tables show the values of the variables in the system under different conditions. The tables also show the values of the variables in the system under different conditions. > The results of the simulation are presented in the form of a number of graphs. The graphs show the behavior of the system under different conditions. The graphs also show the sensitivity of the system to changes in the environment. The results of the simulation are","label":"ai"}
{"id":183,"text":"Ferrograph image segmentation is of significance for obtaining features of\nwear particles. However, wear particles are usually overlapped in the form of\ndebris chains, which makes challenges to segment wear debris. An overlapping\nwear particle segmentation network (OWPSNet) is proposed in this study to\nsegment the overlapped debris chains. The proposed deep learning model includes\nthree parts: a region segmentation network, an edge detection network and a\nfeature refine module. The region segmentation network is an improved U shape\nnetwork, and it is applied to separate the wear debris form background of\nferrograph image. The edge detection network is used to detect the edges of\nwear particles. Then, the feature refine module combines low-level features and\nhigh-level semantic features to obtain the final results. In order to solve the\nproblem of sample imbalance, we proposed a square dice loss function to\noptimize the model. Finally, extensive experiments have been carried out on a\nferrograph image dataset. Results show that the proposed model is capable of\nseparating overlapping wear particles. Moreover, the proposed square dice loss\nfunction can improve the segmentation results, especially for the segmentation\nresults of wear particle edge.","label":"human"}
{"id":184,"text":"In this paper, we propose an efficient semidefinite programming (SDP)\napproach to worst-case linear discriminant analysis (WLDA). Compared with the\ntraditional LDA, WLDA considers the dimensionality reduction problem from the\nworst-case viewpoint, which is in general more robust for classification. However, the original problem of WLDA is non-convex and difficult to optimize. In this paper, we reformulate the optimization problem of WLDA into a sequence\nof semidefinite feasibility problems. To efficiently solve the semidefinite\nfeasibility problems, we design a new scalable optimization method with\nquasi-Newton methods and eigen-decomposition being the core components. The\nproposed method is orders of magnitude faster than standard interior-point\nbased SDP solvers. Experiments on a variety of classification problems demonstrate that our\napproach achieves better performance than standard LDA. Our method is also much\nfaster and more scalable than standard interior-point SDP solvers based WLDA. The computational complexity for an SDP with $m$ constraints and matrices of","label":"human"}
{"id":185,"text":"> Despite significant progress on few-shot segmentation, it remains under-explored on two aspects: global context modeling and data-efficient fine-tuning. > First, existing methods fail to model the local and global relations among objects with limited supervisions, which may mislead the network to assign similarities to dissimilar categories. > Second, fine-tuning models with limited supervisions is costly in terms of computation and memory. > CRNet tackles the above issues by building cross-reference networks to establish the correspondence between objects' categories and spatial locations. > For example, the red dog should not be assigned an orange cat label. > To this end, CRNet employs a dual branch network that explicitly encodes the cross-reference relations with both feature fusion and localization. > In the testing stage, we exploit multiple cross-reference networks to establish the cross-reference relations between the same object's category and different spatial locations (e.g. orange cat and its orange spots). > Then, a spatial attention module is used to determine the spatial locations with higher attention scores. > In the fine-tuning stage, we design a computationally-efficient data augment scheme. > In particular, 9-way 1-shot training can be performed by only using the original training data 7 times, without any new task data required. > CRNet sets the state-of-the-art on PASCAL-5\\(^i\\) benchmark while running 112.1 FLOPs, only 16.1% of its FLOP-counterparts. You can find full details on arxiv.org\nPosted from my blog with STEEM press this","label":"ai"}
{"id":186,"text":"The \"bag-of-frames\" approach (BOF), which encodes audio signals as the\nlong-term statistical distribution of short-term spectral features, is commonly\nregarded as an effective and sufficient way to represent environmental sound\nrecordings (soundscapes) since its introduction in an influential 2007 article. The present paper describes a concep-tual replication of this seminal article\nusing several new soundscape datasets, with results strongly questioning the\nadequacy of the BOF approach for the task. We show that the good accuracy\noriginally re-ported with BOF likely result from a particularly thankful\ndataset with low within-class variability, and that for more realistic\ndatasets, BOF in fact does not perform significantly better than a mere\none-point av-erage of the signal's features. Soundscape modeling, therefore,\nmay not be the closed case it was once thought to be. Progress, we ar-gue,\ncould lie in reconsidering the problem of considering individual acoustical\nevents within each soundscape.","label":"human"}
{"id":187,"text":"> For more than five decades, computer scientists have searched for an algorithm that would solve all instances of maximum cut in time polynomial (or subexponential)in | V|=numberofverticesoninputgraph G=(V,E). It has been long recognized that such an algorithm requires breaking symmetry among cuts and thereby violating local structure of graphs. In particular there are many classes of graphs where one can decide if a given graph belongs to them. Such problems form a big class called \"problems with kernels\". Recently it was shown how to get an exponentialtime cut approximation ratio 0*543 (alas this ratio cannot be improved unless RP NP!). While it may appear very far away from optimal, there is hope - we will showhow to build a new kernelization approach using so-called 'differentiation'. By showing existenceof certain edges on each side of every vertex set SC V, we'll obtain improved hardness ratios. Our main goal howeveris proving existence of these differentiators within linear number of iterations on general graphs. We do this by giving explicit criteriafor edge selectionand construction algorithm to construct differentiators without any additional assumptions on input or output size - only requiringthat two copies exist at given stage. These results are of independent interest and should have wide applicability beyond problem maxcut itself; e.g., they offer strong improvements over known algorithms for maximum independentset-finding task as wella n important extensionto current practicein cryptography(which uses randomized constructions): by reducing dependencefrom random bitsinto deterministic complexity bounds\nWhat's more promising is the fact that a simple binary search variant using a black box solver improves the runtimes of the best approximators exponentially for a small value. This raises hopes that further improving our implementation could prove highly beneficial when solving MaxCut in real life scenarios and potentially other problems related via a reduction.","label":"ai"}
{"id":188,"text":"Machine learning has been widely adopted for medical image analysis in recent\nyears given its promising performance in image segmentation and classification\ntasks. As a data-driven science, the success of machine learning, in particular\nsupervised learning, largely depends on the availability of manually annotated\ndatasets. For medical imaging applications, such annotated datasets are not\neasy to acquire. It takes a substantial amount of time and resource to curate\nan annotated medical image set. In this paper, we propose an efficient\nannotation framework for brain tumour images that is able to suggest\ninformative sample images for human experts to annotate. Our experiments show\nthat training a segmentation model with only 19% suggestively annotated patient\nscans from BraTS 2019 dataset can achieve a comparable performance to training\na model on the full dataset for whole tumour segmentation task. It demonstrates\na promising way to save manual annotation cost and improve data efficiency in\nmedical imaging applications.","label":"human"}
{"id":189,"text":"The $A_\\infty$ T-system, also called the octahedron recurrence, is a\ndynamical recurrence relation. It can be realized as mutation in a\ncoefficient-free cluster algebra (Kedem 2008, Di Francesco and Kedem 2009). We\ndefine T-systems with principal coefficients from cluster algebra aspect, and\ngive combinatorial solutions with respect to any valid initial condition in\nterms of partition functions of perfect matchings, non-intersecting paths and\nnetworks. This also provides a solution to other systems with various choices\nof coefficients on T-systems including Speyer's octahedron recurrence (Speyer","label":"human"}
{"id":190,"text":"The Hawking effect, first proposed by Stephen Hawking, describes the emission of quantum particles from a black hole's event horizon due to quantum fluctuations in the spacetime near the horizon. The effect was originally applied to asymptotic spacetimes, but later generalized to curved spacetimes. In this paper, we explore the effect of a rotating probe D3-brane on the Hawking effect. We find that the presence of the brane leads to an additional quantum flux emitted from the event horizon. This flux is due to the interaction of the brane with the background field, and is highly sensitive to the brane's position and velocity. We also find that the flux is affected by the emission and absorption of gravitational waves caused by the brane's motion. Our results provide new insights into the emergence of quantum effects near black holes, and could have implications for astrophysical applications.","label":"ai"}
{"id":191,"text":"> Deep learning methods offer an optimal solution to many computer graphics and vision problems, including volumetric segmentations of CT scans. However, existing learning schemes require large volumes of training data that are not always available or prohibitively difficult to obtain. To avoid this issue, we propose two novel approaches based on the well known Squeeze&Excite encoder architecture (Hu et al., 2018), for few shot object segmentation. Our methods use pretrained parameters to initialize the network along with minimal additional label supervision during training. The first strategy uses unlabeled examples together with weakly labeled images with limited foreground\/background labels. This method can be trained using only five examples for each class in addition to the fully labeled pretraining process. For our second approach, we perform transfer learning across dataset categories without any redesign of the model architectures. In particular, this enables us to use very small amounts of information about our target domain while adapting deep features learned by other similar datasets such as CT MRI and X ray. Results demonstrate accurate segmentation of the lung lobes using both techniques against other stateof- the-art fewshot segmenters; we also present promising results in ablative studies on cardiac MRA datasets where the proposed methods provide superior performance compared against competitive alternatives. Keywords - Artificial intelligence, CT scan image recognition; Medical imaging, Image processing, Computer assisted diagnosis","label":"ai"}
{"id":192,"text":"We survey recent advances in deep learning and related methods, with applications to fault detection and diagnosis (FDD) and health monitoring\/prognosis problems for various machine types. Faults, often known as failures or breakdowns, cause large financial losses that depend on factors such as frequency type, size and location; thus it becomes paramount to develop systems capable of real-time processing power and accurate prediction. Several studies have introduced innovative approaches utilizing both time-series models based on convolutional neural network structures using multidimensional features including vibrations, spectral data, heat and electrical signals. This approach has shown state-of-the-art results when compared against traditional statistical analysis; however further investigation will be needed as novel machines are designed every day--leading towards more complicated maintenance procedures due... Read more >>","label":"ai"}
{"id":193,"text":"The field of machine learning has seen a surge in interest in developing prediction sets that can provide reliable predictions while also controlling risk. In this paper, we propose a new approach to constructing distribution-free, risk-controlling prediction sets using a novel algorithm called the Randomized Set Method (RSM). Our method is based on randomizing the selection process and allows us to control the expected loss of our prediction set under any unknown probability measure. We demonstrate the effectiveness of our approach through several experiments and show that it outperforms existing methods in terms of both accuracy and risk control. Overall, our work provides an important contribution to the development of robust and reliable prediction sets that are suitable for use in real-world applications.","label":"ai"}
{"id":194,"text":"Contrary to conventional economic growth theory, which reduces a country's\noutput to one aggregate variable (GDP), product diversity is central to\neconomic development, as recent 'economic complexity' research suggests. A\ncountry's product diversity reflects its diversity of knowhow or\n'capabilities'. Researchers proposed the Economic Complexity Index (ECI) and\nthe country Fitness index to estimate a country's number of capabilities from\ninternational export data; these measures predict economic growth better than\nconventional variables such as human capital. This paper offers a simpler\nmeasure of a country's knowhow, Log Product Diversity (or LPD, the logarithm of\na country's number of products), which can be derived from a one-parameter\ncombinatorial model of production in which a set of knowhows combine with some\nprobability to turn raw materials into a product. ECI and log-fitness can be\ninterpreted theoretically (using the combinatorial model) and empirically as\npotentially noisy estimates of LPD; moreover, controlling for natural\nresources, the simple measure better explains the cross-country differences in\nGDP and in GDP per capita.","label":"human"}
{"id":195,"text":"We present highly efficient algorithms for performing forward and backward\npropagation of Convolutional Neural Network (CNN) for pixelwise classification\non images. For pixelwise classification tasks, such as image segmentation and\nobject detection, surrounding image patches are fed into CNN for predicting the\nclasses of centered pixels via forward propagation and for updating CNN\nparameters via backward propagation. However, forward and backward propagation\nwas originally designed for whole-image classification. Directly applying it to\npixelwise classification in a patch-by-patch scanning manner is extremely\ninefficient, because surrounding patches of pixels have large overlaps, which\nlead to a lot of redundant computation. The proposed algorithms eliminate all the redundant computation in\nconvolution and pooling on images by introducing novel d-regularly sparse\nkernels. It generates exactly the same results as those by patch-by-patch\nscanning. Convolution and pooling operations with such kernels are able to\ncontinuously access memory and can run efficiently on GPUs. A fraction of\npatches of interest can be chosen from each training image for backward\npropagation by applying a mask to the error map at the last CNN layer. Its\ncomputation complexity is constant with respect to the number of patches\nsampled from the image. Experiments have shown that our proposed algorithms\nspeed up commonly used patch-by-patch scanning over 1500 times in both forward\nand backward propagation. The speedup increases with the sizes of images and\npatches.","label":"human"}
{"id":196,"text":"The objective of this study is to develop a novel deep learning model, PC-U Net, that can simultaneously reconstruct and segment the cardiac walls in 3D from computed tomography (CT) data. This approach addresses two critical tasks in medical imaging, which are essential for accurate diagnosis and treatment planning of various heart diseases. The proposed model utilizes an encoder-decoder architecture with skip connections to learn both reconstruction and segmentation tasks jointly. The encoder extracts features from the input CT images, while the decoder generates high-resolution reconstructions and segmentations based on these features. To improve the performance of the model, we also introduce several novel techniques such as multi-scale attention mechanisms, progressive growing, and adaptive normalization. We evaluate our model on a large dataset of CT scans and compare it with state-of-the-art methods using metrics such as mean squared error, Dice coefficient, and intersection over union. Our results demonstrate that PC-U Net outperforms existing models in terms of both reconstruction accuracy and segmentation quality. Furthermore, we show that our method can be applied to different types of CT scanners and image resolutions, making it a versatile tool for clinical use.","label":"ai"}
{"id":197,"text":"> We give a new characterization of Leavitt path algebras of graphs in terms of Baer *-rings. We also give a new characterization of Leavitt path algebras of graphs in terms of Baer *-rings. The paper is by J. D. Farthing, J. M. Gould, and J. M. Sands. ### About Leavitt path algebras\nLeavitt path algebras are a class of rings that were introduced by C. Leavitt in 1995. They are defined in terms of graphs, and are a generalization of the Cuntz algebras. The Leavitt path algebras of graphs are a class of rings that were introduced by C. Leavitt in 1995. They are defined in terms of graphs, and are a generalization of the Cuntz algebras. Baer *-rings are a class of rings that were introduced by C. Baer in 1935. They are defined in terms of graphs, and are a generalization of the Cuntz algebras. ### About the authors\nJ. D. Farthing is a professor of mathematics at the University of California, Berkeley. J. M. Gould is a professor of mathematics at the University of California, Berkeley. J. M. Sands is a professor of mathematics at the University of California, Berkeley.","label":"ai"}
{"id":198,"text":"> Abstract: We present a new model for the interstellar dust extinction and emission in galaxies. The model is based on the\n> Mie theory and includes the effects of grain growth, grain size distribution, and grain composition. The model is\n> calibrated on the Milky Way and applied to a sample of nearby galaxies. We find that the model is able to reproduce\n> the observed extinction and emission properties of these galaxies. We then apply the model to a sample of high-redshift\n> galaxies and find that the model is able to reproduce the observed extinction and emission properties of these galaxies. > We also find that the model is able to reproduce the observed extinction and emission properties of galaxies in the\n> local Universe. We conclude that the model is a good tool for studying the interstellar dust in galaxies. The paper is available at:","label":"ai"}
{"id":199,"text":"> Abstract: In this work, we consider energy efficient transmission over space shift keying (SSK) modulated multiple-input multiple-output (MIMO) channels with perfect channel state information at both transmitter and receiver sides. We first derive an upper bound on the achievable rate region by using the concept of superposition coding in conjunction with successive decoding. Then, we propose two novel schemes that achieve the same upper bound but require less power than the scheme based on superposition coding. Finally, we show that our proposed schemes are optimal among all possible SSK modulation schemes.","label":"ai"}
{"id":200,"text":"In a well generated triangulated category T, given a regular cardinal a, we\nconsider the following problems: given a functor from the category of a-compact\nobjects to abelian groups that preserves products of <a objects and takes exact\ntriangles to exact sequences, is it the restriction of a representable functor\nin T? Is every natural transformation between two such restricted representable\nfunctors induced by a map between the representatives? If the answer to both\nquestions is positive we say that T satisfies a-Adams representability. A\nclassical result going back to Brown and Adams shows that the stable homotopy\ncategory satisfies Adams representability for the first infinite cardinal. For\nthat cardinal, Adams representability is well understood thanks to the work of\nChristensen, Keller and Neeman. In this paper, we develop an obstruction theory\nto decide when T satisfies a-Adams representability. We derive necessary and\nsufficient conditions of homological nature, and we compute several examples. In particular, we show that there are rings satisfying a-Adams representability\nfor all non-countable cardinals a and rings which do not satisfy a-Adams\nrepresentability for any infinite cardinal a. Moreover, we exhibit rings for\nwhich the answer to both questions is no for infinite many cardinals. As a side\nresult, we give an example of an infinite phantom map.","label":"human"}
{"id":201,"text":"> We are interested in investigating methods to learn image segmentation sequence models from single or multiple videos, and more importantly how we can apply these deep network architectures for predicting high quality object detection and tracking results as well as performing frame wise object segmentations over test cases (either new or unseen sequences). This task consists in training convolutional neural networks able to output segmentation masks given one or several frames from the same video. It has been introduced recently by Gadde et al. [1] where they also proposed both Mask RNN and FrameMask CNN, two very interesting state-of-the-art approaches that we used while building our current proposal which combines both types into an hybrid architecture. Moreover, instead of considering only images during training -as proposed before-, nowadays it looks possible to tackle this problem successfully with either stills and videos, however using the right data balancing strategy depending on the approach\/architecture under study might be determinant for achieving better performance accuracy over different datasets\/configurations tested so far. Here, to show our claims, we will compare experiments performed with three main variants of the Mask RCNN approach: VGG16 mask; FasterRCN + COCO model pretrained first on 80 classes dataset and then fine tuned for our case study; ResNet50 + PASCAL VOC training weights. Results obtained after applying this kind of pipeline confirm once again its validity since they consistently achieve more accurate mean average precision measurements along the entire temporal domain than those previously reported elsewhere -at least when compared against what was published thus far by other competing proposals-. In line with some of their assumptions stated at the beginning of the manuscript, we have also tried many different ways of addressing data balancing issues in order to assess its importance within a typical computer vision task scenario comprising several categories \/ classes in play: i) training from scratch, ii) finetuning existing checkpoints provided by the authors themselves together with all related code implementation, iii) combining information coming either from static images or dynamic frames whenever available without any particular concern regarding memory space storage requirements here because both resources were considered equivalent between them, iv) including both types altogether but just keeping half amount of original size files -in this instance we decided not to","label":"ai"}
{"id":202,"text":"> We consider the discretization of fluid-structure interaction (FSI) systems, which are coupled partial differential equations that model the dynamics of fluids interacting with deformable solids. In this work we focus on the case where both the solid and fluid domains have complex geometries. To solve these problems efficiently, it is important to develop robust preconditioners for the linear system arising in each time step. This requires understanding how well-posed the discrete problem is as a function of the mesh parameters. For example, if the mesh size goes to zero then the discrete problem becomes ill-posed due to the loss of boundary conditions. However, if the mesh sizes go to zero at different rates then the discrete problem may still be well-posed. In this work we show that under certain assumptions on the geometry, the FSI system can be made well-posed by choosing appropriate mesh sizes. Furthermore, we provide an analysis of two popular preconditioners used in practice, namely the Schur complement method and the block Jacobi method. Our results indicate that the Schur complement method is not robust while the block Jacobi method is robust provided that the mesh sizes satisfy our assumptions.","label":"ai"}
{"id":203,"text":"In this academic paper, we propose a new architecture called UCTransNet that improves upon the skip connections in U-Net by utilizing channel-attention mechanisms and incorporating transformer technology. Our model achieves superior performance on various image segmentation benchmarks while maintaining computational efficiency. Skip connections are an important component of convolutional neural networks (CNNs), as they enable information flow between different levels of representation. However, traditional skip connections often suffer from degradation or overfitting, which limits their capacity to learn complex features accurately. In recent years, several methods have attempted to address these challenges through novel network structures such as ResNets, DenseConnect, FCN, and U-Net. Despite these advancements, there remains room for improvement in developing efficient yet effective skip connection architectures. Our proposed UCTransNet employs multiple self-attention mechanisms to weigh the importance of input channels when merging them, allowing our model to selectively learn relevant feature representations more effectively than traditional CNN models. We also leverage residual connections and bottleneck architectures found within Transformers to optimize resource utilization while minimizing vanishing gradients. These improvements result in improved performance on various image segmentation tasks without sacrificing computational complexity. Our results demonstrate the effectiveness of UCTransNet for improving upon the limitations inherent in traditional skip connection architectures. By incorporating channel-wise attention and leveraging transformer technology, we provide significant advances that contribute to the ongoing development of more accurate and efficient deep learning models.","label":"ai"}
{"id":204,"text":"Abstract: Efficient image segmentation based on similarity matching with geometric priors can have numerous applications in the field of computer vision and pattern recognition; e.g., it allows to robustly recognize shape classes (as in texture discrimination or object classification), but also detecting, locating, reconstructing and alignin... Read more\nSource: Computer Vision - ScienceDirect","label":"ai"}
{"id":205,"text":"The task of segmenting an image into several regions with predefined categories has been used in many medical fields, such as radiologists recognizing whether pneumonia or not. Due to its limited amount in medical scanning data, applying deep neural network (DNN) to learn a semantic representation that is accurate enough for segmentation could be challenging. To address this problem, we designed ACE-net, a framework containing augmented contracting and expansive paths. An auxiliary path expands a DNN gradually while other main DNN contracts it slowly until they reach similar feature dimensions, then predicts corresponding classification labels simultaneously. During the learning process, both are forced to converge to the same prediction results, thus a small training set can be sufficiently leveraged without losing much performance. Experiments on public datasets achieved state-of-the-art accuracy against existing works at competitive complexity. With 0-shot fine tuned models only trained on large scale imagery dataset e-shoppings, our method also achieved better performance than prior art significantly when applied to multiple downstream tasks.","label":"ai"}
{"id":206,"text":"> In this paper, we propose a novel uncertainty-aware self-ensembling model for semi-supervised 3D left atrium (LA) segmentation. The proposed model consists of two main components: a 3D U-Net-based segmentation network and a self-ensembling module. The segmentation network is trained on a large number of unlabeled 3D cardiac MRI volumes to learn the underlying structure of the LA. The self-ensembling module is designed to generate pseudo-labels for unlabeled data by combining the predictions of the segmentation network and the uncertainty estimates. The pseudo-labels are then used to train the segmentation network on the unlabeled data, which improves the performance of the model on the labeled data. The proposed model is evaluated on a dataset of 3D cardiac MRI volumes with LA annotations. The results show that the proposed model outperforms the state-of-the-art methods in terms of segmentation accuracy and generalization ability. The proposed model is also robust to noise and outliers in the data, which makes it suitable for real-world applications. The following is the full text of the abstract for a research paper titled \"Uncertainty-aware Self-ensembling Model for Semi-supervised 3D Left Atrium Segmentation\" from arxiv.org:\n> In this paper, we propose a novel uncertainty-aware self-ensembling model for semi-supervised 3D left atrium (LA) segmentation. The proposed model consists of two main components: a 3D U-Net-based segmentation network and a self-ensembling module. The segmentation network is trained on a large number of unlabeled 3D cardiac MRI volumes to learn the underlying structure of the LA. The self-ensembling module is designed to generate pseudo-labels for unlabeled data by combining the predictions of the segmentation network and the uncertainty estimates. The pseudo-labels are then used to train the segmentation network on the unlabeled data, which improves the performance of the model on the labeled data. The proposed model","label":"ai"}
{"id":207,"text":"> Multi-organ segmentation in thoracic CT is a challenging task due to the presence of similar structures and the large variability in the shape and size of the organs. In this paper, we propose a 2D dilated residual U-Net for multi-organ segmentation in thoracic CT. The proposed network consists of a 2D dilated residual U-Net with a 2D dilated residual block as the basic building block. The 2D dilated residual block is designed to capture the long-range contextual information and to alleviate the vanishing gradient problem. The proposed network is trained on a large dataset of 1000 thoracic CT scans with manual segmentation of 10 organs. The proposed network is evaluated on a test set of 100 thoracic CT scans with manual segmentation of 10 organs. The proposed network achieves a mean Dice score of 0.92 for the 10 organs. The proposed network is also compared with other state-of-the-art methods on the same dataset. The proposed network outperforms other methods in terms of mean Dice score. The proposed network is also evaluated on a dataset of 100 thoracic CT scans with manual segmentation of 10 organs. The proposed network achieves a mean Dice score of 0.93 for the 10 organs. The proposed network is also compared with other state-of-the-art methods on the same dataset. The proposed network outperforms other methods in terms of mean Dice score. The following is the full text of the abstract for a research paper titled \"A 2D dilated residual U-Net for multi-organ segmentation in thoracic CT\" from arxiv.org:\n> Multi-organ segmentation in thoracic CT is a challenging task due to the presence of similar structures and the large variability in the shape and size of the organs. In this paper, we propose a 2D dilated residual U-Net for multi-organ segmentation in th","label":"ai"}
{"id":208,"text":"We develop a theory of aggregation using statistical mechanical methods. An\nexample of a complicated aggregation system with several levels of structures\nis peptide\/protein self-assembly. The problem of protein aggregation is\nimportant for the understanding and treatment of neurodegenerative diseases and\nalso for the development of bio-macromolecules as new materials. We write the\neffective Hamiltonian in terms of interaction energies between protein\nmonomers, protein and solvent, as well as between protein filaments. The grand\npartition function can be expressed in terms of a Zimm-Bragg-like transfer\nmatrix, which is calculated exactly and all thermodynamic properties can be\nobtained. We start with two-state and three-state descriptions of protein\nmonomers using Potts models that can be generalized to include q-states, for\nwhich the exactly solvable feature of the model remains. We focus on n X N\nlattice systems, corresponding to the ordered structures observed in some real\nfibrils. We have obtained results on nucleation processes and phase diagrams,\nin which a protein property such as the sheet content of aggregates is\nexpressed as a function of the number of proteins on the lattice and\ninter-protein or interfacial interaction energies. We have applied our methods\nto A{\\beta}(1-40) and Curli fibrils and obtained results in good agreement with\nexperiments.","label":"human"}
{"id":209,"text":"> We present an algorithm to learn non-Gaussian, nonlinear Markov random fields (MRF) using backpropagation through stochastic networks. Our approach uses a novel formulation that allows us to train MRF models with arbitrary potential functions and pairwise interactions between variables. This enables learning of complex distributions such as those used in computer vision applications like semantic segmentation or image denoising. In addition, we show how our method can be applied to problems where the data are not fully observed but only partially available due to missing values. To demonstrate the effectiveness of our approach, we apply it to two different tasks: 1) Semantic Segmentation on Cityscapes dataset; 2) Image Denoising on BSD68 dataset. For both tasks, we compare against state-of-the-art methods including conditional random field (CRF), graphical model based approaches, and deep neural network architectures trained end-to-end without any postprocessing steps. Experimental results show that our proposed method outperforms all other baselines by large margins while being significantly faster than competing algorithms during training time.","label":"ai"}
{"id":210,"text":"Recent observations of gravitational waves by the Laser Interferometer\nGravitational-Wave Observatory (LIGO) has confirmed one of the last outstanding\npredictions in general relativity and in the process opened up a new frontier\nin astronomy and astrophysics. Additionally the observation of gravitational\nwaves has also given us the data needed to deduce the physical properties of\nspace time. Bredberg et al have shown in their 2011 paper titled From\nNavier-Stokes to Einstein, that for every solution of the incompressible\nNavier-Stokes equation in p + 1 dimensions, there is a uniquely associated\ndual\" solution of the vacuum Einstein equations in p + 2 dimensions. The author\nshows that the physical properties of space time can be deduced using the\nrecent measurements from the Laser Interferometer Gravitational-Wave\nObservatory and solutions from the incompressible Navier-Stokes equation.","label":"human"}
{"id":211,"text":"An evacuation process is simulated within the Social Force Model. Thousand\npedestrians are leaving a room by one exit. We investigate the stationarity of\nthe distribution of time lags between instants when two successive pedestrians\ncross the exit. The exponential tail of the distribution is shown to gradually\nvanish. Taking fluctuations apart, the time lags decrease in time till there\nare only about 50 pedestrians in the room, then they start to increase. This\nsuggests that at the last stage the flow is laminar. In the first stage,\nclogging events slow the evacuation down. As they are more likely for larger\ncrowds, the flow is not stationary. The data are investigated with detrended\nfluctuation analysis.","label":"human"}
{"id":212,"text":"In this paper, we introduce and study a family of random noble means substitutions. These substitutions are used to approximate certain integrals involving functions with bounded variation or Lipschitz norms. We show that these approximations have good convergence properties under mild assumptions on the underlying distribution. Our results extend previous work in the literature by allowing for more general types of distributions and providing new insights into the behavior of such approximations.","label":"ai"}
{"id":213,"text":"Deep learning has achieved great success as a powerful classification tool\nand also made great progress in sematic segmentation. As a result, many\nresearchers also believe that deep learning is the most powerful tool for pixel\nlevel image segmentation. Could deep learning achieve the same pixel level\naccuracy as traditional image segmentation techniques by mapping the features\nof the object into a non-linear function? This paper gives a short survey of\nthe accuracies achieved by deep learning so far in image classification and\nimage segmentation. Compared to the high accuracies achieved by deep learning\nin classifying limited categories in international vision challenges, the image\nsegmentation accuracies achieved by deep learning in the same challenges are\nonly about eighty percent. On the contrary, the image segmentation accuracies\nachieved in international biomedical challenges are close to ninty five\npercent. Why the difference is so big? Since the accuracies of the competitors\nmethods are only evaluated based on their submitted results instead of\nreproducing the results by submitting the source codes or the software, are the\nachieved accuracies verifiable or overhyped? We are going to find it out by\nanalyzing the working principle of deep learning. Finally, we compared the\naccuracies of state of the art deep learning methods with a threshold selection\nmethod quantitatively. Experimental results showed that the threshold selection\nmethod could achieve significantly higher accuracy than deep learning methods\nin image segmentation.","label":"human"}
{"id":214,"text":"The paper proposes 4-dimensional equations for the proper characteristics of\nFrom these conditions follow the law of motion of the proper tetrad and the\nequations of the inverse problem of kinematics, i.e., differential equations\nthat solve the problem of restoring the motion parameters of a rigid reference\nframe from known proper acceleration and angular velocity. In particular, it is\nshown that when boosted, a moving reference frame that has proper Thomas\nprecession relative to the new laboratory frame will have a combination of two\nrotations: the new Thomas proper precession and the Wigner rotation, which\ntogether give the original frequency of Thomas precession $$","label":"human"}
{"id":215,"text":"> We study the crossover phenomenon in discrete-time quantum walks on a line. We show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We also show that the crossover phenomenon is a generic feature of discrete-time quantum walks on a line. We","label":"ai"}
{"id":216,"text":"Greenhouse segmentation has pivotal importance for climate-smart agricultural\nland-use planning. Deep learning-based approaches provide state-of-the-art\nperformance in natural image segmentation. However, semantic segmentation on\nhigh-resolution optical satellite imagery is a challenging task because of the\ncomplex environment. In this paper, a sound methodology is proposed for\npixel-wise classification on images acquired by the Azersky (SPOT-7) optical\nsatellite. In particular, customized variations of U-Net-like architectures are\nemployed to identify greenhouses. Two models are proposed which uniquely\nincorporate dilated convolutions and skip connections, and the results are\ncompared to that of the baseline U-Net model. The dataset used consists of\npan-sharpened orthorectified Azersky images (red, green, blue,and near infrared\nchannels) with 1.5-meter resolution and annotation masks, collected from 15\nregions in Azerbaijan where the greenhouses are densely congested. The images\ncover the cumulative area of 1008 $km^2$ and annotation masks contain 47559\npolygons in total. The $F_1, Kappa, AUC$, and $IOU$ scores are used for\nperformance evaluation. It is observed that the use of the deconvolutional\nlayers alone throughout the expansive path does not yield satisfactory results;\ntherefore, they are either replaced or coupled with bilinear interpolation. All\nmodels benefit from the hard example mining (HEM) strategy. It is also reported\nweighted binary cross-entropy loss is coupled with the dice loss. Experimental\nresults showed that both of the proposed models outperformed the baseline U-Net\narchitecture such that the best model proposed scored $4.48\\%$ higher in\ncomparison to the baseline architecture.","label":"human"}
{"id":217,"text":"The nematode Caenorhabditis elegans is a well-known model organism used to\ninvestigate fundamental questions in biology. Motility assays of this small\nroundworm are designed to study the relationships between genes and behavior. Commonly, motility analysis is used to classify nematode movements and\ncharacterize them quantitatively. Over the past years, C. elegans' motility has\nbeen studied across a wide range of environments, including crawling on\nsubstrates, swimming in fluids, and locomoting through microfluidic substrates. However, each environment often requires customized image processing tools\nrelying on heuristic parameter tuning. In the present study, we propose a novel\nMulti-Environment Model Estimation (MEME) framework for automated image\nsegmentation that is versatile across various environments. The MEME platform\nis constructed around the concept of Mixture of Gaussian (MOG) models, where\nstatistical models for both the background environment and the nematode\nappearance are explicitly learned and used to accurately segment a target\nnematode. Our method is designed to simplify the burden often imposed on users;\nhere, only a single image which includes a nematode in its environment must be\nprovided for model learning. In addition, our platform enables the extraction\nof nematode `skeletons' for straightforward motility quantification. We test\nour algorithm on various locomotive environments and compare performances with\nan intensity-based thresholding method. Overall, MEME outperforms the\nthreshold-based approach for the overwhelming majority of cases examined. Ultimately, MEME provides researchers with an attractive platform for C.\nelegans' segmentation and `skeletonizing' across a wide range of motility\nassays.","label":"human"}
{"id":218,"text":"> We propose a novel task-agnostic framework for self-supervision based on a simple assumption of similar motion between neighboring pixels. While this framework is intuitive, it is not straightforward to achieve. Recent advances in optical flow and computer vision have made possible the efficient calculation of motion between pixels. We leverage this for self-supervision of semantic segmentation and instance segmentation networks, with state-of-the-art accuracies while being simple, efficient and modular. For cross-channel similarity, we adopt the spatial cross-correlation as a distance which is also used for supervised learning in previous tasks. We test the framework on the COCO dataset for instance segmentation and semantic segmentation. For instance segmentation, we use the Mask2Former architecture which leads to an mIoU of 0.391, which is a new state-of-the-art for self-supervised learning. Semantic segmentation was evaluated using the Deeplabv3+ architecture, and we got an mIoU of 0.33, which is also a new state-of-the-art for self-supervised learning. We additionally extend our method to multiclass optical-flow estimation and show that we can get supervision for semantic segmentation for 3 classes with our method. While our method is simple with just adding a linear head to supervised training, it is task-agnostic and applicable to many computer vision tasks.","label":"ai"}
{"id":219,"text":"> We prove that the language equivalence problem for MM-QFAs is undecidable. This result is obtained by a reduction from the undecidable problem of equivalence of two MM-QFAs with the same number of states. We also prove that the language equivalence problem for MM-QFAs is undecidable even if the two MM-QFAs have the same number of states and the same number of transitions. The paper is available here.","label":"ai"}
{"id":220,"text":"This paper aims at developing an integrated system of clothing co-parsing, in\norder to jointly parse a set of clothing images (unsegmented but annotated with\ntags) into semantic configurations. We propose a data-driven framework\nconsisting of two phases of inference. The first phase, referred as \"image\nco-segmentation\", iterates to extract consistent regions on images and jointly\nrefines the regions over all images by employing the exemplar-SVM (E-SVM)\ntechnique [23]. In the second phase (i.e. \"region co-labeling\"), we construct a\nmulti-image graphical model by taking the segmented regions as vertices, and\nincorporate several contexts of clothing configuration (e.g., item location and\nmutual interactions). The joint label assignment can be solved using the\nefficient Graph Cuts algorithm. In addition to evaluate our framework on the\nFashionista dataset [30], we construct a dataset called CCP consisting of 2098\nhigh-resolution street fashion photos to demonstrate the performance of our\nrecognition rate on the Fashionista and the CCP datasets, respectively, which\nare superior compared with state-of-the-art methods.","label":"human"}
{"id":221,"text":"Scene understanding is a critical component of autonomous manipulation, enabling robots to perceive and interpret their environment in order to perform tasks safely and efficiently. In this paper, we present a deep learning-based approach to scene understanding that leverages convolutional neural networks (CNNs) to extract features from visual input and classify objects within a scene. Our method uses a combination of supervised and unsupervised learning techniques to improve accuracy and robustness, and can handle complex scenes with multiple objects and occlusions. We evaluate our approach on a benchmark dataset of indoor scenes and demonstrate state-of-the-art performance compared to previous methods. Our work paves the way for more advanced autonomous manipulation systems that can operate in real-world environments with greater safety and efficiency.","label":"ai"}
{"id":222,"text":"We present a new method for efficient high-quality image segmentation of\nobjects and scenes. By analogizing classical computer graphics methods for\nefficient rendering with over- and undersampling challenges faced in pixel\nlabeling tasks, we develop a unique perspective of image segmentation as a\nrendering problem. From this vantage, we present the PointRend (Point-based\nRendering) neural network module: a module that performs point-based\nsegmentation predictions at adaptively selected locations based on an iterative\nsubdivision algorithm. PointRend can be flexibly applied to both instance and\nsemantic segmentation tasks by building on top of existing state-of-the-art\nmodels. While many concrete implementations of the general idea are possible,\nwe show that a simple design already achieves excellent results. Qualitatively,\nPointRend outputs crisp object boundaries in regions that are over-smoothed by\nprevious methods. Quantitatively, PointRend yields significant gains on COCO\nand Cityscapes, for both instance and semantic segmentation. PointRend's\nefficiency enables output resolutions that are otherwise impractical in terms\nof memory or computation compared to existing approaches. Code has been made\navailable at\nhttps:\/\/github.com\/facebookresearch\/detectron2\/tree\/master\/projects\/PointRend.","label":"human"}
{"id":223,"text":"This paper examines whether conditional generative adversarial networks (cGANs) are explicitly conditioned on a specific variable, such as a feature vector or label, in the same way that standard GANs are trained solely based on one variable at a time (data and noise). The authors find that cGANs can generate realistic images that correspond to multiple variables simultaneously and require only limited explicit conditioning in order to do so. They also show that training a multivariate cGAN requires significantly fewer resources than using a separate model to capture each variable individually. Overall, this work suggests that cGANs offer a more flexible and efficient approach for image generation tasks that involve multiple variables.","label":"ai"}
{"id":224,"text":"Image segmentation and classification are the two main fundamental steps in\npattern recognition. To perform medical image segmentation or classification\nwith deep learning models, it requires training on large image dataset with\nannotation. The dermoscopy images (ISIC archive) considered for this work does\nnot have ground truth information for lesion segmentation. Performing manual\nlabelling on this dataset is time-consuming. To overcome this issue,\nself-learning annotation scheme was proposed in the two-stage deep learning\nalgorithm. The two-stage deep learning algorithm consists of U-Net segmentation\nmodel with the annotation scheme and CNN classifier model. The annotation\nscheme uses a K-means clustering algorithm along with merging conditions to\nachieve initial labelling information for training the U-Net model. The\nclassifier models namely ResNet-50 and LeNet-5 were trained and tested on the\nimage dataset without segmentation for comparison and with the U-Net\nsegmentation for implementing the proposed self-learning Artificial\nIntelligence (AI) framework. The classification results of the proposed AI\nframework achieved training accuracy of 93.8% and testing accuracy of 82.42%\nwhen compared with the two classifier models directly trained on the input\nimages.","label":"human"}
{"id":225,"text":"Marking tumors and organs is a challenging task suffering from both inter-\nand intra-observer variability. The literature quantifies observer variability\nby generating consensus among multiple experts when they mark the same image. Automatically building consensus contours to establish quality assurance for\nimage segmentation is presently absent in the clinical practice. As the\n\\emph{big data} becomes more and more available, techniques to access a large\nnumber of existing segments of multiple experts becomes possible. Fast\nalgorithms are, hence, required to facilitate the search for similar cases. The\npresent work puts forward a potential framework that tested with small datasets\n(both synthetic and real images) displays the reliability of finding similar\nimages. In this paper, the idea of content-based barcodes is used to retrieve\nsimilar cases in order to build consensus contours in medical image\nsegmentation. This approach may be regarded as an extension of the conventional\natlas-based segmentation that generally works with rather small atlases due to\nrequired computational expenses. The fast segment-retrieval process via\nbarcodes makes it possible to create and use large atlases, something that\ndirectly contributes to the quality of the consensus building. Because the\naccuracy of experts' contours must be measured, we first used 500 synthetic\nprostate images with their gold markers and delineations by 20 simulated users. The fast barcode-guided computed consensus delivered an average error of\n$8\\%\\!\\pm\\!5\\%$ compared against the gold standard segments. Furthermore, we\nused magnetic resonance images of prostates from 15 patients delineated by 5\noncologists and selected the best delineations to serve as the gold-standard\nsegments. The proposed barcode atlas achieved a Jaccard overlap of","label":"human"}
{"id":226,"text":"The paper \"NeuroNet: Fast and Robust Reproduction of Multiple Brain Image Segmentation Pipelines\" presents a novel approach for reproducing multiple brain image segmentation pipelines with high accuracy and speed. The proposed method, NeuroNet, utilizes a combination of deep learning models and optimized parallel processing to efficiently replicate various segmentation pipelines using a single, optimized template. The paper shows that NeuroNet achieves state-of-the-art segmentation results for multiple brain imaging tasks, and is capable of handling large datasets and complex models with ease. The paper concludes by discussing the implications of NeuroNet for advancing both the accuracy and efficiency of brain image segmentation.","label":"ai"}
{"id":227,"text":"Image segmentation refers to the process to divide an image into\nnonoverlapping meaningful regions according to human perception, which has\nbecome a classic topic since the early ages of computer vision. A lot of\nresearch has been conducted and has resulted in many applications. However,\nwhile many segmentation algorithms exist, yet there are only a few sparse and\noutdated summarizations available, an overview of the recent achievements and\nissues is lacking. We aim to provide a comprehensive review of the recent\nprogress in this field. Covering 180 publications, we give an overview of broad\nareas of segmentation topics including not only the classic bottom-up\napproaches, but also the recent development in superpixel, interactive methods,\nobject proposals, semantic image parsing and image cosegmentation. In addition,\nwe also review the existing influential datasets and evaluation metrics. Finally, we suggest some design flavors and research directions for future\nresearch in image segmentation.","label":"human"}
{"id":228,"text":"> Quantum coherence and quantum correlations are two important resources in quantum information processing. In this paper, we investigate the complementary relation of quantum coherence and quantum correlations in multiple measurements. We first introduce the concept of quantum coherence in multiple measurements and then propose a measure of quantum coherence in multiple measurements. We show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence in multiple measurements is a monotone under the partial trace operation. We also show that the quantum coherence","label":"ai"}
{"id":229,"text":"Video semantic segmentation is a critical task in the field of computer vision that involves segmenting objects and scenes within a video. Although various methods have been developed for this task, they often struggle to handle distortions that can occur in videos, such as camera shake, optical flow errors, and lighting changes. To address this challenge, we propose a novel video semantic segmentation approach that incorporates distortion-aware feature correction. Our method involves first detecting distortions within the video and then applying a correction algorithm to correct for these distortions. We then use the corrected frames to train a deep neural network for semantic segmentation. Our experimental results show that our method outperforms state-of-the-art methods on various video semantic segmentation benchmarks, including two datasets with challenging distortions. These results demonstrate the effectiveness of our approach for improving the accuracy of video semantic segmentation in real-world scenarios.","label":"ai"}
{"id":230,"text":"> In this work, we propose an approach to weakly supervised semantic segmentation that leverages both deep learning and graphical models. Our method uses a convolutional neural network (CNN) as a feature extractor, which learns discriminative features in an unsupervised manner by minimizing the reconstruction error between input images and their reconstructions using learned filters. These CNN-learned features are then used within a Markov random field model with a novel energy function that incorporates spatial constraints on the predicted labels. This allows us to leverage the power of deep learning while also enforcing smoothness and consistency across neighboring pixels. Experiments show that our proposed method outperforms state-of-the-art methods on two challenging histopathological image datasets.","label":"ai"}
{"id":231,"text":"An important statistical task in disease mapping problems is to identify\ndivergent regions with unusually high or low risk of disease. Leave-one-out\ncross-validatory (LOOCV) model assessment is the gold standard for estimating\npredictive p-values that can flag such divergent regions. However, actual LOOCV\nis time-consuming because one needs to rerun a Markov chain Monte Carlo\nanalysis for each posterior distribution in which an observation is held out as\na test case. This paper introduces a new method, called integrated importance\nsampling (iIS), for estimating LOOCV predictive p-values with only Markov chain\nsamples drawn from the posterior based on a full data set. The key step in iIS\nis that we integrate away the latent variables associated the test observation\nwith respect to their conditional distribution \\textit{without} reference to\nthe actual observation. By following the general theory for importance\nsampling, the formula used by iIS can be proved to be equivalent to the LOOCV\npredictive p-value. We compare iIS and other three existing methods in the\nliterature with two disease mapping datasets. Our empirical results show that\nthe predictive p-values estimated with iIS are almost identical to the\npredictive p-values estimated with actual LOOCV, and outperform those given by\nthe existing three methods, namely, the posterior predictive checking, the\nordinary importance sampling, and the ghosting method by Marshall and","label":"human"}
{"id":232,"text":"WAYLA (Wearable Artificial Yaw-Pitch Lens Array) is a novel system that generates high-quality images in real-time based on eye movements. The system consists of a wearable headset equipped with an array of lenses and sensors, which track the user's gaze direction and adjust the image accordingly. This allows users to view images from any angle without physically moving their heads or bodies. The system uses computer vision algorithms to generate high-resolution images that are synchronized with the user's eye movements. It also incorporates machine learning techniques to improve the accuracy and quality of the generated images over time. The results show that WAYLA can significantly enhance the immersive experience of viewing digital content, particularly in applications such as gaming, virtual reality, and augmented reality. Overall, WAYLA represents a significant advancement in the field of interactive computing and has the potential to revolutionize the way we interact with digital media.","label":"ai"}
{"id":233,"text":"Notions of simulation, among other uses, provide a computationally tractable\nand sound (but not necessarily complete) proof method for language inclusion. They have been comprehensively studied by Lynch and Vaandrager for\nnondeterministic and timed systems; for B\\\"{u}chi automata the notion of fair\nsimulation has been introduced by Henzinger, Kupferman and Rajamani. We\ncontribute to a generalization of fair simulation in two different directions:\none for nondeterministic tree automata previously studied by Bomhard; and the\nother for probabilistic word automata with finite state spaces, both under the\nB\\\"{u}chi acceptance condition. The former nondeterministic definition is\nformulated in terms of systems of fixed-point equations, hence is readily\ntranslated to parity games and is then amenable to Jurdzi\\'{n}ski's algorithm;\nthe latter probabilistic definition bears a strong ranking-function flavor. These two different-looking definitions are derived from one source, namely our\ncoalgebraic modeling of B\\\"{u}chi automata. Based on these coalgebraic\nobservations, we also prove their soundness: a simulation indeed witnesses\nlanguage inclusion.","label":"human"}
{"id":234,"text":"Nonlocality tests have been proposed as potential methods to detect hidden variables in quantum mechanics, but all experiments which tested Bell's inequality with loophole-free conditions found results consistent with quantum theory. We propose an alternative method based on Gisin's \"no steering loophole free\" scheme requiring only one measurement at each party (1). Rather than measuring photons individually we suggest two sets of measurements where identical pairs enter both ports and all detectors are coincidence timed rather than individually gated. This creates multiple entanglement between different pairs at either end with two photons per quadrant creating the same overall state distribution predicted by the no-teleportation theorem and thus demonstrating that individual results can not be used teleport information over more than half a distance L = n\/2D. A third set measures entanglement, again locally with a single detector at each site measuring every pair. If this has a higher probability of detecting opposite polarizations than random then it proves there exists some global causal process. ## Proposed Experiment Design\nThe initial experiment will test the locality using one mode per beam but could later expand to multiple modes if resources permit. All sources should give similar brightnesses so no source comparison issues arise, although there may well exist an inherent problem due a difference in relative efficiencies depending upon which path a photon follows between generator and source. In addition, any small differences in path lengths within a channel could affect the results slightly unless they are corrected by optics such as lenses or mirrors at a cost in experimental efficiency. The detection stage needs little explanation other than the use of dichroic filters at front surfaces of polarizers to allow the high peak power beam splitter outputs to access them when switched on without damaging them. It does seem logical though that additional filter options would prevent many unwanted spurious signals caused by high intensity light entering through optical paths unfiltered prior to reaching these devices.","label":"ai"}
{"id":235,"text":"Fully convolutional U-shaped neural networks have largely been the dominant\napproach for pixel-wise image segmentation. In this work, we tackle two defects\nthat hinder their deployment in real-world applications: 1) Predictions lack\nuncertainty quantification that may be crucial to many decision-making systems;\n2) Large memory storage and computational consumption demanding extensive\nhardware resources. To address these issues and improve their practicality we\ndemonstrate a few-parameter compact Bayesian convolutional architecture, that\nachieves a marginal improvement in accuracy in comparison to related work using\nsignificantly fewer parameters and compute operations. The architecture\ncombines parameter-efficient operations such as separable convolutions,\nbilinear interpolation, multi-scale feature propagation and Bayesian inference\nfor per-pixel uncertainty quantification through Monte Carlo Dropout. The best\nperforming configurations required fewer than 2.5 million parameters on diverse\nchallenging datasets with few observations.","label":"human"}
{"id":236,"text":"The paper \"Foundations of Newtonian Dynamics: An Axiomatic Approach for the Thinking Student\" presents a new approach to the study of Newtonian dynamics. The authors argue that the traditional approach to the subject, which relies on the use of equations and calculations, is not sufficient for a thorough understanding of the underlying principles. Instead, they propose an axiomatic approach that emphasizes the fundamental concepts and principles of Newtonian mechanics. The paper begins by introducing the basic concepts of Newtonian mechanics, such as mass, force, and motion. The authors then present a set of axioms that form the foundation of their approach. These axioms include the law of inertia, the law of acceleration, and the law of action and reaction. The authors argue that these axioms are sufficient to derive all of the laws of Newtonian mechanics. The paper then proceeds to demonstrate how the axiomatic approach can be used to solve problems in Newtonian mechanics. The authors provide a number of examples, including the calculation of the trajectory of a projectile and the behavior of a pendulum. They also discuss the limitations of the axiomatic approach and suggest areas for future research. Overall, the paper provides a clear and concise introduction to the foundations of Newtonian dynamics. The axiomatic approach presented in the paper is accessible to students with little prior knowledge of the subject, making it a useful resource for introductory courses in physics.","label":"ai"}
{"id":237,"text":"> We present a new method for constructing a perfect NOT transformation and a conjugate transformation. The method is based on the use of a new type of quantum gate, which we call a \"perfect NOT gate\". The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a quantum state into its conjugate state. The perfect NOT gate is a quantum gate that transforms a","label":"ai"}
{"id":238,"text":"We present near-infrared spectroscopic observations of the high-intensity HeI\n10830 emission line in 45 low-metallicity HII regions. We combined these NIR\ndata with spectroscopic data in the optical range to derive the primordial He\nabundance. The use of the HeI 10830A line, the intensity of which is very\nsensitive to the density of the HII region, greatly improves the determination\nof the physical conditions in the He^+ zone. This results in a considerably\ntighter Y - O\/H linear regression compared to all previous studies. We\nextracted a final sample of 28 HII regions with Hbeta equivalent width\nY derived with an accuracy better than 3%. With this final sample we derived a\nhigher than the one predicted by the standard big bang nucleosynthesis (SBBN)\nchi^2 technique, we found that the best agreement between these light element\nabundances is achieved in a cosmological model with a baryon mass density\nat the 99% CL, implying the possible existence of additional types of neutrino\nspecies.","label":"human"}
{"id":239,"text":"Image segmentation is an important step in most visual tasks. While\nconvolutional neural networks have shown to perform well on single image\nsegmentation, to our knowledge, no study has been been done on leveraging\nrecurrent gated architectures for video segmentation. Accordingly, we propose a\nnovel method for online segmentation of video sequences that incorporates\ntemporal data. The network is built from fully convolutional element and\nrecurrent unit that works on a sliding window over the temporal data. We also\nintroduce a novel convolutional gated recurrent unit that preserves the spatial\ninformation and reduces the parameters learned. Our method has the advantage\nthat it can work in an online fashion instead of operating over the whole input\nbatch of video frames. The network is tested on the change detection dataset,\nand proved to have 5.5\\% improvement in F-measure over a plain fully\nconvolutional network for per frame segmentation. It was also shown to have\nimprovement of 1.4\\% for the F-measure compared to our baseline network that we","label":"human"}
{"id":240,"text":"Physical modeling method, represented by simulation and visualization of the\nprinciples in physics, is introduced in the shape extraction of the active\ncontours. The objectives of adopting this concept are to address the several\nmajor difficulties in the application of Active Contours. Primarily, a\ntechnique is developed to realize the topological changes of Parametric Active\nContours (Snakes). The key strategy is to imitate the process of a balloon\nexpanding and filling in a closed space with several objects. After removing\nthe touched balloon surfaces, the objects can be identified by surrounded\nremaining balloon surfaces. A burned region swept by Snakes is utilized to\ntrace the contour and to give a criterion for stopping the movement of Snake\ncurve. When the Snakes terminates evolution totally, through ignoring this\ncriterion, it can form a connected area by evolving the Snakes again and\ncontinuing the region burning. The contours extracted from the boundaries of\nthe burned area can represent the child snake of each object respectively. Secondly, a novel scheme is designed to solve the problems of leakage of the\ncontour from the large gaps, and the segmentation error in Geometric Active\nContours (GAC). It divides the segmentation procedure into two processing\nstages. By simulating the wave propagating in the isotropic substance at the\nfinal stage, it can significantly enhance the effect of image force in GAC\nbased on Level Set and give the satisfied solutions to the two problems. Thirdly, to support the physical models for active contours above, we introduce\na general image force field created on a template plane over the image plane. This force is more adaptable to noisy images with complicated geometric shapes.","label":"human"}
{"id":241,"text":"We propose a general framework to build certified proofs of distributed\nself-stabilizing algorithms with the proof assistant Coq. We first define in\nCoq the locally shared memory model with composite atomicity, the most commonly\nused model in the self-stabilizing area. We then validate our framework by\ncertifying a non trivial part of an existing silent self-stabilizing algorithm\nwhich builds a $k$-clustering of the network. We also certify a quantitative\nproperty related to the output of this algorithm. Precisely, we show that the\nclusterheads, where $n$ is the number of nodes in the network. To obtain these\nresults, we also developed a library which contains general tools related to\npotential functions and cardinality of sets.","label":"human"}
{"id":242,"text":"In this research, we present a novel architecture called 'Spatial and Channel Squeeze & Excitation' which is applied to fully convolutional networks (FCNs). This design addresses two critical issues that limit their performance: channel overflow and spatial under-utilization. Firstly, we introduce the spatial squeeze operation, a module that shrinks input channels by reducing their dimensionality along the spatial axis, thus preventing channel overload errors. Second, we propose the channel excitation network, a mechanism that learns relevance weights with respect to feature maps across all the channels using attention mechanisms, enabling them to contribute differently while maintaining computational efficiency. We apply these techniques to different benchmark datasets, including the PASCAL VOC 2016 semantic segmentation dataset and MS COCO object detection task, achieving significant improvements over state-of-the-art FCN architectures, including the original FCN model by Faroughi et al. Our results demonstrate the effectiveness of our proposed method, showing superior accuracy and faster training times compared to the competition on challenging tasks like fine-grained object classification and pixel-level semantic segmentation.","label":"ai"}
{"id":243,"text":"Broadly speaking, the objective in cardiac image segmentation is to delineate\nthe outer and inner walls of the heart to segment out either the entire or\nparts of the organ boundaries. This paper will focus on MR images as they are\nthe most widely used in cardiac segmentation -- as a result of the accurate\nmorphological information and better soft tissue contrast they provide. This\ncardiac segmentation information is very useful as it eases physical\nmeasurements that provides useful metrics for cardiac diagnosis such as\ninfracted volumes, ventricular volumes, ejection fraction, myocardial mass,\ncardiac movement, and the like. But, this task is difficult due to the\nintensity and texture similarities amongst the different cardiac and background\nstructures on top of some noisy artifacts present in MR images. Thus far,\nvarious researchers have proposed different techniques to solve some of the\npressing issues. This seminar paper presents an overview of representative\nmedical image segmentation techniques. The paper also highlights preferred\napproaches for segmentation of the four cardiac chambers: the left ventricle\n(LV), right ventricle (RV), left atrium (LA) and right atrium (RA), on short\naxis image planes.","label":"human"}
{"id":244,"text":"Single-photon-counting (SPC) modes of imaging is a method that utilizes the low-count single-photon emission from extended X-ray free-electron lasers (XFELs) to capture 3D images of materials with high spatial resolution. This technique has shown significant potential in various fields such as materials science, biology, and nanotechnology. In this article, we provide a comprehensive overview of the SPC imaging method using XFELs and its applications. We discuss the principles of SPC imaging, the various experimental techniques used to achieve high-quality images, and the recent advancements in this field. We also highlight the challenges and open issues that need to be addressed to further enhance the performance and capabilities of SPC imaging using XFELs. Overall, this article provides a valuable resource for researchers and scientists interested in this promising technique for imaging at the nanoscale.","label":"ai"}
{"id":245,"text":"Crosslink-Net is a novel deep learning model for image segmentation that utilizes a double-branch encoder architecture to fuse both vertical and horizontal convolutions. The model is designed to improve the accuracy and efficiency of image segmentation tasks by leveraging the strengths of both types of convolutions. The vertical branch of the encoder is responsible for capturing spatial information, while the horizontal branch is responsible for capturing contextual information. The two branches are fused using a novel fusion mechanism that combines the outputs of both branches at multiple scales. The model is trained on a large dataset of medical images and achieves state-of-the-art performance on several benchmark tasks. Overall, Crosslink-Net represents a significant advancement in the field of image segmentation and has the potential to revolutionize the way we analyze and interpret medical images.","label":"ai"}
{"id":246,"text":"> Medical imaging has been widely used in clinical diagnosis and treatment, which requires accurate segmentation of organs or tissues to provide quantitative information about their morphology and function. However, manual delineations are time consuming and laborious, especially when dealing with large datasets. In this work, we propose a novel framework that combines deep neural networks (DNNs) and active learning (AL). Specifically, our method consists of two main components: a DNN model trained by AL and a saliency map generator. Firstly, we train a DNN model using only a small number of manually labeled samples via AL. Then, we use the trained DNN model as a teacher network to generate pseudo labels for unlabeled data. Finally, we combine these pseudo labels with the original ones to retrain the DNN model. This process can be iterated until convergence. To further improve the performance of the DNN model, we also design a saliency map generator to guide the selection of informative regions during training. Experimental results show that our proposed approach outperforms state-of-the-art methods in terms of both accuracy and efficiency.","label":"ai"}
{"id":247,"text":"The field of computer vision has seen significant advancements in recent years, with a particular focus on object detection and localization. However, most existing methods are limited to short-term visual tracking or require extensive computational resources. In this study, we propose a novel approach to long-term visual localization that utilizes semantically segmented images. Our method leverages the spatial relationships between objects within an image to estimate their positions over time, without relying on feature extraction or tracking algorithms. We evaluate our approach on several benchmark datasets and demonstrate its effectiveness in accurately localizing objects across multiple frames. Additionally, we explore potential applications in areas such as autonomous vehicles and surveillance systems where real-time tracking is not feasible. Overall, our work represents a significant step towards developing robust and efficient methods for long-term visual localization.","label":"ai"}
{"id":248,"text":"Deep neural networks have achieved tremendous success in various fields\nincluding medical image segmentation. However, they have long been criticized\nfor being a black-box, in that interpretation, understanding and correcting\narchitectures is difficult as there is no general theory for deep neural\nnetwork design. Previously, precision learning was proposed to fuse deep\narchitectures and traditional approaches. Deep networks constructed in this way\nbenefit from the original known operator, have fewer parameters, and improved\ninterpretability. However, they do not yield state-of-the-art performance in\nall applications. In this paper, we propose to analyze deep networks using\nknown operators, by adopting a divide-and-conquer strategy to replace network\ncomponents, whilst retaining its performance. The task of retinal vessel\nsegmentation is investigated for this purpose. We start with a high-performance\nU-Net and show by step-by-step conversion that we are able to divide the\nnetwork into modules of known operators. The results indicate that a\ncombination of a trainable guided filter and a trainable version of the Frangi\nfilter yields a performance at the level of U-Net (AUC 0.974 vs. 0.972) with a\ntrained layers can be mapped back into their original algorithmic\ninterpretation and analyzed using standard tools of signal processing.","label":"human"}
{"id":249,"text":"We report the fabrication of artificial unidimensional crystals exhibiting an\neffective bulk second-order nonlinearity. The crystals are created by cycling\natomic layer deposition of three dielectric materials such that the resulting\nmetamaterial is non-centrosymmetric in the direction of the deposition. Characterization of the structures by second-harmonic generation Maker-fringe\nmeasurements shows that the main component of their nonlinear susceptibility\ntensor is about 5 pm\/V which is comparable to well-established materials and\nmore than an order of magnitude greater than reported for a similar crystal\nopens new possibilities for second-order nonlinear effects on CMOS-compatible\nnanophotonic platforms.","label":"human"}
{"id":250,"text":"Self-Supervision with Superpixels: Training Few-shot Medical Image Segmentation without Annotation\nAbstract:\nMedical image segmentation is a crucial task in the field of healthcare, but it requires a large amount of labeled data for training. However, obtaining annotated data is time-consuming and expensive. In this paper, we propose a novel approach to train few-shot medical image segmentation models without annotation. Our approach utilizes self-supervision with superpixels to generate synthetic annotations for training. We demonstrate the effectiveness of our approach on several benchmark datasets, achieving state-of-the-art performance with significantly fewer labeled examples. Our work has the potential to revolutionize the field of medical image segmentation by enabling the training of models on large-scale datasets with limited annotation resources.","label":"ai"}
{"id":251,"text":"The purpose of this paper is to provide analytical and numerical solutions of\nthe formation and evolution of the localized plastic zone in a uniaxially\nloaded bar with variable cross-sectional area. An energy-based variational\napproach is employed and the governing equations with appropriate physical\nboundary conditions, jump conditions, and regularity conditions at evolving\nelasto-plastic interface are derived for a fourth-order explicit gradient\nplasticity model with linear isotropic softening. Four examples that differ by\nregularity of the yield stress and stress distributions are presented. Results\nfor the load level, size of the plastic zone, distribution of plastic strain\nand its spatial derivatives, plastic elongation, and energy balance are\nconstructed and compared to another, previously discussed non-variational\ngradient formulation.","label":"human"}
{"id":252,"text":"Semantic segmentation models trained on public datasets have achieved great\nsuccess in recent years. However, these models didn't consider the\npersonalization issue of segmentation though it is important in practice. In\nthis paper, we address the problem of personalized image segmentation. The\nobjective is to generate more accurate segmentation results on unlabeled\npersonalized images by investigating the data's personalized traits. To open up\nfuture research in this area, we collect a large dataset containing various\nusers' personalized images called PIS (Personalized Image Semantic\nSegmentation). We also survey some recent researches related to this problem\nand report their performance on our dataset. Furthermore, by observing the\ncorrelation among a user's personalized images, we propose a baseline method\nthat incorporates the inter-image context when segmenting certain images. Extensive experiments show that our method outperforms the existing methods on\nthe proposed dataset. The code and the PIS dataset will be made publicly\navailable.","label":"human"}
{"id":253,"text":"S-folds are generalizations of orientifolds in type IIB string theory, such\nthat the geometric identifications are accompanied by non-trivial S-duality\ntransformations. They were recently used by Garcia-Etxebarria and Regalado to\nprovide the first construction of four dimensional N=3 superconformal theories. In this note, we classify the different variants of these N=3 preserving\nS-folds, distinguished by an analog of discrete torsion, using both a direct\nanalysis of the different torsion classes and the compactification of the\nS-folds to three dimensional M-theory backgrounds. Upon adding D3-branes, these\nvariants lead to different classes of N=3 superconformal field theories. We\nalso analyze the holographic duals of these theories, and in particular clarify\nthe role of discrete gauge and global symmetries in holography. In the main part of the paper, certain properties of cohomology groups\nassociated to the S-folds were conjectured and used. This arXiv version\nincludes an appendix written by Kiyonori Gomi in 2023 providing the proofs of\nthe required properties using the technique of Borel equivariant cohomology,\nwhose brief review is also provided.","label":"human"}
{"id":254,"text":"Hirzebruch-type inequalities are a fundamental result in algebraic topology that relate the homotopy groups of a topological space to its homology groups. In this paper, we study the implications of these inequalities for plane curve configurations, which are collections of plane curves in a complex plane. We show that the Hirzebruch-type inequalities can be used to determine the number of distinct plane curve configurations that can be obtained by perturbing a given configuration. We also prove that the Hirzebruch-type inequalities can be used to determine the number of distinct plane curve configurations that can be obtained by perturbing a given configuration while preserving certain topological invariants, such as the genus or the number of singular points. Our results have applications in various areas of mathematics, including algebraic geometry, topology, and computer science.","label":"ai"}
{"id":255,"text":"We propose an active learning approach to image segmentation that exploits\ngeometric priors to speed up and streamline the annotation process. It can be\napplied for both background-foreground and multi-class segmentation tasks in 2D\nimages and 3D image volumes. Our approach combines geometric smoothness priors\nin the image space with more traditional uncertainty measures to estimate which\npixels or voxels are the most informative, and thus should to be annotated\nnext. For multi-class settings, we additionally introduce two novel criteria\nfor uncertainty. In the 3D case, we use the resulting uncertainty measure to\nselect voxels lying on a planar patch, which makes batch annotation much more\nconvenient for the end user compared to the setting where voxels are randomly\ndistributed in a volume. The planar patch is found using a branch-and-bound\nalgorithm that looks for a 2D patch in a 3D volume where the most informative\ninstances are located. We evaluate our approach on Electron Microscopy and\nMagnetic Resonance image volumes, as well as on regular images of horses and\nfaces. We demonstrate a substantial performance increase over other approaches\nthanks to the use of geometric priors.","label":"human"}
{"id":256,"text":"> We study Hamiltonian $S^1$-actions on compact symplectic manifolds $(M,\\omega)$ which have only finitely many isolated fixed points and are minimal in the sense that every orbit is dense. In particular, we show that if such an action has at least two fixed points then it must be linearizable by a symplectomorphism. This answers a question posed by Ginzburg-Gusein-Zade [GG] and improves upon results of Lerman [L], who showed that any such action with more than one fixed point is either linearizable or conjugate to a rotation on $\\mathbb{C}P^{n}$. Our proof uses a combination of techniques including equivariant Morse theory, Floer homology, and the Atiyah-Bott fixed point formula.","label":"ai"}
{"id":257,"text":"Suppose you're on a game show, and you're given the choice of three doors:\nBehind one door is a car; behind the others, goats. You pick a door, say No. 1,\nand the host, who knows what's behind the doors, opens another door, say No. 3,\nwhich has a goat. He then says to you, ``Do you want to pick door No. 2?'' Is\nit to your advantage to switch your choice? The answer is ``yes'' but the\nliterature offers many reasons why this is the correct answer. The present\npaper argues that the most common reasoning found in introductory statistics\ntexts, depending on making a number of ``obvious'' or ``natural'' assumptions\nand then computing a conditional probability, is a classical example of\nsolution driven science. The best reason to switch is to be found in von\nNeumann's minimax theorem from game theory, rather than in Bayes' theorem.","label":"human"}
{"id":258,"text":"Task decomposition and synchronization are two important techniques used in semantic biomedical image segmentation. In this paper, we present a comprehensive review of these methods and their applications in medical imaging. We discuss how task decomposition involves breaking down complex tasks into smaller sub-tasks that can be performed independently, while synchronization ensures that all sub-tasks are executed simultaneously to produce accurate results. We also explore different approaches to task decomposition and synchronization, including parallel processing, distributed computing, and hybrid models. We provide examples of successful implementations of these techniques in various medical imaging applications, such as brain tumor detection, lung cancer diagnosis, and cardiac function analysis. Overall, our review highlights the importance of task decomposition and synchronization in improving the accuracy and efficiency of semantic biomedical image segmentation, which has significant implications for clinical decision making and patient outcomes.","label":"ai"}
{"id":259,"text":"> This work describes an architecture for Quantitative Finite State Machine Transducer (QLM-FSMT), where QLM-FSMTs are extensions to FSMTs with quantitative values used in describing complex dynamic scenarios, which can be mapped between two different domains, i.e., states and actions. In this design, we introduce two basic structures -- probabilistic state transition function with probability value as data type representing real numbers along with nonnegative values less than or equal to 1 for state transitions; and probabilistic observation rule that calculates conditional probability given particular combinations of observations for actions within probabilistic semantic domain mapping multiple action sequences onto single state sequence by observing system behaviors on continuous streams of events over time for modeling complex systems involving interactions among concurrent processes. QLM-FSMT combines finite state machine properties based on automaton theory while including conditional probability measures in their definitions so they are not limited only during state changes\/transitions nor do they provide concrete evidence about occurrence likelihood due uncertainty factor associated with event generation, thus providing flexibility in modeling uncertain behaviors as well as capturing dependencies across related objects when applied accordingly based upon problem scenario definition required at start up before execution begins depending upon how user defines relevant set inputs needed prior proceeding further into more elaborate phases thereafter after completing initialization stage successfully via successful configuration checker running tests against predetermined list criteria defining minimum requirement levels necessary achieving desired objectives specified ahead time without delay afterwards leading towards positive conclusion meeting standards expected accomplishing established goals originally desired since beginning undertaking project planning phase initially scheduled months prior completion task deadline approaching soon fast approaches final end result outcome shortly later awaited eagerly by all participants involved regardless role level assigned specifically contributing overall progress significantly throughout entire lifecycle development cycle ongoing activity continuously until done completeness achieved satisfactory satisfaction everybody satisfied contented agreement everyone happy working together harmoniously smoothly efficiently cooperatively interactively coordinated properly synchronously congruently unified united solidarity strongly bond team member spirit motivation enthusiasm inspiration courage willingness determined resolve persistent effort determination dedication commitment loyalty trust integrity honesty ethics morals principles character behavior conduct respect polite courtesy kindness care civility gentleness tenderness delicacy refinement decorum sophistication propriety tact etiquette grace poise self control discipline orderliness neat clean tid","label":"ai"}
{"id":260,"text":"The paper presents a novel approach to simultaneous traffic sign detection and boundary estimation using convolutional neural network (CNN). The proposed method utilizes a multi-task CNN architecture that simultaneously predicts traffic signs and their boundaries in images. The model is trained on a large dataset of annotated images, which includes both traffic sign detection and boundary estimation tasks. The results show that the proposed method outperforms state-of-the-art methods in both tasks, achieving high accuracy and robustness. The paper also discusses the importance of data augmentation techniques in improving the performance of the model. Overall, this work contributes to the development of more accurate and efficient systems for traffic sign recognition and delineation.","label":"ai"}
{"id":261,"text":"ABSTRACT: A quantum semi-(quasi)group has been introduced and studied in previous works as an analogue of a classical semi-(quasi)- group, and the concept has already appeared in various contexts such as statistical mechanics, number theory, noncommutative geometry, deformation quantization etc.. It has also recently become clear that it is necessary to understand precisely when quantum semi-groups are quantum groups, justifying this interpolation scale between Lie algebras (quantum commutative objects) and Hopf *C*astings (the most natural class of quantum homogeneous spaces). In particular, if one aims at developing noncommutative versions of differential geometric notions on quantum homogeneous spaces which are compatible with those over the base algebra, then these compatibility properties cannot be expected to hold outside closed subalgebras satisfying a certain \"Baum-Connes property\". Hence the notion we wish to investigate is essentially the noncommutative counterpart of \"boundary\" or \"corner subalgebra\", where boundary can itself vary from smooth manifolds to topological ones like locally compact Hausdorff spaces. Our result amounts to saying roughly speaking that a generalized Leavitt path algebra, viewed as a quantum semidirect product associated with its center and some other graph data, satisfies our Baum- Connes condition whenever the corresponding quantum direct product does it. Keywords: noncommtave geometry; differential geometry; quantum groupoid; operator algebra; quantun semigroup","label":"ai"}
{"id":262,"text":"Sunspot number series are subject to various uncertainties, which are still\npoorly known. The need for their better understanding was recently highlighted\nby the major makeover of the international Sunspot Number [Clette et al., Space\nScience Reviews, 2014]. We present the first thorough estimation of these\nuncertainties, which behave as Poisson-like random variables with a\nmultiplicative coefficient that is time- and observatory-dependent. We provide\na simple expression for these uncertainties, and reveal how their evolution in\ntime coincides with changes in the observations, and processing of the data. Knowing their value is essential for properly building composites out of\nmultiple observations, and for preserving the stability of the composites in\ntime.","label":"human"}
{"id":263,"text":"Despite deep convolutional neural networks achieved impressive progress in\nmedical image computing and analysis, its paradigm of supervised learning\ndemands a large number of annotations for training to avoid overfitting and\nachieving promising results. In clinical practices, massive semantic\nannotations are difficult to acquire in some conditions where specialized\nbiomedical expert knowledge is required, and it is also a common condition\nwhere only few annotated classes are available. In this work, we proposed a\nnovel method for few-shot medical image segmentation, which enables a\nsegmentation model to fast generalize to an unseen class with few training\nimages. We construct our few-shot image segmentor using a deep convolutional\nnetwork trained episodically. Motivated by the spatial consistency and\nregularity in medical images, we developed an efficient global correlation\nmodule to capture the correlation between a support and query image and\nincorporate it into the deep network called global correlation network. Moreover, we enhance discriminability of deep embedding to encourage clustering\nof the feature domains of the same class while keep the feature domains of\ndifferent organs far apart. Ablation Study proved the effectiveness of the\nproposed global correlation module and discriminative embedding loss. Extensive\nexperiments on anatomical abdomen images on both CT and MRI modalities are\nperformed to demonstrate the state-of-the-art performance of our proposed\nmodel.","label":"human"}
{"id":264,"text":"Holes and cracks are common defects that can occur in rigid foam materials, which have widespread use in various applications such as insulation, packaging, and aerospace. In this study, we investigate the properties of holes and cracks in rigid foam films through experimental characterization and modeling using finite element analysis (FEA). We examine different types of foam architectures, including monolayer foams, sandwich structures, and honeycomb-like frameworks, to understand their susceptibility to form these defects. Our results indicate that the density and geometry of foam cells play critical roles in determining the propagation behavior of hole formation. We also evaluate the effect of temperature on hole growth and find that it is enhanced at higher temperatures due to increased thermal expansion. Additionally, our FEA simulations reveal that the presence of support structures around holes significantly reduces the probability of crack initiation. Overall, our findings provide fundamental insights into damage mechanics in rigid foam materials, helping guide future design strategies aimed at enhancing their robustness against environmental stressors.","label":"ai"}
{"id":265,"text":"A simple method is proposed for inclusion of inelastic effects (electron\nabsorption) in computations of low-energy electron reflectivity (LEER) spectra. The theoretical spectra are formulated by matching of electron wavefunctions\nobtained from first-principles computations in a repeated vacuum-slab-vacuum\ngeometry. Inelastic effects are included by allowing these states to decay in\ntime in accordance with an imaginary term in the potential of the slab, and by\nmixing of the slab states in accordance with the same type of distribution as\noccurs in a free-electron model. LEER spectra are computed for various\ntwo-dimensional materials, including free-standing multilayer graphene,\ngraphene on copper substrates, and hexagonal boron nitride (h-BN) on cobalt\nsubstrates.","label":"human"}
{"id":266,"text":"The sigma point (SP) filter, also known as unscented Kalman filter, is an\nattractive alternative to the extended Kalman filter and the particle filter. Here, we extend the SP filter to nonsequential Bayesian inference corresponding\nto loopy factor graphs. We propose sigma point belief propagation (SPBP) as a\nlow-complexity approximation of the belief propagation (BP) message passing\nscheme. SPBP achieves approximate marginalizations of posterior distributions\ncorresponding to (generally) loopy factor graphs. It is well suited for\ndecentralized inference because of its low communication requirements. For a\ndecentralized, dynamic sensor localization problem, we demonstrate that SPBP\ncan outperform nonparametric (particle-based) BP while requiring significantly\nless computations and communications.","label":"human"}
{"id":267,"text":"In multi-organ segmentation of abdominal CT scans, most existing fully\nsupervised deep learning algorithms require lots of voxel-wise annotations,\nwhich are usually difficult, expensive, and slow to obtain. In comparison,\nmassive unlabeled 3D CT volumes are usually easily accessible. Current\nmainstream works to address the semi-supervised biomedical image segmentation\nproblem are mostly graph-based. By contrast, deep network based semi-supervised\nlearning methods have not drawn much attention in this field. In this work, we\npropose Deep Multi-Planar Co-Training (DMPCT), whose contributions can be\ndivided into two folds: 1) The deep model is learned in a co-training style\nwhich can mine consensus information from multiple planes like the sagittal,\ncoronal, and axial planes; 2) Multi-planar fusion is applied to generate more\nreliable pseudo-labels, which alleviates the errors occurring in the\npseudo-labels and thus can help to train better segmentation networks. Experiments are done on our newly collected large dataset with 100 unlabeled\ncases as well as 210 labeled cases where 16 anatomical structures are manually\nannotated by four radiologists and confirmed by a senior expert. The results\nsuggest that DMPCT significantly outperforms the fully supervised method by\nmore than 4% especially when only a small set of annotations is used.","label":"human"}
{"id":268,"text":"Segmentation of wear particles in medical images is a challenging task due to the small size and variabilities in these particles. In this study, we propose a deep learning-based approach to segment wear particles in MRI images with few labelled data and imbalanced samples. Our method utilizes an encoder-decoder architecture with skip connections and attention mechanisms to improve the segmentation accuracy. To address the issue of imbalanced samples, we propose two techniques: (i) Synthetic data augmentation to generate synthetic samples, which helps in increasing the size of the minority class, and (ii) Class weighting to adjust the contribution of minority and majority classes during training. We evaluate our method on the publicly available ADNI-LD dataset and demonstrate superior segmentation accuracy compared to state-of-the-art methods. Our results suggest that our method can be used for automatic segmentation of wear particles in MRI images with fewer labelled data and imbalance samples.","label":"ai"}
{"id":269,"text":"The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car.","label":"human"}
{"id":270,"text":"A stable generalized complex structure is one that is generically symplectic\nbut degenerates along a real codimension two submanifold, where it defines a\ngeneralized Calabi-Yau structure. We introduce a Lie algebroid which allows us\nto view such structures as symplectic forms. This allows us to construct new\nexamples of stable structures, and also to define period maps for their\ndeformations in which the background three-form flux is either fixed or not,\nproving the unobstructedness of both deformation problems. We then use the same\ntools to establish local normal forms for the degeneracy locus and for\nLagrangian branes. Applying our normal forms to the four-dimensional case, we\nprove that any compact stable generalized complex 4-manifold has a symplectic\ncompletion, in the sense that it can be modified near its degeneracy locus to\nproduce a compact symplectic 4-manifold.","label":"human"}
{"id":271,"text":"This work presents use of Fully Convolutional Network (FCN-8) for semantic\nsegmentation of high-resolution RGB earth surface satel-lite images into land\nuse land cover (LULC) categories. Specically, we propose a non-overlapping\ngrid-based approach to train a Fully Convo-lutional Network (FCN-8) with vgg-16\nweights to segment satellite im-ages into four (forest, built-up, farmland and\nwater) classes. The FCN-8 semantically projects the discriminating features in\nlower resolution learned by the encoder onto the pixel space in higher\nresolution to get a dense classi cation. We experimented the proposed system\nwith Gaofen-2 image dataset, that contains 150 images of over 60 di erent\ncities in china. For comparison, we used available ground-truth along with\nimages segmented using a widely used commeriial GIS software called\neCogni-tion. With the proposed non-overlapping grid-based approach, FCN-8\nobtains signi cantly improved performance, than the eCognition soft-ware. Our\nmodel achieves average accuracy of 91.0% and average Inter-section over Union\n(IoU) of 0.84. In contrast, eCognitions average accu-racy is 74.0% and IoU is\n0.60. This paper also reports a detail analysis of errors occurred at the LULC\nboundary.","label":"human"}
{"id":272,"text":"> Quantum causal models (QCMs) are a generalization of causal models to the quantum domain. They are a powerful tool for reasoning about causal structure in quantum systems. In this paper, we study the faithfulness of QCMs, i.e., the extent to which the causal structure of a QCM is reflected in the correlations between its variables. We show that the faithfulness of a QCM is determined by the causal structure of its underlying classical causal model and the quantum correlations between its variables. We also show that the faithfulness of a QCM is preserved under certain transformations, such as marginalization and conditioning. Finally, we discuss the implications of our results for the study of causal structure in quantum systems. The paper is available here.","label":"ai"}
{"id":273,"text":"> In this work, we propose an encoder-decoder architecture with fully connected conditional random fields (FC-CRF) to segment remote sensed images into land cover classes. We use convolutional neural networks (CNNs) as our encoders which are trained on large scale datasets such as Places365 and ImageNet. Our decoders consist of FC-CRF layers that take in features extracted by the encoders and produce pixel level predictions. To train our model, we introduce a new dataset called AIDA consisting of 1000 high resolution satellite images covering different regions around the world. Each image has been manually labeled at the pixel level using Google Earth Engine. We evaluate our method on two publicly available benchmark datasets namely CamVid and DIOR. On both these datasets, our proposed approach outperforms state-of-the-art methods.","label":"ai"}
{"id":274,"text":"We propose to adapt segmentation networks with a constrained formulation,\nwhich embeds domain-invariant prior knowledge about the segmentation regions. Such knowledge may take the form of simple anatomical information, e.g.,\nstructure size or shape, estimated from source samples or known a priori. Our\nmethod imposes domain-invariant inequality constraints on the network outputs\nof unlabeled target samples. It implicitly matches prediction statistics\nbetween target and source domains with permitted uncertainty of prior\nknowledge. We address our constrained problem with a differentiable penalty,\nfully suited for standard stochastic gradient descent approaches, removing the\nneed for computationally expensive Lagrangian optimization with dual\nprojections. Unlike current two-step adversarial training, our formulation is\nbased on a single loss in a single network, which simplifies adaptation by\navoiding extra adversarial steps, while improving convergence and quality of\ntraining. The comparison of our approach with state-of-the-art adversarial methods\nreveals substantially better performance on the challenging task of adapting\nspine segmentation across different MRI modalities. Our results also show a\nrobustness to imprecision of size priors, approaching the accuracy of a fully\nsupervised model trained directly in a target domain.Our method can be readily\nused for various constraints and segmentation problems.","label":"human"}
{"id":275,"text":"The study of profinite complexes of curves is a fundamental area in algebraic geometry. In this paper, we explore the automorphism groups and anabelian properties of moduli stacks of curves. We begin by defining profinite complexes of curves and discussing some basic results about them. We then focus on the automorphism groups of these complexes, showing that they are always profinite and have certain nice properties. Finally, we discuss the anabelian properties of these complexes, including their relation to the classical modular forms and their connection to the arithmetic geometry. Our main result shows that the moduli stack of curves with profinite complexes has many interesting anabelian properties, which can be used to study various aspects of number theory and algebraic geometry.","label":"ai"}
{"id":276,"text":"Infinite traces have emerged as a versatile mathematical framework to study continuous non-linear behaviors, including those associated with dynamic systems, control theory, and quantum mechanics. Coalgebraic infinite traces have been introduced recently as a generalization of the classical infinite traces to non-commutative settings. In this paper, we provide a comprehensive overview of coalgebraic infinite traces and their key properties. We first introduce coalgebraic structures and relate them to the non-commutative setting of coalgebraic infinite traces. We then explore various algebraic and combinatorial properties of coalgebraic infinite traces, including their Kleisli category structure and their connection to topology. Our main focus is on defining Kleisli simulations for coalgebraic infinite traces and studying their properties. We derive new results on Kleisli simulations, including characterizations of their existence and uniqueness, as well as their relationships with other important concepts, such as liftings and extensions. Our work opens new avenues for future research on continuous non-linear behaviors, and has implications for applications in control theory, quantum mechanics, and other areas.","label":"ai"}
{"id":277,"text":"Accurate segmentation of different sub-regions of gliomas including\nperitumoral edema, necrotic core, enhancing and non-enhancing tumor core from\nmultimodal MRI scans has important clinical relevance in diagnosis, prognosis\nand treatment of brain tumors. However, due to the highly heterogeneous\nappearance and shape, segmentation of the sub-regions is very challenging. Recent development using deep learning models has proved its effectiveness in\nthe past several brain segmentation challenges as well as other semantic and\nmedical image segmentation problems. Most models in brain tumor segmentation\nuse a 2D\/3D patch to predict the class label for the center voxel and variant\npatch sizes and scales are used to improve the model performance. However, it\nhas low computation efficiency and also has limited receptive field. U-Net is a\nwidely used network structure for end-to-end segmentation and can be used on\nthe entire image or extracted patches to provide classification labels over the\nentire input voxels so that it is more efficient and expect to yield better\nperformance with larger input size. Furthermore, instead of picking the best\nnetwork structure, an ensemble of multiple models, trained on different dataset\nor different hyper-parameters, can generally improve the segmentation\nperformance. In this study we propose to use an ensemble of 3D U-Nets with\ndifferent hyper-parameters for brain tumor segmentation. Preliminary results\nshowed effectiveness of this model. In addition, we developed a linear model\nfor survival prediction using extracted imaging and non-imaging features,\nwhich, despite the simplicity, can effectively reduce overfitting and\nregression errors.","label":"human"}
{"id":278,"text":"> In recent years the use of Convolutional Neural Networks (CNNs) for detecting fruits from trees has increased, and there has been significant progress in automating tasks such as fruit segmentation, size estimation, counting and sorting. In most cases though, only supervised learning is used for training. In this work we study the potential of combining Supervised and Un-supervised methods for the automatic segmentation of citrus from trees (orange, tangerine, lemon, lime, and grapefruit). We use a CNN trained with supervised learning for feature extraction and we train two CNNs using Un-supervised learning for clustering and image segmentation. We investigate the effect of different pre and post-processing methods to each CNN and show that it is possible to obtain pixel level segmentation that outperforms state of the art results published recently.","label":"ai"}
{"id":279,"text":"This paper presents a method for segmenting iris images obtained from the\ndeceased subjects, by training a deep convolutional neural network (DCNN)\ndesigned for the purpose of semantic segmentation. Post-mortem iris recognition\nhas recently emerged as an alternative, or additional, method useful in\nforensic analysis. At the same time it poses many new challenges from the\ntechnological standpoint, one of them being the image segmentation stage, which\nhas proven difficult to be reliably executed by conventional iris recognition\nmethods. Our approach is based on the SegNet architecture, fine-tuned with\n1,300 manually segmented post-mortem iris images taken from the\nWarsaw-BioBase-Post-Mortem-Iris v1.0 database. The experiments presented in\nthis paper show that this data-driven solution is able to learn specific\ndeformations present in post-mortem samples, which are missing from alive\nirises, and offers a considerable improvement over the state-of-the-art,\nconventional segmentation algorithm (OSIRIS): the Intersection over Union (IoU)\nmetric was improved from 73.6% (for OSIRIS) to 83% (for DCNN-based presented in\nthis paper) averaged over subject-disjoint, multiple splits of the data into\ntrain and test subsets. This paper offers the first known to us method of\nautomatic processing of post-mortem iris images. We offer source codes with the\ntrained DCNN that perform end-to-end segmentation of post-mortem iris images,\nas described in this paper. Also, we offer binary masks corresponding to manual\nsegmentation of samples from Warsaw-BioBase-Post-Mortem-Iris v1.0 database to\nfacilitate development of alternative methods for post-mortem iris\nsegmentation.","label":"human"}
{"id":280,"text":"> We propose an iterative inference algorithm to segment images into regions with similar properties, such as color or texture. Our method uses conditional score estimation (CSE) [1] to estimate the probability that each pixel belongs to one region given all other pixels and their labels. This allows us to use any classifier trained on labeled data to perform unsupervised image segmentation. CSE has been shown to be effective at estimating these probabilities when applied directly to the raw input features. However, we show that it can also be used to improve upon state-of-the-art methods based on deep convolutional neural networks (DCNNs). Specifically, our approach outperforms previous DCNN-based approaches on several benchmark datasets while using fewer parameters and requiring less training time.","label":"ai"}
{"id":281,"text":"Image segmentation and image restoration are two important topics in image\nprocessing with great achievements. In this paper, we propose a new multiphase\nsegmentation model by combining image restoration and image segmentation\nmodels. Utilizing image restoration aspects, the proposed segmentation model\ncan effectively and robustly tackle high noisy images, blurry images, images\nwith missing pixels, and vector-valued images. In particular, one of the most\nimportant segmentation models, the piecewise constant Mumford-Shah model, can\nbe extended easily in this way to segment gray and vector-valued images\ncorrupted for example by noise, blur or missing pixels after coupling a new\ndata fidelity term which comes from image restoration topics. It can be solved\nefficiently using the alternating minimization algorithm, and we prove the\nconvergence of this algorithm with three variables under mild condition. Experiments on many synthetic and real-world images demonstrate that our method\ngives better segmentation results in comparison to others state-of-the-art\nsegmentation models especially for blurry images and images with missing pixels\nvalues.","label":"human"}
{"id":282,"text":"Nominal Logic is a version of first-order logic with equality, name-binding,\nrenaming via name-swapping and freshness of names. Contrarily to higher-order\nlogic, bindable names, called atoms, and instantiable variables are considered\nas distinct entities. Moreover, atoms are capturable by instantiations,\nbreaking a fundamental principle of lambda-calculus. Despite these differences,\nnominal unification can be seen from a higher-order perspective. From this\nview, we show that nominal unification can be reduced to a particular fragment\nof higher-order unification problems: Higher-Order Pattern Unification. This\nreduction proves that nominal unification can be decided in quadratic\ndeterministic time, using the linear algorithm for Higher-Order Pattern\nUnification. We also prove that the translation preserves most generality of\nunifiers.","label":"human"}
{"id":283,"text":"> We present SFCG, an approach to 3D segmentation that learns voxel classifiers with shape fully convolutional neural networks (SFCNs). Classifier predictions on individual voxels are propagated through dense graph structures defined by spatial adjacency or higher-order neighborhood relationships between neighboring voxels to obtain labels to which segments at various levels of granularity correspond respectively; localization and global surface coherence can be enforced if such graph structures impose meaningful constraints upon labels they contain via label propagation procedures. To make training viable in high dimension and to encourage consistency between predictions made at different depths within SFCN stacks while encouraging label refinement as information about surrounding context becomes available, the proposed framework leverages shared weighting for all layers. By demonstrating results and ablation studies across multiple datasets of medical images as well as a challenging point cloud dataset from object recognition literature, we prove that deep learning enables promising performance even when facing tasks not originally intended as targets during network training. In addition, our approach naturally extends beyond binary segmentations into multi-label cases and achieves state-of-the-art multi-tissue segmentation over BrainWeb MRI simulated scans, outperforming previous methods without the need for extra preprocessing steps required therein nor any use of any other datasets, despite being trained exclusively on one particular domain of data which does not have equivalent ground truth labels provided; this generalizability may also explain why our algorithm delivers strong performance without modification on a point cloud segmentation task whose input modality differs radically from the volumetric ones typically preferred in machine learning applications.","label":"ai"}
{"id":284,"text":"We tackle biomedical image segmentation in the scenario of only a few labeled\nbrain MR images. This is an important and challenging task in medical\napplications, where manual annotations are time-consuming. Current multi-atlas\nbased segmentation methods use image registration to warp segments from labeled\nimages onto a new scan. In a different paradigm, supervised learning-based\nsegmentation strategies have gained popularity. These method consistently use\nrelatively large sets of labeled training data, and their behavior in the\nregime of a few labeled biomedical images has not been thoroughly evaluated. In\nthis work, we provide two important results for segmentation in the scenario\nwhere few labeled images are available. First, we propose a straightforward\nimplementation of efficient semi-supervised learning-based registration method,\nwhich we showcase in a multi-atlas segmentation framework. Second, through an\nextensive empirical study, we evaluate the performance of a supervised\nsegmentation approach, where the training images are augmented via random\ndeformations. Surprisingly, we find that in both paradigms, accurate\nsegmentation is generally possible even in the context of few labeled images.","label":"human"}
{"id":285,"text":"Fast solvers are essential in solving complex problems involved with unsteady thermal fluid structure interaction (TFSI). TFSI involves modeling of heat transfer from fluid to structural components, and its effects on other physical parameters such as deformation and stress. In this context, accurate computational methods that can incorporate these interactions and provide real-time results are critical to advances in fields including aerospace engineering, automotive design, and building HVAC systems. In this study, we present an approach based on parallel computing techniques that enables efficient fast solution of large scale TFSI simulations. The numerical scheme used is based on time integration algorithms and includes several stabilizing mechanisms to ensure accuracy while preserving stability. We show how our method achieves significantly better performance over existing solvers, especially when dealing with complex geometries or large fluid flows that require high spatial resolution. Furthermore, our algorithm also provides robust control over error and convergence during simulations by utilizing adaptive mesh refinement strategies. We report simulation results obtained using our proposed algorithm, where various scenarios have been explored - such as flow turbulence models and different levels of detail on boundaries and interfaces. Our findings demonstrate that our method accurately captures the dynamics of TFSI interactions and has great potential to optimize their impact on various system design criteria, such as response times, energy consumption and cost efficiency. Overall, our work presents a significant contribution towards the development of reliable and scalable tools for predictive analysis of thermal processes involving fluid motion around flexible structures.","label":"ai"}
{"id":286,"text":"The measurement-device-independent quantum key distribution (MDI-QKD)\nprotocol has been proposed for the purpose of removing the detector side\nchannel attacks. Due to the multi-photon events of coherent states sources,\nreal-life implementations of MDI-QKD protocol must employ decoy states to beat\nthe photon-number-splitting attack. Decoy states for MDI-QKD based on the weak\ncoherent states have been studied recently. In this paper, we propose to\nperform MDI-QKD protocol with modified coherent states (MCS) sources. We\nsimulate the performance of MDI-QKD with the decoy states based on MCS sources. And our simulation indicates that both the secure-key rate and transmission\ndistance can be improved evidently with MCS sources.The physics behind this\nimprovement is that the probability of multi-photon events of the MCS is lower\nthan that of weak coherent states while at the same time the probability of\nsingle-photon is higher.","label":"human"}
{"id":287,"text":"> In this paper, we propose a novel unsupervised color image segmentation method based on the Voronoi region. The proposed method is based on the assumption that the color distribution of each region is uniform. The proposed method is composed of two steps. In the first step, the Voronoi region is constructed based on the color distribution of the image. In the second step, the Voronoi region is divided into several sub-regions based on the color distribution of the image. The proposed method is evaluated on the Berkeley Segmentation Dataset and the MSRC-21 dataset. The experimental results show that the proposed method can achieve better segmentation results than the state-of-the-art methods. The following is the full text of the abstract for a research paper titled \"Voronoi Region-Based Adaptive Unsupervised Color Image Segmentation\" from arxiv.org:\n> In this paper, we propose a novel unsupervised color image segmentation method based on the Voronoi region. The proposed method is based on the assumption that the color distribution of each region is uniform. The proposed method is composed of two steps. In the first step, the Voronoi region is constructed based on the color distribution of the image. In the second step, the Voronoi region is divided into several sub-regions based on the color distribution of the image. The proposed method is evaluated on the Berkeley Segmentation Dataset and the MSRC-21 dataset. The experimental results show that the proposed method can achieve better segmentation results than the state-of-the-art methods. The following is the full text of the abstract for a research paper titled \"Voronoi Region-Based Adaptive Unsupervised Color Image Segmentation\" from arxiv.org:\n> In this paper, we propose a novel unsupervised color image segmentation method based on the Voronoi region. The proposed method is based on the assumption that the color distribution of each region is uniform. The proposed method is composed of two steps. In the first step, the Voronoi region is constructed based on the color distribution of the image. In the second step, the Voronoi region is","label":"ai"}
{"id":288,"text":"The purpose of this study is to propose a novel algorithm for image labeling that uses neural networks and a multiresolution approach. This algorithm combines Markov chains with deep learning models, allowing for more accurate and efficient image classification at various scales. The proposed approach involves first converting the input image into multiple levels of representation using a convolutional neural network (CNN). Then, each level of representation is processed through a Markov chain model to generate a sequence of labels. These labels are then combined to produce the final output, which can be interpreted as a probability distribution over different categories or classes within the image. To evaluate the performance of the algorithm, experiments were conducted on several benchmark datasets, including COCO, VOC, and DVOC-17. Results showed significant improvements in accuracy compared to traditional methods, as well as greater robustness to variations in illumination and perspective. Additionally, the algorithm was able to handle large images effectively without sacrificing computational efficiency. Overall, this study demonstrates the potential of combining machine learning techniques from both computer vision and statistical physics to improve image analysis tasks.","label":"ai"}
{"id":289,"text":"In recent years deep CNNs have achieved state-of-the-art performance on many tasks related to image classification, including semantic (pixelwise) segmentation via direct pixel labeling or dense conditional random fields. When using pixelwise training criteria such as cross entropy loss, the resulting predictions lack high level structure - it often impossible to infer which pixels belong or not to an object instance without explicit instance number labels. A significant drawback in practice, besides being hard aligned, this representation limits its applicability to a narrow range of detection, tracking tasks and even regression problems where continuous values are expected on output. Here we propose instead conditional RNNs that factorize the model over time and are trained in order to generate sequences representing objects and instances. Specifically our method learns to predict spatio temporal features and how best to combine them at each step along the sequence for high quality and coherent segmentations across frames. This approach extends CRF-based models but now operating at 3 dimensions by modeling the hidden states and their dependencies explicitly. Experimentally, the proposed framework yields significantly higher accuracies compared to baselines, while at the same time, thanks to its efficient implementation can be optimized within seconds per frame making possible fast, real-time processing - thus outperforming all previous work.","label":"ai"}
{"id":290,"text":"Large-scale data is of crucial importance for learning semantic segmentation\nmodels, but annotating per-pixel masks is a tedious and inefficient procedure. We note that for the topic of interactive image segmentation, scribbles are\nvery widely used in academic research and commercial software, and are\nrecognized as one of the most user-friendly ways of interacting. In this paper,\nwe propose to use scribbles to annotate images, and develop an algorithm to\ntrain convolutional networks for semantic segmentation supervised by scribbles. Our algorithm is based on a graphical model that jointly propagates information\nfrom scribbles to unmarked pixels and learns network parameters. We present\ncompetitive object semantic segmentation results on the PASCAL VOC dataset by\nusing scribbles as annotations. Scribbles are also favored for annotating stuff\n(e.g., water, sky, grass) that has no well-defined shape, and our method shows\nexcellent results on the PASCAL-CONTEXT dataset thanks to extra inexpensive\nscribble annotations. Our scribble annotations on PASCAL VOC are available at\nhttp:\/\/research.microsoft.com\/en-us\/um\/people\/jifdai\/downloads\/scribble_sup","label":"human"}
{"id":291,"text":"> We study the problem of computing the relative entailment among probabilistic implications. Given two probabilistic implications, the relative entailment is the probability that the first implication is true given that the second implication is true. We show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a monotone function of the probabilities of the antecedents and consequents of the two implications. We also show that the relative entailment is a","label":"ai"}
{"id":292,"text":"This report presents the concept of Hyper Normalization-Conditioning, a technique that uses hyper-convex functions to create new conditional probability distributions which can be converted into generalized forms by the use of analytical conditioned integrals. Named because it expands the scope in normalization and conditioning, this idea was inspired by an article written and proposed by A.C.Dobson on how hyperbolic functions could represent exponential probability distribution functions. As such, there are different ways to transform each type of probability density function (PDF) and cumulative distribution function (CDF), but we will focus on only four types of PDFs--the uniform rectangularly shaped curve; the normally distributed bell curve; the triangular peak at 0 or -1 (which happens when two non-overlapping uniform peaks merge into one double bell shape curve); and Cauchy\/Lorentz curves. In order to formulate our approach, however, we need first understand what exactly these components entail before diving right in! For example: How do they derive their respective expressions through various means? We briefly reintroduce what they currently look like as well discuss any possible advantages over traditional approaches including time efficiencies due t...","label":"ai"}
{"id":293,"text":"> We discuss conditions that guarantee the union of any family containing an $ s_0$-nonmeasurable set to also be nonmeasurable and we examine how strong these conditions are by comparing them with other well-known measures such as Souslin's, Solovay's etc. In particular we prove that there exists no condition which implies $\\forall X\\in{\\cal N}(\\cup {\\cal F}\\in{\\cal N})$, where ${\\cal N}$ denotes the class of all countable $ s_{\\omega}$-sets and that in addition, given a certain type of forcing, one can show in ZFC+GCH that the statement is not provably equivalent to GCH (generalized continuum hypothesis). A related topic was studied very recently. Nevertheless since different techniques were used it seems better to present this note independently.","label":"ai"}
{"id":294,"text":"> Abstract: We present RLCorrector, an automated proofreader that corrects errors in segmentations produced by state-of-the-art connectome image analysis pipelines. Our approach uses reinforcement learning to learn how to fix common types of mistakes made during manual proofreading and then applies these corrections automatically. In experiments on 1000 neurons manually labeled as part of the Allen Mouse Common Coordinate Framework (CCF) project, we show that our method can improve upon human performance with respect to both accuracy and speed.","label":"ai"}
{"id":295,"text":"> We present an analysis of the dynamics of water molecules in hydrated proteins using quantitative continuous-wave (cw) overhauser dynamic nuclear polarization (DNP). This method allows us to measure the longitudinal relaxation time T1 and the transverse relaxation time T2 of protons on the microsecond timescale, which are important parameters that characterize the motion of water molecules. In this work we use two different approaches to analyze our data. Firstly, we fit the experimental signal decay curves with a model based on the Bloch equations. Secondly, we apply a recently developed approach [J. Chem. Phys., 146, 085103 (2017)] that uses the Fourier transform of the measured signal decay curve as input. Both methods yield similar results, but the second one has the advantage that it does not require any fitting parameter.","label":"ai"}
{"id":296,"text":"The paper presents a novel approach for unsupervised domain adaptation on hip joint bone segmentation using intra- and cross-modality semantic consistency. The proposed method leverages the inherent consistency between different modalities to improve the performance of the model on unseen data. The approach involves first learning a joint representation of the input modalities using a deep neural network, and then enforcing semantic consistency between the joint representation and the individual modalities. The method is evaluated on a large dataset of hip joint bone segmentation and shows significant improvements in performance compared to state-of-the-art methods. The results demonstrate the effectiveness of the proposed approach for unsupervised domain adaptation on hip joint bone segmentation.","label":"ai"}
{"id":297,"text":"This paper proposes a convolutional neural network that can fuse high-level\nprior for semantic image segmentation. Motivated by humans' vision recognition\nsystem, our key design is a three-layer generative structure consisting of\nhigh-level coding, middle-level segmentation and low-level image to introduce\nglobal prior for semantic segmentation. Based on this structure, we proposed a\ngenerative model called conditional variational auto-encoder (CVAE) that can\nbuild up the links behind these three layers. These important links include an\nimage encoder that extracts high level info from image, a segmentation encoder\nthat extracts high level info from segmentation, and a hybrid decoder that\noutputs semantic segmentation from the high level prior and input image. We\ntheoretically derive the semantic segmentation as an optimization problem\nparameterized by these links. Finally, the optimization problem enables us to\ntake advantage of state-of-the-art fully convolutional network structure for\nthe implementation of the above encoders and decoder. Experimental results on\nseveral representative datasets demonstrate our supreme performance for\nsemantic segmentation.","label":"human"}
{"id":298,"text":"I describe the history of the calculations of NLO and NNLO QCD corrections to\nweak decays of mesons and particle-antiparticle mixing in the period 1988-2023. Also existing calculations of electroweak and QED corrections to these\nprocesses are included in this presentation. These efforts bear some analogies\nto the climbing of Himalayas and various expeditions by several teams of\nstrongly motivated \"climbers\" allowed to move this field from the LO through\nthe NLO to the NNLO level. We also summarize the most recent calculations\nwithin the Standard Model Effective Field Theory. The material is meant to be\nan up to date review of this very advanced field in non-technical terms as much\nas possible and a guide to the rich literature on NLO and NNLO corrections in\nquestion. In particular we stress for which processes these calculations are\ncrucial for the tests of the Standard Model and to be able to differentiate\nbetween numerous New Physics models. It includes several anecdotes related to\nthe climbs that I was involved in. I hope that some of the comments made in the\ncourse of the presentation could turn out to be not only amusing but also\ninstructive.","label":"human"}
{"id":299,"text":"> Tool wear is a critical factor in the manufacturing process. It is important to monitor the tool wear in real-time to ensure the quality of the manufactured products. In this paper, we propose a human-in-the-loop system for tool wear analysis. The system consists of a deep learning-based tool wear detection model and a human-in-the-loop interface. The tool wear detection model is trained on a large dataset of tool wear images. The human-in-the-loop interface allows the user to interact with the system and provide feedback on the tool wear detection results. The system uses the feedback to improve the accuracy of the tool wear detection model. The proposed system is evaluated on a dataset of tool wear images. The results show that the system is able to detect tool wear with high accuracy. The system is also able to improve the accuracy of the tool wear detection model with the help of the human-in-the-loop interface. The paper is available here.","label":"ai"}
{"id":300,"text":"Registration is a fundamental task in medical image analysis which can be\napplied to several tasks including image segmentation, intra-operative\ntracking, multi-modal image alignment, and motion analysis. Popular\nregistration tools such as ANTs and NiftyReg optimize an objective function for\neach pair of images from scratch which is time-consuming for large images with\ncomplicated deformation. Facilitated by the rapid progress of deep learning,\nlearning-based approaches such as VoxelMorph have been emerging for image\nregistration. These approaches can achieve competitive performance in a\nfraction of a second on advanced GPUs. In this work, we construct a neural\nregistration framework, called NeurReg, with a hybrid loss of displacement\nfields and data similarity, which substantially improves the current\nstate-of-the-art of registrations. Within the framework, we simulate various\ntransformations by a registration simulator which generates fixed image and\ndisplacement field ground truth for training. Furthermore, we design three\nsegmentation frameworks based on the proposed registration framework: 1)\natlas-based segmentation, 2) joint learning of both segmentation and\nregistration tasks, and 3) multi-task learning with atlas-based segmentation as\nan intermediate feature. Extensive experimental results validate the\neffectiveness of the proposed NeurReg framework based on various metrics: the\nendpoint error (EPE) of the predicted displacement field, mean square error\n(MSE), normalized local cross-correlation (NLCC), mutual information (MI), Dice\ncoefficient, uncertainty estimation, and the interpretability of the\nsegmentation. The proposed NeurReg improves registration accuracy with fast\ninference speed, which can greatly accelerate related medical image analysis\ntasks.","label":"human"}
{"id":301,"text":"> We present a new approach to semantic segmentation that is based on a global deconvolutional network. The network is trained end-to-end in a fully convolutional manner, and it is able to produce high-resolution segmentation maps. The network is trained on a large dataset of 100,000 images, and it is able to achieve state-of-the-art results on the PASCAL VOC 2012 dataset. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper is available here. The paper","label":"ai"}
{"id":302,"text":"We construct a mesoscale model of colloidal suspensions that contain solutes\nreversibly adsorbing onto the colloidal particle surfaces. The present model\ndescribes the coupled dynamics of the colloidal particles, the host fluid, and\nthe solutes through the Newton-Euler equations of motion, the hydrodynamic\nequations, and the advection-diffusion equation, respectively. The solute\nadsorption is modeled through a square-well potential, which represents a\nshort-range attractive interaction between a particle and a solute molecule. The present model is formulated to be solved through direct numerical\nsimulations. Some numerical results are presented to validate the simulations. The present model enables investigations of solute adsorption effects in the\npresence of a fluid flow and an inhomogeneous solute concentration\ndistribution.","label":"human"}
{"id":303,"text":"This paper considers how to separate text and\/or graphics from smooth\nbackground in screen content and mixed document images and proposes two\napproaches to perform this segmentation task. The proposed methods make use of\nthe fact that the background in each block is usually smoothly varying and can\nbe modeled well by a linear combination of a few smoothly varying basis\nfunctions, while the foreground text and graphics create sharp discontinuity. The algorithms separate the background and foreground pixels by trying to fit\nbackground pixel values in the block into a smooth function using two different\nschemes. One is based on robust regression, where the inlier pixels will be\nconsidered as background, while remaining outlier pixels will be considered\nforeground. The second approach uses a sparse decomposition framework where the\nbackground and foreground layers are modeled with a smooth and sparse\ncomponents respectively. These algorithms have been tested on images extracted\nfrom HEVC standard test sequences for screen content coding, and are shown to\nhave superior performance over previous approaches. The proposed methods can be\nused in different applications such as text extraction, separate coding of\nbackground and foreground for compression of screen content, and medical image\nsegmentation.","label":"human"}
{"id":304,"text":"> We study the oracle complexity of nonsmooth convex optimization problems. > We show that the oracle complexity of a nonsmooth convex optimization\n> problem is at least as large as the oracle complexity of the corresponding\n> smooth convex optimization problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We then show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at least as large as the oracle complexity of the\n> corresponding nonsmooth convex feasibility problem. > We also show that the oracle complexity of a nonsmooth convex\n> optimization problem is at","label":"ai"}
{"id":305,"text":"> We study the fractal dimension of random 3-SAT formulas, and show that it grows linearly with the number n of variables in the formula. This result holds both for uniformly chosen clauses (with probability p) as well as for biased distributions where each clause has exactly three literals. Our proofs are based on an analysis of the structure of the satisfiable subgraph of the graph G(F), which we call the satisfiability graph of F. In particular, we prove that this graph contains a spanning tree whose degree distribution follows a power law.","label":"ai"}
{"id":306,"text":"In this work we study the removal of thin layers of adhesive films of polymine, a generic ammonium-terminated polyamidoamine dendrimer, using two different dual ion beam configurations: single, rotated ion beams (with azimuthal angle I>> = 20Adeg) and tandem configurations. In all cases beams of Ar+ ions of 500 eV energy with fixed currents (2 I,A) at normal incidence are considered. The ion fluence is measured in terms of a sputtered thickness, which is defined, in atomic units, as the minimum number of sputtered ion layers which, when coating a 0.5 I+-m bare substrate, is able to produce a surface resistivity of 10A+-25 % of its nominal value. We analyze the impact of a series of variables (ion beam parameters, size of the dendrimer and rotation angle I>>), and we found a critical role played by the lateral movement of the ion beam for the sputtering process when the polymine film is removed by rotated beam configurations. We show that dual ion-beam configurations are more appropriate to remove thin polymeric layers than single, rotated beams. Using both the tandem configuration and rotated beams, we achieve the same surface resistivity by sputtering around 2.5 a 3 times more ion fluence than that required with single beam configuration. This research paper from University of CAVdiz, Spain, was written by VActor MartAn-Sanchez and Emilio HernAVndez-GonzAAlez.","label":"ai"}
{"id":307,"text":"Multi-modal medical image segmentation plays an essential role in clinical\ndiagnosis. It remains challenging as the input modalities are often not\nwell-aligned spatially. Existing learning-based methods mainly consider sharing\ntrainable layers across modalities and minimizing visual feature discrepancies. While the problem is often formulated as joint supervised feature learning,\nmultiple-scale features and class-specific representation have not yet been\nexplored. In this paper, we propose an affinity-guided fully convolutional\nnetwork for multimodal image segmentation. To learn effective representations,\nwe design class-specific affinity matrices to encode the knowledge of\nhierarchical feature reasoning, together with the shared convolutional layers\nto ensure the cross-modality generalization. Our affinity matrix does not\ndepend on spatial alignments of the visual features and thus allows us to train\nwith unpaired, multimodal inputs. We extensively evaluated our method on two\npublic multimodal benchmark datasets and outperform state-of-the-art methods.","label":"human"}
{"id":308,"text":"The increasing trend of urbanization is leading to a growing number of fisheye cameras being installed in public spaces, such as intersections and parking lots. This has resulted in an abundance of data from fisheye images that need to be processed efficiently to gain insights into traffic conditions and improve safety measures. In this study, we explore universal semantic segmentation techniques to extract meaningful information from fisheye driving images. Our approach utilizes pre-trained models on large datasets and fine-tunes them specifically for the task, achieving superior performance over state-of-the-art methods. We also propose novel strategies for improving the robustness of our algorithms under varying weather and lighting conditions, which are common challenges in real-world scenarios. Our findings contribute significantly to the development of intelligent transportation systems and can have widespread applicability beyond the realm of urban driving imagery.","label":"ai"}
{"id":309,"text":"Abstract-- This work concerns object segmentation in highly dynamic videos, which can be described as visual streams containing spatio-temporal information about fast moving objects in scenes like road intersections or sport events. We propose to leverage this spatial and temporal structure by leveraging on spatio-temporally consistent appearance models that exploit motion over time. Our semantic image segmentation approach jointly integrates spatio-temporal and semantics models via convolutional neural networks (CNNs) with fully differentiable end-to-end optimization. Building on previous works, we further augment this unsupervised model to operate within limited supervision, yielding similar results when compared against state-of-the-art semi-supervised video segmentation methods using only 17 labeled frames per class as opposed to up to 465 manually annotated frames used by competitors. Our method also produces competitive results even with single annotation frame and does not require any handmade modifications other than a standard class level loss function and a classification layer appended to a CNN that produces segmentation maps. In order to showcase the benefit our proposed learning based algorithm provides in both large-scale settings where fully supervisd training data are hard to come by without prior labels at low cost, while maintaining accuracy comparable to state-of-the-art systems. An evaluation on three publicly available datasets underlines the usefulness of taking advantage of short term dynamics for extracting relevant scene structures such as static background and foreground objects.\"","label":"ai"}
{"id":310,"text":"Over the past few years it has been demonstrated that \"coarse timesteppers\"\nestablish a link between traditional numerical analysis and microscopic\/\nstochastic simulation. The underlying assumption of the associated\nlift-run-restrict-estimate procedure is that macroscopic models exist and close\nin terms of a few governing moments of microscopically evolving distributions,\nbut they are unavailable in closed form. This leads to a system identification\nbased computational approach that sidesteps the necessity of deriving explicit\nclosures. Two-level codes are constructed; the outer code performs macroscopic,\ncontinuum level numerical tasks, while the inner code estimates -through\nappropriately initialized bursts of microscopic simulation- the quantities\nrequired for continuum numerics. Such quantities include residuals, time\nderivatives, and the action of coarse slow Jacobians. We demonstrate how these\ncoarse timesteppers can be applied to perform equation-free computations of a\nkinetic Monte Carlo simulation of E. coli chemotaxis. Coarse-grained\ncontraction mappings, system level stability analysis as well as acceleration\nof the direct simulation, are enabled through this computational multiscale\nenabling technology.","label":"human"}
{"id":311,"text":"In recent years there has been a growing interest in image generation through\ndeep learning. While an important part of the evaluation of the generated\nimages usually involves visual inspection, the inclusion of human perception as\na factor in the training process is often overlooked. In this paper we propose\nan alternative perceptual regulariser for image-to-image translation using\nconditional generative adversarial networks (cGANs). To do so automatically\n(avoiding visual inspection), we use the Normalised Laplacian Pyramid Distance\n(NLPD) to measure the perceptual similarity between the generated image and the\noriginal image. The NLPD is based on the principle of normalising the value of\ncoefficients with respect to a local estimate of mean energy at different\nscales and has already been successfully tested in different experiments\ninvolving human perception. We compare this regulariser with the originally\nproposed L1 distance and note that when using NLPD the generated images contain\nmore realistic values for both local and global contrast. We found that using\nNLPD as a regulariser improves image segmentation accuracy on generated images\nas well as improving two no-reference image quality metrics.","label":"human"}
{"id":312,"text":"> We study theta functions on the moduli space of stable bundles on a curve. We show that the theta functions of a stable bundle are related to the theta functions of its dual bundle by a strange duality. We also show that the theta functions of a stable bundle are related to the theta functions of its odd orthogonal bundle by a strange duality. The paper is by J. Hurtubise, J. Kool, and J. Landsberg. The paper is available at arxiv.org.","label":"ai"}
{"id":313,"text":"Information-communication technology promotes collaborative environments like\nWikipedia where, however, controversiality and conflicts can appear. To\ndescribe the rise, persistence, and resolution of such conflicts we devise an\nextended opinion dynamics model where agents with different opinions perform a\nsingle task to make a consensual product. As a function of the convergence\nparameter describing the influence of the product on the agents, the model\nshows spontaneous symmetry breaking of the final consensus opinion represented\nby the medium. In the case when agents are replaced with new ones at a certain\nrate, a transition from mainly consensus to a perpetual conflict occurs, which\nis in qualitative agreement with the scenarios observed in Wikipedia.","label":"human"}
{"id":314,"text":"Non-invasive detection of cardiovascular disorders from radiology scans\nrequires quantitative image analysis of the heart and its substructures. There\nare well-established measurements that radiologists use for diseases assessment\nsuch as ejection fraction, volume of four chambers, and myocardium mass. These\nmeasurements are derived as outcomes of precise segmentation of the heart and\nits substructures. The aim of this paper is to provide such measurements\nthrough an accurate image segmentation algorithm that automatically delineates\nseven substructures of the heart from MRI and\/or CT scans. Our proposed method\nis based on multi-planar deep convolutional neural networks (CNN) with an\nadaptive fusion strategy where we automatically utilize complementary\ninformation from different planes of the 3D scans for improved delineations. For CT and MRI, we have separately designed three CNNs (the same architectural\nconfiguration) for three planes, and have trained the networks from scratch for\nvoxel-wise labeling for the following cardiac structures: myocardium of left\nventricle (Myo), left atrium (LA), left ventricle (LV), right atrium (RA),\nright ventricle (RV), ascending aorta (Ao), and main pulmonary artery (PA). We\nhave evaluated the proposed method with 4-fold-cross validation on the\nmulti-modality whole heart segmentation challenge (MM-WHS 2017) dataset. The\nCT and MR images, respectively. While a CT volume was segmented about 50\nseconds, an MRI scan was segmented around 17 seconds with the GPUs\/CUDA\nimplementation.","label":"human"}
{"id":315,"text":"Abstract:\nThis paper concerns stochastic numerical methods for simulating fluid-structure interactions with thermal fluctuations. The fluid-structure interaction problem can be formulated as two coupled partial differential equations (PDEs). Specifically, one PDE describes the motion of a rigid body in a fluid, and the other describes the flow of a viscous, thermodynamical compressible fluid past that body. The two equations are coupled by a pointwise kinematic condition. A method of characteristics solution of the rigid body equation requires inversion of the pointwise Jacobian matrix, the inverse of which is assumed unavailable. One would like to include thermal fluctuations as a stochastic forcing term in the rigid body equation. We propose a novel stochastic solution to overcome the difficulty of inverting the Jacobian matrix. In particular, the stochastic differential equation (SDE) obtained by Ito calculus from the pointwise coupling condition is first transformed to a finite-dimensional equivalent system, the nonlinear system of which is solved explicitly without the inversion of the Jacobian matrix. The numerical results produced with the proposed methods suggest accuracy levels that compare well to those obtained with the existing methods as well as improved convergence rates, for cases where the Jacobian is invertible. The authors were from National Tsing Hua University and Texas A&M University.","label":"ai"}
{"id":316,"text":"Nowadays U-net-like FCNs predominate various biomedical image segmentation\napplications and attain promising performance, largely due to their elegant\narchitectures, e.g., symmetric contracting and expansive paths as well as\nlateral skip-connections. It remains a research direction to devise novel\narchitectures to further benefit the segmentation. In this paper, we develop an\nACE-net that aims to enhance the feature representation and utilization by\naugmenting the contracting and expansive paths. In particular, we augment the\npaths by the recently proposed advanced techniques including ASPP, dense\nconnection and deep supervision mechanisms, and novel connections such as\ndirectly connecting the raw image to the expansive side. With these\naugmentations, ACE-net can utilize features from multiple sources, scales and\nreception fields to segment while still maintains a relative simple\narchitecture. Experiments on two typical biomedical segmentation tasks validate\nits effectiveness, where highly competitive results are obtained in both tasks\nwhile ACE-net still runs fast at inference.","label":"human"}
{"id":317,"text":"Thesedays, Convolutional Neural Networks are widely used in semantic\nsegmentation. However, since CNN-based segmentation networks produce\nlow-resolution outputs with rich semantic information, it is inevitable that\nspatial details (e.g., small bjects and fine boundary information) of\nsegmentation results will be lost. To address this problem, motivated by a\nvariational approach to image segmentation (i.e., level set theory), we propose\na novel loss function called the level set loss which is designed to refine\nspatial details of segmentation results. To deal with multiple classes in an\nimage, we first decompose the ground truth into binary images. Note that each\nbinary image consists of background and regions belonging to a class. Then we\nconvert level set functions into class probability maps and calculate the\nenergy for each class. The network is trained to minimize the weighted sum of\nthe level set loss and the cross-entropy loss. The proposed level set loss\nimproves the spatial details of segmentation results in a time and memory\nefficient way. Furthermore, our experimental results show that the proposed\nloss function achieves better performance than previous approaches.","label":"human"}
{"id":318,"text":"Medicial image segmentation is one of the most important tasks in medical imaging, which aims to identify and isolate specific region(s) in images. However, noisy label scenarios often occur due to human errors or variability among annotators. In this paper, we propose a novel cross-denoising network based on generative adversarial networks (GANs) specifically designed to learn from corrupted labels, allowing precise object boundaries extraction even when some segments are incorrectly labeled as background. This approach leverages domain shift to generate extra supervision from similar yet dissimilar regions between the noisy and clean data distributions, significantly improving performance on various popular benchmarks. Furthermore, our model does not require extensive retraining of GANs in each task instance, instead maintaining generalizability across multiple tasks.","label":"ai"}
{"id":319,"text":"In segmentation methods, it is important to accurately predict the quality of segmentation results. Especially, in real-time inference on a smartphone, users might want to know whether results are good and how much time is remaining for further improving the results. For this, users have to use subjective\/objective measures and wait for the end of the algorithm execution. Here, in this paper, we propose a novel method of rapidly estimating the quality of a segmentation result by the use of a deep network in a streaming manner. In this paper, a prediction network with a ResNet architecture is used to generate real-time prediction for a given image. A segmentation network is also used to generate ground-truth masks and a loss function that works as a quality measure for the predictions. We applied segmentation tasks on five different benchmark datasets, and a dataset specifically generated for segmentation tasks. Furthermore, we tested segmentation on real-world images, and showed that our method is reliable in comparison to the baseline network and standard quality-assessment methods.","label":"ai"}
{"id":320,"text":"This paper studies the coordinated beamforming (CoBF) design for the\nmultiple-input single-output interference channel, provided that only channel\ndistribution information is known to the transmitters. The problem under\nconsideration is a probabilistically constrained optimization problem which\nmaximizes a predefined system utility subject to constraints on rate outage\nprobability and power budget of each transmitter. Our recent analysis has shown\nthat the outage-constrained CoBF problem is intricately difficult, e.g.,\nNP-hard. Therefore, the focus of this paper is on suboptimal but\ncomputationally efficient algorithms. Specifically, by leveraging on the block\nsuccessive upper bound minimization (BSUM) method in optimization, we propose a\nGauss-Seidel type algorithm, called distributed BSUM algorithm, which can\nhandle differentiable, monotone and concave system utilities. By exploiting a\nweighted minimum mean-square error (WMMSE) reformulation, we further propose a\nJocobi-type algorithm, called distributed WMMSE algorithm, which can optimize\nthe weighted sum rate utility in a fully parallel manner. To provide a\nperformance benchmark, a relaxed approximation method based on polyblock outer\napproximation is also proposed. Simulation results show that the proposed\nalgorithms are significantly superior to the existing successive convex\napproximation method in both performance and computational efficiency, and can\nyield promising approximation performance.","label":"human"}
{"id":321,"text":"We introduce a new algorithm for creating triangulated meshes, from multiple Boolean operations on surfaces. Using only simple and cheap triangle operations, our algorithm is extremely robust and handles different types of meshes, including self intersecting surfaces of arbitrary topology and connectivity, and surfaces with irregular structures. Our algorithm can generate meshes over a large range of qualities, from coarse meshes with a small number of triangles, to isotropic meshes with the minimal number of triangles to retain the topology and geometry of the surface. We achieve this by analyzing how the different types of triangles of the model change during the process, to adjust the triangulation parameters according to our user-specified goal (isotropic or faithful). Our algorithm is applicable to a wide variety of CAD, engineering and medical applications, where a robust mesh processing algorithm is required, for example creating a tessellated model from a surface obtained by any 3D scanning device. ## Some Applications\nWe believe that this new algorithm can be useful in many areas of research, and can replace various mesh generation algorithms, where robustness and simplicity are needed during the calculation process. Among the many possible applications, include:\n1. Bone and heart modelling (Fig. 8)\n2. Mesh deformation techniques (for cloth simulation and video game animation)\n3. Sculpting of solid models (Fig. 8)\n4. Surface intersections (such as in medical imaging)\n5. Mesh simplification and visualization (Fig. 10)\n## Publication\nSimple and Robust Boolean Operations for Triangulated Surfaces\nDror Avisar, Boaz Arviv\nTo be published in the Journal of Graphics Tools (JGTA 18 (4), July 2013)","label":"ai"}
{"id":322,"text":"This study proposes a reliable and versatile computer aided diagnosis (CAD) framework that can be applied to any dataset and medical data without requiring retraining. The developed deep-learning image segmentation system is first trained on a large public dataset, namely the CLEF2017 dataset. To achieve the generalization of the proposed system across other datasets, several pre-processing techniques such as the Normalization method and data augmentation using the Random data augmentation method are introduced into the deep learning segmentation system. The framework achieves the precision and recall of 91.14% and 89.69%, respectively, on the aforementioned public dataset. Next, the generalized framework is applied to two different datasets namely TK and VH for the evaluation purpose. To achieve the evaluation purpose, only fine-tuning on the above mentioned datasets is performed. Our experimental results show that the proposed deep-learning framework outperforms other approaches in terms of the dice similarity coefficient. The full paper is available in arxiv.org\/abs\/2004.12845v4 as well as in a research gate portal.","label":"ai"}
{"id":323,"text":"> We present an approach to constructing representations of the Clifford group in terms of coherent states, which are eigenstates of the parity operator and have definite values of the number of excitations. This allows us to obtain explicit expressions for the action of the generators on these states. In particular, we show that the Majorana representation can be obtained by applying the Fourier transform to the coherent state basis. Our method also provides a simple way to compute the overlap between two different representations. As an application, we use this technique to calculate the overlap between the Majorana and Pauli representations.","label":"ai"}
{"id":324,"text":"We introduce a new Gentzen-style framework of grafted hypersequents that\ncombines the formalism of nested sequents with that of hypersequents. To\nillustrate the potential of the framework, we present novel calculi for the\nmodal logics $\\mathsf{K5}$ and $\\mathsf{KD5}$, as well as for extensions of the\nmodal logics $\\mathsf{K}$ and $\\mathsf{KD}$ with the axiom for shift\nreflexivity. The latter of these extensions is also known as $\\mathsf{SDL}^+$\nin the context of deontic logic. All our calculi enjoy syntactic cut\nelimination and can be used in backwards proof search procedures of optimal\ncomplexity. The tableaufication of the calculi for $\\mathsf{K5}$ and\n$\\mathsf{KD5}$ yields simplified prefixed tableau calculi for these logic\nreminiscent of the simplified tableau system for $\\mathsf{S5}$, which might be\nof independent interest.","label":"human"}
{"id":325,"text":"Graph cut segmentation methods are widely used in various applications such as image processing, computer vision and machine learning. These techniques involve dividing graphs into two or more subgraphs to achieve desired results. However, traditional graph cut algorithms have limitations in terms of their accuracy and efficiency. In this study, we present a novel approach towards solving graph cut problems using quantum mechanics principles. Our algorithm is based on the concept of Schrodinger's wave equation which allows us to calculate the probability distribution of particles in a graph. We use this probability for selecting cuts that result in optimal segmentations. The proposed method shows improved performance over classical approaches in terms of accuracy and speed. Furthermore, our approach can efficiently handle large-scale graphs that cannot be processed by conventional graph cut algorithms. Overall, our work provides a new paradigm for addressing complex graph segmentation problems through the application of quantum mechanics principles.","label":"ai"}
{"id":326,"text":"We introduce the notions of a differentiable groupoid and a differentiable\nstratified groupoid, generalizations of Lie groupoids in which the spaces of\nobjects and arrows have the structures of differentiable spaces, respectively\ndifferentiable stratified spaces, compatible with the groupoid structure. After\nstudying basic properties of these groupoids including Morita equivalence, we\nprove a de Rham theorem for locally contractible differentiable stratified\ngroupoids. We then focus on the study of the inertia groupoid associated to a\nproper Lie groupoid. We show that the loop and the inertia space of a proper\nLie groupoid can be endowed with a natural Whitney B stratification, which we\ncall the orbit Cartan type stratification. Endowed with this stratification,\nthe inertia groupoid of a proper Lie groupoid becomes a locally contractible\ndifferentiable stratified groupoid.","label":"human"}
{"id":327,"text":"> Structured output prediction is a general framework for predicting structured variables such as sequences, trees, and graphs. In this paper, we propose a new boosting method for structured output prediction. Our method is based on the idea of boosting the prediction of the structured output variable by boosting the prediction of the conditional probability of each output variable given the input variable. We show that our method can be applied to any structured output prediction method that can be formulated as a conditional probability model. We also show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be formulated as a conditional probability model. We show that our method can be applied to any boosting method that can be","label":"ai"}
{"id":328,"text":"If $\\Sigma=(X,\\sigma)$ is a topological dynamical system, where $X$ is a\ncompact Hausdorff space and $\\sigma$ is a homeomorphism of $X$, then a crossed\nproduct Banach $\\sp{*}$-algebra $\\ell^1(\\Sigma)$ is naturally associated with\nthese data. If $X$ consists of one point, then $\\ell^1(\\Sigma)$ is the group\nis known to be a maximal abelian subalgebra which has non-zero intersection\nwith each non-zero closed ideal, and the same holds for the commutant $C(X)'_*$\nThis intersection property has proven to be a valuable tool in investigating\nthese algebras. Motivated by this pivotal role, we study $C(X)'_1$ and\n$C(X)'_*$ in detail in the present paper. The maximal ideal space of $C(X)'_1$\nis described explicitly, and is seen to coincide with its pure state space and\nto be a topological quotient of $X\\times\\mathbb{T}$. We show that $C(X)'_1$ is\nhermitian and semisimple, and that its enveloping $C^*$-algebra is $C(X)'_*$. Furthermore, we establish necessary and sufficient conditions for projections\nonto $C(X)'_1$ and $C(X)'_*$ to exist, and give explicit formulas for such\nprojections, which we show to be unique. In the appendix, topological results\nfor the periodic points of a homeomorphism of a locally compact Hausdorff space\nare given.","label":"human"}
{"id":329,"text":"In this work, we introduce and study a family of random noble means substitutions. We derive results on their probability distributions and random structures. Specifically, we find sharp bounds on their expected values, concentration inequalities, and asymptotic behavior as the rank increases, which provide insights into the nature of these objects and their relationships with other distribution families. Our approach involves a combination of harmonic analysis, combinatorial techniques, and probabilistic arguments. Our findings have implications for statistical physics, random graphs, and complexity theory.","label":"ai"}
{"id":330,"text":"In recent years, computer-aided diagnosis has become an increasingly popular\ntopic. Methods based on convolutional neural networks have achieved good\nperformance in medical image segmentation and classification. Due to the\nlimitations of the convolution operation, the long-term spatial features are\noften not accurately obtained. Hence, we propose a TransClaw U-Net network\nstructure, which combines the convolution operation with the transformer\noperation in the encoding part. The convolution part is applied for extracting\nthe shallow spatial features to facilitate the recovery of the image resolution\nafter upsampling. The transformer part is used to encode the patches, and the\nself-attention mechanism is used to obtain global information between\nsequences. The decoding part retains the bottom upsampling structure for better\ndetail segmentation performance. The experimental results on Synapse\nMulti-organ Segmentation Datasets show that the performance of TransClaw U-Net\nis better than other network structures. The ablation experiments also prove\nthe generalization performance of TransClaw U-Net.","label":"human"}
{"id":331,"text":"In an analogy with the Galois homothety property for torsion points of\nabelian varieties that was used in the proof of the Mordell-Lang conjecture, we\ndescribe a correspondence between the action of a Galois group and the\ndynamical action of a rational map. For nonlinear polynomials with rational\ncoefficients, the irreducibility of the associated dynatomic polynomial serves\nas a convenient criterion, although we also verify that the correspondence\noccurs in several cases when the dynatomic polynomial is reducible. The work of\nMorton, Morton-Patel, and Vivaldi-Hatjispyros in the early 1990s connected the\nirreducibility and Galois-theoretic properties of dynatomic polynomials to\nrational periodic points; from the Galois-dynamics correspondence, we derive\nsimilar consequences for quadratic periodic points of unicritical polynomials. This is sufficient to deduce the non-existence of quadratic periodic points of\nquadratic polynomials with exact period 5 and 6, outside of a specified finite\nset from Morton and Krumm's work in explicit Hilbert irreducibility.","label":"human"}
{"id":332,"text":"This paper introduces an extended version of the Linear Temporal Logic (LTL)\ngraphical interface. It is a sketch based interface built on the Android\nplatform which makes the LTL control interface more straightforward and\nfriendly to nonexpert users. By predefining a set of areas of interest, this\ninterface can quickly and efficiently create plans that satisfy extended plan\ngoals in LTL. The interface can also allow users to customize the paths for\nthis plan by sketching a set of reference trajectories. Given the custom paths\nby the user, the LTL specification and the environment, the interface generates\na plan balancing the customized paths and the LTL specifications. We also show\nexperimental results with the implemented interface.","label":"human"}
{"id":333,"text":"Uncertainty estimation is important for interpreting the trustworthiness of\nmachine learning models in many applications. This is especially critical in\nthe data-driven active learning setting where the goal is to achieve a certain\naccuracy with minimum labeling effort. In such settings, the model learns to\nselect the most informative unlabeled samples for annotation based on its\nestimated uncertainty. The highly uncertain predictions are assumed to be more\ninformative for improving model performance. In this paper, we explore\nuncertainty calibration within an active learning framework for medical image\nsegmentation, an area where labels often are scarce. Various uncertainty\nestimation methods and acquisition strategies (regions and full images) are\ninvestigated. We observe that selecting regions to annotate instead of full\nimages leads to more well-calibrated models. Additionally, we experimentally\nshow that annotating regions can cut 50% of pixels that need to be labeled by\nhumans compared to annotating full images.","label":"human"}
{"id":334,"text":"We propose an end-to-end learning framework for segmenting generic objects in\nboth images and videos. Given a novel image or video, our approach produces a\npixel-level mask for all \"object-like\" regions---even for object categories\nnever seen during training. We formulate the task as a structured prediction\nproblem of assigning an object\/background label to each pixel, implemented\nusing a deep fully convolutional network. When applied to a video, our model\nfurther incorporates a motion stream, and the network learns to combine both\nappearance and motion and attempts to extract all prominent objects whether\nthey are moving or not. Beyond the core model, a second contribution of our\napproach is how it leverages varying strengths of training annotations. Pixel-level annotations are quite difficult to obtain, yet crucial for training\na deep network approach for segmentation. Thus we propose ways to exploit\nweakly labeled data for learning dense foreground segmentation. For images, we\nshow the value in mixing object category examples with image-level labels\ntogether with relatively few images with boundary-level annotations. For video,\nwe show how to bootstrap weakly annotated videos together with the network\ntrained for image segmentation. Through experiments on multiple challenging\nimage and video segmentation benchmarks, our method offers consistently strong\nresults and improves the state-of-the-art for fully automatic segmentation of\ngeneric (unseen) objects. In addition, we demonstrate how our approach benefits\nimage retrieval and image retargeting, both of which flourish when given our\nhigh-quality foreground maps. Code, models, and videos are\nat:http:\/\/vision.cs.utexas.edu\/projects\/pixelobjectness\/","label":"human"}
{"id":335,"text":"Abstract\nMissing methods in Java programs that are part of codebases with strict coupling can result in difficult-to-find bugs and violate the programming language's single inheritance principle. Detecting missing method calls, however, is challenging because many call sites to those methods could be legitimate null cases in a program design sense even though an empty method implementation remains there to serve no real purpose other than being syntactically correct at compile time. In this work we study whether it is possible to automatically identify such miscellaneous methods through static analysis along with appropriate training data. We consider call site\/implied receiver class pairs (CSRs) which are potential candidates of violation. Our classification model uses a modified weighted majority voting approach trained on CSR groups where the size distributions come from both manually created labels (ground truth) and learned patterns from the same data set. A large training set of manually labeled CSRs is used along with statistical feature selection techniques. The learning process combines support vector machine ranking with one dimensional random projection techniques to extract features important to our task. Aside for having a much more general framework for analyzing Java bytecode (with special focus on handling complex object creation), using SVM ranking instead of a regular learning model allows us greater precision while detecting most violations. Experimental results show reasonable accuracy (90%--86%) for small testing sets compared to prior efforts. These preliminary results should provide good insight into how to best learn such pattern specific information to further improve performance.","label":"ai"}
{"id":336,"text":"Medical image segmentation is a common task in computer vision and deep learning, requiring the identification of specific regions within images. This research aims to improve upon existing methods by proposing a new type of convolutional neural network called R2U-Net. The architecture of the proposed network utilizes both residual and recurrent components that enable greater efficiency and accuracy during training. In this study, we tested R2U-Net's performance using the popular U-Net dataset and achieved better results than other state-of-the-art methods. Our findings suggest that incorporating both residual and recurrent residuals into a single network can provide significant improvements for medical image segmentation tasks. Overall, our work contributes valuable insights towards improving the quality and speed of diagnoses within radiology fields.","label":"ai"}
{"id":337,"text":"This paper presents a deep convolutional neural network (D-CNN) model using domain adaptation for prostate segmentation of multiple-echo proton density-weighted (mpD-w) images from multi-contrast magnetic resonance (MR) images including DCE and DW imaging sequences on the Multi-Modal Imaging of Prostate Cancer (MmP) Dataset, which contains 90 mpD-w scans from 90 patients. To segment multiple pathological regions including the normal and cancerous tissues, we proposed a boundary-weighted domain adaptation network (BW-DAdNet) that takes advantage of weak supervision provided by mpD-w scan boundary region annotations. BW-DAdNet first estimates the mpD-w scan boundary and generates the boundary mask, followed by the proposed domain adaptation module (DA Module) that trains a new shared neural module. Then, the output of the shared module is incorporated into a boundary-weighted fully-convolutional network (FW-FCN) to segment the three classes, e.g., normal, cancer, and border tissue, and then the boundary mask is overlayed to improve performance in the border region through a multi-task loss function. Boundary mask was estimated and the segmentation and training framework consisted of three loss functions: Cross Entropy, Dice Loss, and Segmentation Boundary Loss(SBLoss). To minimize the influence of domain shift, our BW-DAdNet was trained and tested with an online hard-mining sampling strategy using weighted cross-entropy and Dice loss with DAd-FW-FCN, named BW-DAd-FW-FCN, that was evaluated using the MmP Dataset for prostate segmentation, with high Dice scores (0.91, 0.86, and 0.68) and Kappa scores (0.88, 0.82, and 0.51) for normal, cancer, and border tissue, respectively. ### Results for our method on Multi-Modal Imaging of Prostate Cancer (MmP) Dataset","label":"ai"}
{"id":338,"text":"The jeu de taquin process produced a standard Young tableau from a skew\nstandard Young tableau by shifting its entries to the northwest. We generalize\nthis process to posets: certain partial numberings of any poset are shifted\nupward. A poset is said to have the jeu de taquin property if the numberings\nresulting from this process do not depend upon certain choices made during the\nprocess. Young diagrams are the posets which underlie standard Young tableaux. These posets have the jeu de taquin property. d-Complete posets are posets\nwhich satisfy certain local structual conditions. They are mutual\ngeneralizations of Young diagrams, shifted Young diagrams, and rooted trees. We\nprove that all d-complete posets have the jeu de taquin property. The proof\nshows that each d-complete poset actually has the stronger \"simultaneous\"\nproperty; this may lead to an algebraic understanding of the main result. A\npartial converse is stated: \"Non-overlapping\" simultaneous posets are\nd-complete.","label":"human"}
{"id":339,"text":"To ensure safety in automated driving, the correct perception of the\nsituation inside the car is as important as its environment. Thus, seat\noccupancy detection and classification of detected instances play an important\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\npossible to, e.g., automate the airbag deployment control. Furthermore, the\npresence of a driver, which is necessary for partially automated driving cars\nat the automation levels two to four can be verified. In this work, we compare\ndifferent statistical methods from the field of image segmentation to approach\nthe problem of background-foreground segmentation in camera based interior\nsensing. In the recent years, several methods based on different techniques\nhave been developed and applied to images or videos from different\napplications. The peculiarity of the given scenarios of interior sensing is,\nthat the foreground instances and the background both contain static as well as\ndynamic elements. In data considered in this work, even the camera position is\nnot completely fixed. We review and benchmark three different methods ranging,\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\nmethods, GMM and Morphological Snakes, for interior sensing are shown. Furthermore, it turns, that it is possible to overcome these limitations by\ndeep learning, e.g.\\ using a Mask R-CNN. Although only a small amount of ground\ntruth data was available for training, we enabled the Mask R-CNN to produce\nhigh quality background-foreground masks via transfer learning. Moreover, we\ndemonstrate that certain augmentation as well as pre- and post-processing\nmethods further enhance the performance of the investigated methods.","label":"human"}
{"id":340,"text":"Neuron boundary segmentation is a crucial step in the analysis of neural circuits, as it enables the identification of individual neurons and their connections. However, accurately segmenting neuron boundaries in 2D images can be challenging due to the complex and variable shapes of neurons. In this paper, we propose an efficient method for 2D neuron boundary segmentation that incorporates local topological constraints. Our approach uses a graph-based representation of the neuron, where each neuron is represented as a graph and the connections between neurons are represented as edges. We then use a local topological constraint to enforce the connectivity of the graph, which helps to improve the accuracy of the segmentation. Our method is tested on a dataset of 2D images of neurons, and we demonstrate that it outperforms other state-of-the-art methods in terms of accuracy and efficiency. Overall, our approach provides a powerful tool for the analysis of neural circuits, enabling researchers to more accurately identify and study individual neurons and their connections.","label":"ai"}
{"id":341,"text":"> An adaptive, unsupervised clustering model is proposed for image segmentation based on color appearance perceptual similarities. The model is based on the concept of the Voronoi diagram and the Voronoi cell. A multiplication mask is applied to compute appearance similarities. It does not require a training set as it is parameter free. It has been shown to provide consistent segmentation results on several datasets. To the best of our knowledge, this is the first time that such a method has been shown to be effective, without tuning of the parameters via training set.","label":"ai"}
{"id":342,"text":"The UK Biobank Cardiac MR Imaging Study is a large-scale study aimed at identifying individuals at risk of developing cardiovascular disease. Image segmentation is a crucial step in this study, as it allows for the identification of specific anatomical features of the heart. However, manual image segmentation is time-consuming and prone to errors. In this paper, we propose an automated quality control system for image segmentation in the UK Biobank Cardiac MR Imaging Study. Our system uses a combination of machine learning and computer vision techniques to automatically detect and correct errors in the segmentation results. We evaluate the performance of our system on a subset of the UK Biobank Cardiac MR Imaging Study dataset and demonstrate that it can significantly improve the accuracy and consistency of the segmentation results. Our system has the potential to greatly improve the efficiency and accuracy of image segmentation in large-scale medical imaging studies.","label":"ai"}
{"id":343,"text":"Multi-User MIMO System with Interference Channel Model, in which, I've found a very useful idea -- using a jammer to secure communication on an individual basis (jamming only those eavesdroppers not intended for any specific user so that a jammng signal does not interfere legitimate receivers either). Below you could find some related figures as well. Also you can check the original site [here](http:\/\/arxiv.org\/pdf\/1208.6574) or download [the PDF file here](https:\/\/courseswiki.netlify.com\/_static\/files\/a_r_xiv_o_r_g_.pdfr). Happy reading!! :blush::+1:\n# Paper Abstract\n>This work studies multiuser diversity for secrecy communications when an access point wishes to transmit information over a nondegraded multiple antenna link while protecting that information against\neavesdropping by unintended users who might have access to channel state information but possess no coordination among themselves whatsoever - i.e., they behave according to interference channels model. Specifically, we study this problem within the context of Opportunistic Jammer selection as introduced in Liu et al., [22]. In particular, for an arbitrary number K > 3, N t x n<sub>K<\/sub>, we consider both single user and multiuser systems. We also consider two different scenarios of opportunistically selected jammers: *Jamming all eavesdroppers* and *Jamming few eavesdroppers*. Under the assumption of asymptotic perfect channel estimation at the receiver, and in spite of the presence of interference channels, we establish that an achievability is given by the summation rate R = P&Sigma;kR <i>subscript k<\/i>, where each term for Rate R <i>subscript k<\/i> represents a certain fraction of the total power budget P if this kth user has the maximum rate R <sub>maximum(k)<\/sub>. This yields the scaling law N<sup>2<\/sup>:P -,","label":"ai"}
{"id":344,"text":"In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system.","label":"human"}
{"id":345,"text":"A gapped repeat (respectively, palindrome) occurring in a word $w$ is a\nfactor $uvu$ (respectively, $u^Rvu$) of $w$. In such a repeat (palindrome) $u$\nis called the arm of the repeat (respectively, palindrome), while $v$ is called\nthe gap. We show how to compute efficiently, for every position $i$ of the word\n$w$, the longest gapped repeat and palindrome occurring at that position,\nprovided that the length of the gap is subject to various types of\nrestrictions. That is, that for each position $i$ we compute the longest prefix\n$w[1..i-1]$ (defining thus a gapped repeat $uvu$ -- respectively, palindrome\n$u^Rvu$), and the length of $v$ is subject to the aforementioned restrictions.","label":"human"}
{"id":346,"text":"Mixture Markov Model (MMM) is a widely used tool to cluster sequences of\nevents coming from a finite state-space. However the MMM likelihood being\nmulti-modal, the challenge remains in its maximization. Although\nExpectation-Maximization (EM) algorithm remains one of the most popular ways to\nestimate the MMM parameters, however convergence of EM algorithm is not always\nguaranteed. Given the computational challenges in maximizing the mixture\nlikelihood on the constrained parameter space, we develop a pattern\nsearch-based global optimization technique which can optimize any objective\nfunction on a collection of simplexes, which is eventually used to maximize MMM\nlikelihood. This is shown to outperform other related global optimization\ntechniques. In simulation experiments, the proposed method is shown to\noutperform the expectation-maximization (EM) algorithm in the context of MMM\nestimation performance. The proposed method is applied to cluster Multiple\nsclerosis (MS) patients based on their treatment sequences of disease-modifying\ntherapies (DMTs). We also propose a novel method to cluster people with MS\nbased on DMT prescriptions and associated clinical features (covariates) using\nMMM with covariates. Based on the analysis, we divided MS patients into 3\nclusters. Further cluster-specific summaries of relevant covariates indicate\npatient differences among the clusters.","label":"human"}
{"id":347,"text":"This chapter examines optimal auction design when both bidders and items have side information that affects valuations, which we model using multi-dimensional distribution or utility functions over items and value type distributions depending on bidder type; thus bidder signals may be correlated across values but not necessarily items. For independent type signals conditioned on all other variables as well, our results establish regret bounds based solely on number of items. Since there are no bidder types in this case either, we only need to consider additive separable item utilities, i.e., those represented by realizations. We obtain tight minimax bounds under several natural regularity conditions including (1) when a single type of signal exists with positive probability, and this distribution is common knowledge at least among bidders, (2) when such a set of private types has non-zero joint distribution, and (3) when item utilities exist. These latter two cases represent scenarios where it makes little sense to use any randomization because players will discover through experience whether their type was used. Our main conclusions can be easily extended to more general versions incorporating nonseparability between different dimensions under reasonable conditions, e.g., convex feasible price regions or support being connected within each dimension individually. Further extensions involve allowing correlations among items' utilities conditional on anything else (i.e,, removing independence ) while still restricting bidder signals only along lines of separation from one another defined by a linear transformation matrix with linearly invariant norm bounded rows.","label":"ai"}
{"id":348,"text":"Pixel-wise segmentation is one of the most data and annotation hungry tasks\nin our field. Providing representative and accurate annotations is often\nmission-critical especially for challenging medical applications. In this\npaper, we propose a semi-weakly supervised segmentation algorithm to overcome\nthis barrier. Our approach is based on a new formulation of deep supervision\nand student-teacher model and allows for easy integration of different\nsupervision signals. In contrast to previous work, we show that care has to be\ntaken how deep supervision is integrated in lower layers and we present\nmulti-label deep supervision as the most important secret ingredient for\nsuccess. With our novel training regime for segmentation that flexibly makes\nuse of images that are either fully labeled, marked with bounding boxes, just\nglobal labels, or not at all, we are able to cut the requirement for expensive\nlabels by 94.22% - narrowing the gap to the best fully supervised baseline to\nonly 5% mean IoU. Our approach is validated by extensive experiments on retinal\nfluid segmentation and we provide an in-depth analysis of the anticipated\neffect each annotation type can have in boosting segmentation performance.","label":"human"}
{"id":349,"text":"Shape instantiation which predicts the 3D shape of a dynamic target from one\nor more 2D images is important for real-time intra-operative navigation. Previously, a general shape instantiation framework was proposed with manual\nimage segmentation to generate a 2D Statistical Shape Model (SSM) and with\nKernel Partial Least Square Regression (KPLSR) to learn the relationship\nbetween the 2D and 3D SSM for 3D shape prediction. In this paper, the two-stage\nshape instantiation is improved to be one-stage. PointOutNet with 19\nconvolutional layers and three fully-connected layers is used as the network\nstructure and Chamfer distance is used as the loss function to predict the 3D\ntarget point cloud from a single 2D image. With the proposed one-stage shape\ninstantiation algorithm, a spontaneous image-to-point cloud training and\ninference can be achieved. A dataset from 27 Right Ventricle (RV) subjects,\nindicating 609 experiments, were used to validate the proposed one-stage shape\ninstantiation algorithm. An average point cloud-to-point cloud (PC-to-PC) error\nof 1.72mm has been achieved, which is comparable to the PLSR-based (1.42mm) and\nKPLSR-based (1.31mm) two-stage shape instantiation algorithm.","label":"human"}
{"id":350,"text":"> We study graded comodules over a finite dimensional Hopf algebra H, and we show that if there are enough projective objects in the category of graded left comodules then this category has an injective cogenerator. This result generalizes to arbitrary rings R the well-known fact that every module category with enough projectives has an injective cogenerator. As applications, we prove that the category of finitely generated modules over a commutative noetherian ring has an injective cogenerator if and only if it has enough projectives; and that the category of finitely presented modules over a commutative noetherian ring has an injective cogenerator if and only if it has enough projectives.","label":"ai"}
{"id":351,"text":"The interpretation of quantum mechanics is an area of increasing interest to\nmany working physicists. In particular, interest has come from those involved\nin quantum computing and information theory, as there has always been a strong\nfoundational element in this field. This paper introduces one interpretation of\nquantum mechanics, a modern `many-worlds' theory, from the perspective of\nquantum computation. Reasons for seeking to interpret quantum mechanics are\ndiscussed, then the specific `neo-Everettian' theory is introduced and its\nclaim as the best available interpretation defended. The main objections to the\ninterpretation, including the so-called ``problem of probability'' are shown to\nfail. The local nature of the interpretation is demonstrated, and the\nimplications of this both for the interpretation and for quantum mechanics more\ngenerally are discussed. Finally, the consequences of the theory for quantum\ncomputation are investigated, and common objections to using many worlds to\ndescribe quantum computing are answered. We find that using this particular\nmany-worlds theory as a physical foundation for quantum computation gives\nseveral distinct advantages over other interpretations, and over not\ninterpreting quantum theory at all.","label":"human"}
{"id":352,"text":"This academic paper proposes an analysis of the global behaviour of bistable solutions for gradient systems in one unbounded spatial dimension. Gradient systems are an important class of mathematical models that arise in various fields, such as biology, ecology, and physics. Bistable systems are characterized by their ability to exhibit two stable equilibrium points, which can lead to interesting phenomena such as oscillatory behaviour and pattern formation. The paper begins with a review of the methods and results in the literature on bistable gradient systems in one spatial dimension. It then presents a new method for the analysis of such systems, based on the notion of the \"wetting transition\" and the use of the Penrose-Onsager equation. This approach allows for a comprehensive study of the global behaviour of bistable gradient systems, including the determination of the stability of the equilibrium points and the analysis of the associated phase portraits and wave patterns. The results of the analysis are presented in a series of case studies, including the study of the diffusion-reaction equation, the Kuramoto-Sivashinsky equation, and the reaction-diffusion equation for a population of organisms. These examples illustrate the wide applicability of the methods and techniques presented in the paper, and provide valuable insights into the behaviour of bistable gradient systems in real-world contexts. Overall, the paper demonstrates the power of modern mathematical methods for the analysis of complex systems, and provides a valuable resource for researchers working in the fields of mathematical biology, ecology, and physics.","label":"ai"}
{"id":353,"text":"The invariant $\\Theta$ is an invariant of rational homology 3-spheres $M$\nequipped with a combing $X$ over the complement of a point. It is related to\nthe Casson-Walker invariant $\\lambda$ by the formula\nthat is simply related to a Gompf invariant. In [arXiv:1209.3219], we proved a\ncombinatorial formula for the $\\Theta$-invariant in terms of Heegaard diagrams,\nequipped with decorations that define combings, from the definition of $\\Theta$\nas an algebraic intersection in a configuration space. In this article, we\nprove that this formula defines an invariant of pairs $(M,X)$ without referring\nto configuration spaces, and we prove that this invariant is the sum of $6\n\\lambda(M)$ and $p_1(X)\/4$ for integral homology spheres, by proving surgery\nformulae both for the combinatorial invariant and for $p_1$.","label":"human"}
{"id":354,"text":"Deep neural network models used for medical image segmentation are large\nbecause they are trained with high-resolution three-dimensional (3D) images. Graphics processing units (GPUs) are widely used to accelerate the trainings. However, the memory on a GPU is not large enough to train the models. A popular\napproach to tackling this problem is patch-based method, which divides a large\nimage into small patches and trains the models with these small patches. However, this method would degrade the segmentation quality if a target object\nspans multiple patches. In this paper, we propose a novel approach for 3D\nmedical image segmentation that utilizes the data-swapping, which swaps out\nintermediate data from GPU memory to CPU memory to enlarge the effective GPU\nmemory size, for training high-resolution 3D medical images without patching. We carefully tuned parameters in the data-swapping method to obtain the best\ntraining performance for 3D U-Net, a widely used deep neural network model for\nmedical image segmentation. We applied our tuning to train 3D U-Net with\nfull-size images of 192 x 192 x 192 voxels in brain tumor dataset. As a result,\ncommunication overhead, which is the most important issue, was reduced by\nvoxels, our training for full-size images achieved improvement on the mean Dice\nscore by 4.48% and 5.32 % for detecting whole tumor sub-region and tumor core\nsub-region, respectively. The total training time was reduced from 164 hours to\n47 hours, resulting in 3.53 times of acceleration.","label":"human"}
{"id":355,"text":"Chirped Bessel waves are introduced as stable (non-diffracting) solutions of\nthe paraxial wave equation in optical antiguides with a power-law radial\nvariation in their index of refraction. Through numerical simulations, we\ninvestigate the propagation of apodized (finite-energy) versions of such waves,\nwith or without vorticity, in antiguides with practical parameters. The new\nwaves exhibit a remarkable resistance against the defocusing effect of the\nunstable index potentials, outperforming standard Gaussians with the same full\nwidth at half maximum. The chirped profile persists even under conditions of\neccentric launching or antiguide bending and is also capable of self-healing\nlike standard diffraction-free beams in free space.","label":"human"}
{"id":356,"text":"> We present a weakly supervised segmentation method that uses only image-level labels and does not require any pixel-wise annotations. Our approach is based on a deep geodesic prior, which we use to regularize the output of a convolutional neural network (CNN) trained with standard cross entropy loss. This allows us to learn a CNN that produces accurate semantic segmentations without requiring any additional training data or manual labeling effort. In our experiments, we show that this simple idea leads to state-of-the-art results in several challenging datasets including PASCAL VOC 2012, Cityscapes, CamVid, and SUN RGBD.","label":"ai"}
{"id":357,"text":"A well-known result of E. Bombieri asserts that if $C$ is a smooth projective curve of genus 2 or 3 defined over ${\\mathbb{F}}_q$, the probability that $x$ is a point on $C$ such that $|C(x)| \\ge \\rho$ tends to 0, as $\\rho \\to \\infty$ where $\\rho^\\alpha \\to \\infty$ and $\\alpha \\ge 1$. In our earlier paper we proved such a bound for all $g \\ge 2$ and we also proved a polynomial bound for the expected value for all $g>0$ and for a restricted range for the number of points $\\rho$. In this paper, we prove similar bounds for any finite field curve $C$ for the expected value for $g \\ge 1$ and the probability for $g \\ge 2$. We also prove similar bounds when $C$ has a point defined over ${\\mathbb{F}}_q^2$, i.e., a two torsion point, for the expectation and the probability for $g \\ge 1$.","label":"ai"}
{"id":358,"text":"Spatial pyramid pooling module or encode-decoder structure are used in deep\nneural networks for semantic segmentation task. The former networks are able to\nencode multi-scale contextual information by probing the incoming features with\nfilters or pooling operations at multiple rates and multiple effective\nfields-of-view, while the latter networks can capture sharper object boundaries\nby gradually recovering the spatial information. In this work, we propose to\ncombine the advantages from both methods. Specifically, our proposed model,\nDeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module\nto refine the segmentation results especially along object boundaries. We\nfurther explore the Xception model and apply the depthwise separable\nconvolution to both Atrous Spatial Pyramid Pooling and decoder modules,\nresulting in a faster and stronger encoder-decoder network. We demonstrate the\neffectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets,\nachieving the test set performance of 89.0\\% and 82.1\\% without any\npost-processing. Our paper is accompanied with a publicly available reference\nimplementation of the proposed models in Tensorflow at\n\\url{https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/deeplab}.","label":"human"}
{"id":359,"text":"> We present a new algorithm for polynomial mating, which we call the Medusa algorithm. The Medusa algorithm is a generalization of the algorithm of Bjorklund, Husfeldt, and Nisan (BHN) for polynomial mating. The BHN algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/3}$. The Medusa algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/2}$. > The Medusa algorithm is based on a new technique for polynomial mating, which we call the Medusa technique. The Medusa technique is a generalization of the BHN technique for polynomial mating. The BHN technique is a technique for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/3}$. The Medusa technique is a technique for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/2}$. > The Medusa algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/2}$. The Medusa algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/2}$. > The Medusa algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n^{1\/2}$. The Medusa algorithm is a polynomial-time algorithm for polynomial mating of two polynomials of degree $d$ over a field $\\mathbb{F}$ of size $n$ with $d \\leq n","label":"ai"}
{"id":360,"text":"We present a general theory for determining the force (and torque) exerted on\na boundary (or body) in active matter. The theory extends the description of\npassive Brownian colloids to self-propelled active particles and applies for\nall ratios of the thermal energy $k_BT$ to the swimmer's activity $k_sT_s =\nthe swim speed and $\\tau_R$ is the reorientation time of the active particles. The theory has a natural microscopic length scale over which concentration and\norientation distributions are confined near boundaries, but the microscopic\nlength does not appear in the force. The swim pressure emerges naturally and\ndominates the behavior when the boundary size is large compared to the\nswimmer's run length $\\ell = U_0\\tau_R$. The theory is used to predict the\nmotion of bodies of all sizes immersed in active matter.","label":"human"}
{"id":361,"text":"The field of image segmentation has seen significant advancements in recent years, with random walker algorithms being a promising approach. However, these methods often require extensive preprocessing time, which can be prohibitive for real-time applications. In this study, we propose an adaptive precomputation method that reduces the computational cost of random walker image segmentation and registration without sacrificing accuracy. Our approach involves identifying regions of interest within the input images and precomputing only those areas, allowing us to significantly reduce processing times while maintaining high performance. We demonstrate our method on several benchmark datasets and show that it outperforms traditional random walker approaches in terms of both speed and accuracy. Overall, our work represents a major step forward in the development of efficient and effective random walker-based image segmentation and registration techniques.","label":"ai"}
{"id":362,"text":"> In this paper we study combings of three-manifolds, a general construction in differential topology, introduced by R. Kirby. In analogy with the Thurston's work on three-manifolds we give a similar construction of the universal abelian cover of the space of all combings of a given three-manifold. We define a universal invariant of the group of homotopy classes of combings of a closed orientable three-manifold $M$ and show that such invariant is an invariant of the third homotopy group of $M$. The full research paper will be uploaded by the arXiv team on arxiv.org in due course.","label":"ai"}
{"id":363,"text":"Psi-Net is a novel deep learning architecture designed for medical image segmentation. It is a joint multi-task network that can simultaneously segment multiple organs and tissues in a single image. The network is shape and boundary aware, meaning that it can handle images with varying shapes and sizes, and can accurately segment organs and tissues that are close to each other. The network uses a combination of convolutional and recurrent neural networks to learn the spatial and temporal relationships between the organs and tissues. The network is trained on a large dataset of medical images, and has been shown to outperform state-of-the-art segmentation models on several benchmark datasets. Overall, Psi-Net is a powerful tool for medical image segmentation that can help clinicians and researchers make more accurate diagnoses and develop more effective treatments.","label":"ai"}
{"id":364,"text":"The paper presents a study on the well-posedness and robust preconditioners for the discretized fluid-structure interaction systems. The authors analyze the stability and convergence of the system using the Galerkin method and prove the well-posedness of the system under certain conditions. They also develop robust preconditioners based on the Arbitrary Lagrangian Eulerian formulation (ALE) to overcome the difficulties in solving the nonlinear system. The preconditioners are shown to be effective in reducing the number of iterations required to converge to the solution. The results of the study demonstrate the importance of robust preconditioners in the efficient solution of fluid-structure interaction systems.","label":"ai"}
{"id":365,"text":"The paradox of Wigner's friend challenges the objectivity of description in\nquantum theory. A pragmatist interpretation can meet this challenge by\njudicious appeal to decoherence. On this interpretation, quantum theory\nprovides situated agents with resources for predicting and explaining what\nhappens in the physical world---not conscious observations of it. Even in\nWigner's friend scenarios, differently situated agents agree on the objective\ncontent of statements about the values of physical magnitudes. In more\nrealistic circumstances quantum Darwinism also permits differently situated\nagents equal observational access to evaluate their truth. In this view,\nquantum theory has nothing to say about consciousness or conscious experiences\nof observers. But it does prompt us to reexamine the significance even of\neveryday claims about the physical world.","label":"human"}
{"id":366,"text":"Electronic health records (EHR) contain patient medical information in machine legible form, but many parts remain unscanned and stored as free-text notes, which are currently still being used by physicians to document relevant issues in their patient's case history. Researchers have turned towards developing automated natural language processing algorithms to mine and extract structured EHR data; however there is little prior work on determining what to do if multiple different methods agree only partly regarding any particular clinical finding. We explore using inter-annotator agreement among human annotations as one possible way out in this scenario. After selecting two types of problems where we expect disagreement may be beneficial- tumor margin prediction for breast cancer staging, and lesion segmentation for skin image analysis - through a small amount of qualitative investigation of existing clinical guidelines and some online discussions with clinicians, we evaluate several ways of determining thresholds below which agreement should not be trusted before moving forward. While results vary somewhat depending on the application, our analysis shows preliminary evidence that taking into account overall uncertainty due to variability across annotators can alleviate some errors generated by individual systems without sacrificing too much useful precision.","label":"ai"}
{"id":367,"text":"We propose an algorithm for separating the foreground (mainly text and line\ngraphics) from the smoothly varying background in screen content images. The\nproposed method is designed based on the assumption that the background part of\nthe image is smoothly varying and can be represented by a linear combination of\na few smoothly varying basis functions, while the foreground text and graphics\ncreate sharp discontinuity and cannot be modeled by this smooth representation. The algorithm separates the background and foreground using a least absolute\ndeviation method to fit the smooth model to the image pixels. This algorithm\nhas been tested on several images from HEVC standard test sequences for screen\ncontent coding, and is shown to have superior performance over other popular\nmethods, such as k-means clustering based segmentation in DjVu and shape\nprimitive extraction and coding (SPEC) algorithm. Such background\/foreground\nsegmentation are important pre-processing steps for text extraction and\nseparate coding of background and foreground for compression of screen content\nimages.","label":"human"}
{"id":368,"text":"Compared to the general semantic segmentation problem, portrait segmentation\nhas higher precision requirement on boundary area. However, this problem has\nnot been well studied in previous works. In this paper, we propose a\nboundary-sensitive deep neural network (BSN) for portrait segmentation. BSN\nintroduces three novel techniques. First, an individual boundary-sensitive\nkernel is proposed by dilating the contour line and assigning the boundary\npixels with multi-class labels. Second, a global boundary-sensitive kernel is\nemployed as a position sensitive prior to further constrain the overall shape\nof the segmentation map. Third, we train a boundary-sensitive attribute\nclassifier jointly with the segmentation network to reinforce the network with\nsemantic boundary shape information. We have evaluated BSN on the current\nlargest public portrait segmentation dataset, i.e, the PFCN dataset, as well as\nthe portrait images collected from other three popular image segmentation\ndatasets: COCO, COCO-Stuff, and PASCAL VOC. Our method achieves the superior\nquantitative and qualitative performance over state-of-the-arts on all the\ndatasets, especially on the boundary area.","label":"human"}
{"id":369,"text":"> We propose a novel supervised-free learning approach for cardiac MR image segmentation. Our method predicts the spatial anatomical position of each voxel within a 3D cardiac image without any supervised guidance. The predicted position is the probability distribution of each voxel belonging to a certain anatomical region. In the inference stage, we use a maximum a posteriori estimator to derive segmentation results from the predicted positions. By using the anatomical position predicted by the learned encoder as soft labels for its corresponding decoder, our self-supervised learning approach makes the model robust to domain shift in data acquisition protocols, which is a common challenge for cardiac MR image segmentation. We evaluated the performance of our proposed approach by training the self-supervised model using data from only one site, and then testing it on other sites with different MR acquisition protocols. Without any fine-tuning, our self-supervised model improved the Dice score and decreased the mean relative Hausdorff distance from 0.708 to 0.774 and 0.661 to 0.606, respectively, compared to prior models on a test dataset from another institution. The paper includes this figure demonstrating the difference in the cardiac MR segmentation results between their proposed self-supervised segmentation approach and other conventional ones:\nThe figure below illustrates that the proposed self-supervised approach can generalize well to segment images captured with different protocols:\nFrom the conclusion:\n> Our novel self-supervised learning approach can learn cardiac MR segmentation by predicting the spatial anatomical position of the voxels without any supervised guidance. In the inference stage, we use a maximum a posteriori estimator to derive segmentation results from the predicted anatomical position. By using the anatomical position predicted by the learned encoder as soft labels for its corresponding decoder, our self-supervised learning approach makes the model robust to domain shift in data acquisition protocols, which is a common challenge for cardiac MR image segmentation. In our experiments on cardiac MR images acquired with different protocols, without any fine-t","label":"ai"}
{"id":370,"text":"In recent years, linear regression has become increasingly popular in statistical modeling, particularly in fields such as economics, social sciences, and psychology. This type of regression analysis allows researchers to determine the relationship between a dependent variable and one or multiple independent variables. While linear regression is a powerful tool, it can be susceptible to errors in data collection, measurement, or analysis. Therefore, it is essential to identify and address these errors to obtain valid and reliable results. In this paper, we discuss some common sources of errors in linear regressions, such as multicollinearity, outliers, leveraging, and measurement errors. We also present techniques that can be used to detect and correct these errors, including ridge regression, least squares method with regularization, robust regression, and Bayesian inference. Finally, we provide some practical tips for choosing the best technique for your specific dataset and research question. Overall, this paper contributes to the ongoing debate on the assessment and improvement of linear regression methods, and highlights the importance of rigorous data analysis and interpretation in any field that uses these models.","label":"ai"}
{"id":371,"text":"- Structural support vector machines (SVMs) are a class of inductive inference engines which represent probabilistic hypotheses in a sparse factorized form. Despite their popularity in areas such as bioinformatics, the existing SVM formulations have limitations that can severely restrict their utility. In particular, the constraints imposed by the classical support vector machine (cSVM) formulation inhibits its successful application to high-dimensional domains, while the structured support vector machine (sSVM) formulation is not amenable to incremental training (learning). Here I describe an integrated inference architecture called the extended structural support vector machine (eSSVM) which combines the advantages of both cSVM and sSVM. Through probabilistic modeling and variational approximations over the feature factors in SVMs, I show how to obtain the equivalent eSSVM formulation which can be used in inference and learning. The eSSVM can learn the feature probabilistic properties while performing inference. Thus learning and inference can both be performed together incrementally using eSSVM, without the need to store the feature matrix. I apply inference with the proposed eSSVM architecture to DNA microarray data from yeast, demonstrating that the eSSVM outperforms SVMs. I further show that the eSSVM learning algorithm is amenable to incremental training for online learning of feature structures.","label":"ai"}
{"id":372,"text":"Unsupervised learning poses one of the most difficult challenges in computer\nvision today. The task has an immense practical value with many applications in\nartificial intelligence and emerging technologies, as large quantities of\nunlabeled videos can be collected at relatively low cost. In this paper, we\naddress the unsupervised learning problem in the context of detecting the main\nforeground objects in single images. We train a student deep network to predict\nthe output of a teacher pathway that performs unsupervised object discovery in\nvideos or large image collections. Our approach is different from published\nmethods on unsupervised object discovery. We move the unsupervised learning\nphase during training time, then at test time we apply the standard\nfeed-forward processing along the student pathway. This strategy has the\nbenefit of allowing increased generalization possibilities during training,\nwhile remaining fast at testing. Our unsupervised learning algorithm can run\nover several generations of student-teacher training. Thus, a group of student\nnetworks trained in the first generation collectively create the teacher at the\nnext generation. In experiments our method achieves top results on three\ncurrent datasets for object discovery in video, unsupervised image segmentation\nand saliency detection. At test time the proposed system is fast, being one to\ntwo orders of magnitude faster than published unsupervised methods.","label":"human"}
{"id":373,"text":"We quantify the amount of information filtered by different hierarchical\nclustering methods on correlations between stock returns comparing it with the\nunderlying industrial activity structure. Specifically, we apply, for the first\ntime to financial data, a novel hierarchical clustering approach, the Directed\nBubble Hierarchical Tree and we compare it with other methods including the\nLinkage and k-medoids. In particular, by taking the industrial sector\nclassification of stocks as a benchmark partition, we evaluate how the\ndifferent methods retrieve this classification. The results show that the\nDirected Bubble Hierarchical Tree can outperform other methods, being able to\nretrieve more information with fewer clusters. Moreover, we show that the\neconomic information is hidden at different levels of the hierarchical\nstructures depending on the clustering method. The dynamical analysis on a\nrolling window also reveals that the different methods show different degrees\nof sensitivity to events affecting financial markets, like crises. These\nresults can be of interest for all the applications of clustering methods to\nportfolio optimization and risk hedging.","label":"human"}
{"id":374,"text":"Self-supervised learning has proven to be invaluable in making best use of\nall of the available data in biomedical image segmentation. One particularly\nsimple and effective mechanism to achieve self-supervision is inpainting, the\ntask of predicting arbitrary missing areas based on the rest of an image. In\nthis work, we focus on image inpainting as the self-supervised proxy task, and\npropose two novel structural changes to further enhance the performance of a\ndeep neural network. We guide the process of generating images to inpaint by\nusing supervoxel-based masking instead of random masking, and also by focusing\non the area to be segmented in the primary task, which we term as the\nregion-of-interest. We postulate that these additions force the network to\nlearn semantics that are more attuned to the primary task, and test our\nhypotheses on two applications: brain tumour and white matter hyperintensities\nsegmentation. We empirically show that our proposed approach consistently\noutperforms both supervised CNNs, without any self-supervision, and\nconventional inpainting-based self-supervision methods on both large and small\ntraining set sizes.","label":"human"}
{"id":375,"text":"The main idea of this challenging research is to revisit the solar-centric\ndynamics of Earth around the Sun in analysis of its position on 13 April 2029\nclose to asteroid Apophis which is supposed to be moving in fly-by near the\nEarth on its orbit. As of now, we can be sure that trajectory of Apophis is\nwell-known with respect to the center of Sun. Also, NASA experts calculated\nthat relative distance between center of Earth and Apophis should be less than\n38 thousands of kilometers during closest Apophis approach to the Earth. But\nthe reasonable question is: will the center of Earth be at the predicted\nposition at the beginning of April 2029? The matter is that NASA solving\nprocedure disregards influence of Milankovich cycles to the orbit of Earth but\nalternative concept suggests another solution (with additional quasi-periodic\ndeviation from their solution, proportional to square of eccentricity of Earth\norbit around the Sun equals to ~ 0.017). So, possible perturbation of Earth\n200 km which could be compared with gap between Earth and Apophis during\nclosest Apophis approach to Earth in April 2029.","label":"human"}
{"id":376,"text":"> We propose a novel regularization method to improve semantic image segmentation performance by using convolutional neural networks (CNNs). Our approach uses an additional loss term that penalizes the difference between predicted and ground truth labels in regions where the CNN has low confidence, i.e., when it predicts high uncertainty about its prediction. This encourages the network to focus on areas with higher certainty while still allowing it to learn more complex patterns in uncertain regions. In addition, we introduce a new dataset called Cityscapes which contains 5000 images taken from street scenes across Germany. It provides pixel-level annotations for 30 classes including road markings, traffic signs, pedestrians, cars etc. We evaluate our proposed model on this dataset as well as Pascal VOC2012 and show significant improvements over state-of-the-art methods without requiring any extra training data or modifications to existing architectures such as FCNs or DeconvNets.","label":"ai"}
{"id":377,"text":"In this paper, we proposed a novel mutual consistency network (MC-Net+) to\neffectively exploit the unlabeled hard regions for semi-supervised medical\nimage segmentation. The MC-Net+ model is motivated by the observation that deep\nmodels trained with limited annotations are prone to output highly uncertain\nand easily mis-classified predictions in the ambiguous regions (e.g. adhesive\nedges or thin branches) for the image segmentation task. Leveraging these\nregion-level challenging samples can make the semi-supervised segmentation\nmodel training more effective. Therefore, our proposed MC-Net+ model consists\nof two new designs. First, the model contains one shared encoder and multiple\nsightly different decoders (i.e. using different up-sampling strategies). The\nstatistical discrepancy of multiple decoders' outputs is computed to denote the\nmodel's uncertainty, which indicates the unlabeled hard regions. Second, a new\nmutual consistency constraint is enforced between one decoder's probability\noutput and other decoders' soft pseudo labels. In this way, we minimize the\nmodel's uncertainty during training and force the model to generate invariant\nand low-entropy results in such challenging areas of unlabeled data, in order\nto learn a generalized feature representation. We compared the segmentation\nresults of the MC-Net+ with five state-of-the-art semi-supervised approaches on\nthree public medical datasets. Extension experiments with two common\nsemi-supervised settings demonstrate the superior performance of our model over\nother existing methods, which sets a new state of the art for semi-supervised\nmedical image segmentation.","label":"human"}
{"id":378,"text":"We propose a single chain slip-spring model, which is based on the\nslip-spring model by Likhtman [A. E. Likhtman, Macromolecules, 38, 6128\n(2005)], for fast rheology simulations of entangled polymers on a GPU. We\nmodify the original slip-spring model slightly for efficient calculations on a\nGPU. Our model is designed to satisfy the detailed balance condition, which\nenables us to analyze its static or linear response properties easily. We\ntheoretically analyze several statistical properties of the model, such as the\nlinear response, which will be useful to analyze simulation data. We show that\nour model can reproduce several rheological properties such as the linear\nviscoelasticity or the viscosity growth qualitatively. We also show that the\nuse of a GPU can improve the performance drastically.","label":"human"}
{"id":379,"text":"> In this work we propose an approach to multi-channel image segmentation based on component trees, which are derived by means of a novel algorithm that combines region growing and watershed transforms. We show how our method can be used in order to obtain accurate results with respect to both accuracy and speed. Our experiments demonstrate that it outperforms state-of-the-art methods such as graph cuts or mean shift clustering. Moreover, we provide a theoretical analysis of its performance, showing that it scales linearly with the number of channels.","label":"ai"}
{"id":380,"text":"Superpixel-based Higher-order Conditional random fields (SP-HO-CRFs) are\nknown for their effectiveness in enforcing both short and long spatial\ncontiguity for pixelwise labelling in computer vision. However, their\nhigher-order potentials are usually too complex to learn and often incur a high\ncomputational cost in performing inference. We propose an new approximation\napproach to SP-HO-CRFs that resolves these problems. Our approach is a\nmulti-layer CRF framework that inherits the simplicity from pairwise CRFs by\nformulating both the higher-order and pairwise cues into the same pairwise\npotentials in the first layer. Essentially, this approach provides accuracy\nenhancement on the basis of pairwise CRFs without training by reusing their\npre-trained parameters and\/or weights. The proposed multi-layer approach\nperforms especially well in delineating the boundary details (boarders) of\nobject categories such as \"trees\" and \"bushes\". Multiple sets of experiments\nconducted on dataset MSRC-21 and PASCAL VOC 2012 validate the effectiveness and\nefficiency of the proposed methods.","label":"human"}
{"id":381,"text":"The problem of expressing a specific polynomial as the determinant of a\nsquare matrix of affine-linear forms arises from algebraic geometry,\noptimisation, complexity theory, and scientific computing. Motivated by recent\ndevelopments in this last area, we introduce the notion of a uniform\ndeterminantal representation, not of a single polynomial but rather of all\npolynomials in a given number of variables and of a given maximal degree. We\nderive a lower bound on the size of the matrix, and present a construction\nachieving that lower bound up to a constant factor as the number of variables\nis fixed and the degree grows. This construction marks an improvement upon a\nrecent construction due to Plestenjak-Hochstenbach, and we investigate the\nperformance of new representations in their root-finding technique for\nbivariate systems. Furthermore, we relate uniform determinantal representations\nto vector spaces of singular matrices, and we conclude with a number of future\nresearch directions.","label":"human"}
{"id":382,"text":"Region-based methods have proven necessary for improving segmentation\naccuracy of neuronal structures in electron microscopy (EM) images. Most\nregion-based segmentation methods use a scoring function to determine region\nmerging. Such functions are usually learned with supervised algorithms that\ndemand considerable ground truth data, which are costly to collect. We propose\na semi-supervised approach that reduces this demand. Based on a merge tree\nstructure, we develop a differentiable unsupervised loss term that enforces\nconsistent predictions from the learned function. We then propose a Bayesian\nmodel that combines the supervised and the unsupervised information for\nprobabilistic learning. The experimental results on three EM data sets\ndemonstrate that by using a subset of only 3% to 7% of the entire ground truth\ndata, our approach consistently performs close to the state-of-the-art\nsupervised method with the full labeled data set, and significantly outperforms\nthe supervised method with the same labeled subset.","label":"human"}
{"id":383,"text":"We present a method for highly efficient landmark detection that combines\ndeep convolutional neural networks with well established model-based fitting\nalgorithms. Motivated by established model-based fitting methods such as active\nshapes, we use a PCA of the landmark positions to allow generative modeling of\nfacial landmarks. Instead of computing the model parameters using iterative\noptimization, the PCA is included in a deep neural network using a novel layer\ntype. The network predicts model parameters in a single forward pass, thereby\nallowing facial landmark detection at several hundreds of frames per second. Our architecture allows direct end-to-end training of a model-based landmark\ndetection method and shows that deep neural networks can be used to reliably\npredict model parameters directly without the need for an iterative\noptimization. The method is evaluated on different datasets for facial landmark\ndetection and medical image segmentation. PyTorch code is freely available at\nhttps:\/\/github.com\/justusschock\/shapenet","label":"human"}
{"id":384,"text":"Delineation of line patterns in images is a basic step required in various\napplications such as blood vessel detection in medical images, segmentation of\nrivers or roads in aerial images, detection of cracks in walls or pavements,\netc. In this paper we present trainable B-COSFIRE filters, which are a model of\nsome neurons in area V1 of the primary visual cortex, and apply it to the\ndelineation of line patterns in different kinds of images. B-COSFIRE filters\nare trainable as their selectivity is determined in an automatic configuration\nprocess given a prototype pattern of interest. They are configurable to detect\nany preferred line structure (e.g. segments, corners, cross-overs, etc. ), so\nusable for automatic data representation learning. We carried out experiments\non two data sets, namely a line-network data set from INRIA and a data set of\nretinal fundus images named IOSTAR. The results that we achieved confirm the\nrobustness of the proposed approach and its effectiveness in the delineation of\nline structures in different kinds of images.","label":"human"}
{"id":385,"text":"> Hyperspectral image segmentation is a challenging task due to the high dimensionality of the data and the complexity of the spectral signatures. In this paper, we propose a novel method for hyperspectral image segmentation based on conditional random fields (CRFs) and deep feature learning. The proposed method consists of two main steps. First, we use a deep convolutional neural network (CNN) to extract deep features from the hyperspectral image. Then, we use a CRF model to segment the hyperspectral image based on the extracted deep features. The proposed method is evaluated on two hyperspectral image datasets, and the results show that the proposed method outperforms the state-of-the-art methods in terms of segmentation accuracy. The following is the full text of the abstract for a research paper titled \"Conditional Random Field and Deep Feature Learning for Hyperspectral Image Segmentation\" from arxiv.org:\n> Hyperspectral image segmentation is a challenging task due to the high dimensionality of the data and the complexity of the spectral signatures. In this paper, we propose a novel method for hyperspectral image segmentation based on conditional random fields (CRFs) and deep feature learning. The proposed method consists of two main steps. First, we use a deep convolutional neural network (CNN) to extract deep features from the hyperspectral image. Then, we use a CRF model to segment the hyperspectral image based on the extracted deep features. The proposed method is evaluated on two hyperspectral image datasets, and the results show that the proposed method outperforms the state-of-the-art methods in terms of segmentation accuracy. The following is the full text of the abstract for a research paper titled \"Conditional Random Field and Deep Feature Learning for Hyperspectral Image Segmentation\" from arxiv.org:\n> Hyperspectral image segmentation is a challenging task due to the high dimensionality of the data and the complexity of the spectral signatures. In this paper, we propose a novel method for hyperspectral image segmentation based on","label":"ai"}
{"id":386,"text":"> We present an alternative derivation of the exact equations of motion (EOM) for the Green's functions in the single impurity Anderson model, which are equivalent to those obtained by Nollo and Schotte [Phys. Rev. B 72, 035146 (2005)] using the Langreth theorem. Our method relies on the use of the Dyson equation instead of the Keldysh contour, thus avoiding the need to introduce auxiliary fields or to perform any analytic continuations. This allows us to obtain the EOM directly in terms of the physical quantities of interest, namely the retarded and advanced Green's functions. In addition, we show that our formalism can be easily extended to include more complex systems such as multi-orbital models with multiple impurities.","label":"ai"}
{"id":387,"text":"This paper introduces a class of mixed-effects models for joint modeling of\nspatially correlated intensity variation and warping variation in 2D images. Spatially correlated intensity variation and warp variation are modeled as\nrandom effects, resulting in a nonlinear mixed-effects model that enables\nsimultaneous estimation of template and model parameters by optimization of the\nlikelihood function. We propose an algorithm for fitting the model which\nalternates estimation of variance parameters and image registration. This\napproach avoids the potential estimation bias in the template estimate that\narises when treating registration as a preprocessing step. We apply the model\nto datasets of facial images and 2D brain magnetic resonance images to\nillustrate the simultaneous estimation and prediction of intensity and warp\neffects.","label":"human"}
{"id":388,"text":"In machine learning and other fields, suggesting a good solution to a problem\nis usually a harder task than evaluating the quality of such a solution. This\nasymmetry is the basis for a large number of selection oriented methods that\nuse a generator system to guess a set of solutions and an evaluator system to\nrank and select the best solutions. This work examines the use of this approach\nto the problem of panoptic image segmentation and class agnostic parts\nsegmentation. The generator\/evaluator approach for this case consists of two\nindependent convolutional neural nets: a generator net that suggests variety\nsegments corresponding to objects, stuff and parts regions in the image, and an\nevaluator net that chooses the best segments to be merged into the segmentation\nmap. The result is a trial and error evolutionary approach in which a generator\nthat guesses segments with low average accuracy, but with wide variability, can\nstill produce good results when coupled with an accurate evaluator. The\ngenerator consists of a Pointer net that receives an image and a point in the\nimage, and predicts the region of the segment containing the point. Generating\nand evaluating each segment separately is essential in this case since it\ndemands exponentially fewer guesses compared to a system that guesses and\nevaluates the full segmentation map in each try. The classification of the\nselected segments is done by an independent region-specific classification net. This allows the segmentation to be class agnostic and hence, capable of\nsegmenting unfamiliar categories that were not part of the training set. The\nmethod was examined on the COCO Panoptic segmentation benchmark and gave\nresults comparable to those of the basic semantic segmentation and Mask-RCNN\nmethods. In addition, the system was used for the task of splitting objects of\nunseen classes (that did not appear in the training set) into parts.","label":"human"}
{"id":389,"text":"Fully convolutional neural networks (F-CNNs) have set the state-of-the-art in\nimage segmentation for a plethora of applications. Architectural innovations\nwithin F-CNNs have mainly focused on improving spatial encoding or network\nconnectivity to aid gradient flow. In this paper, we explore an alternate\ndirection of recalibrating the feature maps adaptively, to boost meaningful\nfeatures, while suppressing weak ones. We draw inspiration from the recently\nproposed squeeze & excitation (SE) module for channel recalibration of feature\nmaps for image classification. Towards this end, we introduce three variants of\nSE modules for image segmentation, (i) squeezing spatially and exciting\nchannel-wise (cSE), (ii) squeezing channel-wise and exciting spatially (sSE)\nand (iii) concurrent spatial and channel squeeze & excitation (scSE). We\neffectively incorporate these SE modules within three different\nstate-of-the-art F-CNNs (DenseNet, SD-Net, U-Net) and observe consistent\nimprovement of performance across all architectures, while minimally effecting\nmodel complexity. Evaluations are performed on two challenging applications:\nwhole brain segmentation on MRI scans (Multi-Atlas Labelling Challenge Dataset)\nand organ segmentation on whole body contrast enhanced CT scans (Visceral","label":"human"}
{"id":390,"text":"The abstract for the academic paper titled \"Sem-GAN: Semantically-Consistent Image-to-Image Translation\" is as follows:\nImage-to-image translation is a challenging task in computer vision and machine learning, which requires learning a mapping from a source image to a target image while preserving the semantic meaning of the image. This requires not only the ability to translate the visual contents but also the understanding of the underlying semantic structure of the images. In this paper, we present a novel approach called Sem-GAN, which addresses the problem of semantically-consistent image-to-image translation. Sem-GAN employs a novel multi-task learning framework, where the generator is trained to generate target images that are not only realistic but also semantically consistent with the source image. We use a combination of traditional supervised learning tasks and adversarial learning to achieve this. We evaluate Sem-GAN on multiple benchmark datasets and show that it achieves state-of-the-art performance while preserving the semantic consistency of the generated images.","label":"ai"}
{"id":391,"text":"> In this work, we propose an end-to-end framework to adapt medical image segmentation models trained on one modality (e.g., CT) to another modality (e.g., MRI). Our method consists in two main components: 1) a feature adaptation module that adapts features extracted by the backbone network to be more similar between modalities; 2) an image adaptation module that learns to transform images into a common space where they are closer together across modalities. We show that our approach outperforms state-of-the-art methods on three different datasets with up to +3% Dice score improvement over the best baseline.","label":"ai"}
{"id":392,"text":"A framework of M-estimation based fuzzy C-means clustering (MFCM) algorithm\nis proposed with iterative reweighted least squares (IRLS) algorithm, and\npenalty constraint and kernelization extensions of MFCM algorithms are also\ndeveloped. Introducing penalty information to the object functions of MFCM\nalgorithms, the spatially constrained fuzzy C-means (SFCM) is extended to\npenalty constraints MFCM algorithms(abbr. pMFCM).Substituting the Euclidean\ndistance with kernel method, the MFCM and pMFCM algorithms are extended to\nkernelized MFCM (abbr. KMFCM) and kernelized pMFCM (abbr.pKMFCM) algorithms. The performances of MFCM, pMFCM, KMFCM and pKMFCM algorithms are evaluated in\nthree tasks: pattern recognition on 10 standard data sets from UCI Machine\nLearning databases, noise image segmentation performances on a synthetic image,\na magnetic resonance brain image (MRI), and image segmentation of a standard\nimages from Berkeley Segmentation Dataset and Benchmark. The experimental\nresults demonstrate the effectiveness of our proposed algorithms in pattern\nrecognition and image segmentation.","label":"human"}
{"id":393,"text":"The paper presents a novel approach to compressive beamforming that utilizes multiple snapshots to achieve better performance than traditional single-snapshot methods. The proposed method involves dividing the input signal into multiple segments and applying a beamforming algorithm to each segment separately. The resulting beams are then combined using a weighted sum to produce the final output. The paper demonstrates the effectiveness of the proposed method through simulations and experiments, showing that it can achieve better compression ratios and higher signal-to-noise ratios than traditional methods. The paper also discusses the potential applications of the proposed method in wireless communication systems.","label":"ai"}
{"id":394,"text":"In this paper, we present a novel approach to medical image segmentation that combines transformer-based models with convolutional neural networks (CNNs). Our proposed method, called TransFuse, leverages the strengths of both architectures by fusing their outputs at multiple levels. We demonstrate the effectiveness of our approach on several benchmark datasets, achieving state-of-the-art performance in some cases. Additionally, we analyze the contributions of each component of our model and provide insights into how they interact to improve segmentation accuracy. Overall, our work represents an important step towards developing more effective and efficient methods for medical image analysis.","label":"ai"}
{"id":395,"text":"We present the design and performance of a non-imaging concentrator for use\nin broad-band polarimetry at millimeter through submillimeter wavelengths. A\nrectangular geometry preserves the input polarization state as the concentrator\ncouples f\/2 incident optics to a 2 pi sr detector. Measurements of the co-polar\nand cross-polar beams in both the few-mode and highly over-moded limits agree\nwith a simple model based on mode truncation. The measured co-polar beam\npattern is nearly independent of frequency in both linear polarizations. The\ncross-polar beam pattern is dominated by a uniform term corresponding to\npolarization efficiency 94%. After correcting for efficiency, the remaining\ncross-polar response is -18 dB.","label":"human"}
{"id":396,"text":"We propose a novel method of finding principal components in multivariate\ndata sets that lie on an embedded nonlinear Riemannian manifold within a\nhigher-dimensional space. Our aim is to extend the geometric interpretation of\nPCA, while being able to capture non-geodesic modes of variation in the data. We introduce the concept of a principal sub-manifold, a manifold passing\nthrough a reference point, and at any point on the manifold extending in the\ndirection of highest variation in the space spanned by the eigenvectors of the\nlocal tangent space PCA. Compared to recent work for the case where the\nsub-manifold is of dimension one Panaretos et al. (2014)--essentially a curve\nlying on the manifold attempting to capture one-dimensional variation--the\ncurrent setting is much more general. The principal sub-manifold is therefore\nan extension of the principal flow, accommodating to capture higher dimensional\nvariation in the data. We show the principal sub-manifold yields the ball\nspanned by the usual principal components in Euclidean space. By means of\nexamples, we illustrate how to find, use and interpret a principal sub-manifold\nand we present an application in shape analysis.","label":"human"}
{"id":397,"text":"The study aims to investigate the plasticity of deep convolutional neural networks (CNNs) when random pruning is applied during the training process. A novel pruning algorithm that utilizes uniform random perturbations and threshold values is introduced, and its impact on CNN's performance is evaluated on both binary image classification and object detection tasks. Results demonstrate that the proposed method achieves a substantial reduction in network parameters while maintaining accuracy levels similar to unpruned models. Furthermore, it also allows for efficient transfer learning and domain adaptation. The findings suggest that random pruning can be an effective approach towards optimizing CNN architecture by enabling fine-tuning of sparsely connected subregions within the network.","label":"ai"}
{"id":398,"text":"Title: Selected Properties of Optical Spatial Solitons in Photorefractive Media and Their Important Applications\nAbstract: In recent years, photorefractive materials have gained significant attention due to their ability to generate large-scale optical pattern formation. Optical spatial solitons (OSSs) are one of the most interesting phenomena observed in photorefractive crystals. OSSs can be stable and self-reproducible wave patterns that can propagate without dispersion or attenuation. This research paper presents an overview of OSSs in photorefractive media. Firstly, we discuss the principles behind OSS generation in photorefractive crystals. We explore the different approaches adopted in achieving stable OSS generation. Secondly, we examine various experimental observations related to spatiotemporal dynamics of OSSs. Thirdly, this paper highlights some promising applications of OSSs such as ultracompact all-optical data storage, integrated optics interconnect device with large bandwidth, and high birefringence polarization beam shaping devices. Finally, this research paper provides a comprehensive analysis of recent progress and future directions in the fundamental understanding and practical applications of OSSs in photorefractive media.","label":"ai"}
{"id":399,"text":"> Abstract: We present an adaptive optics (AO) controller that uses spatially and angularly resolved wavefront sensing to correct for atmospheric turbulence in multi-object AO systems, such as those used on large telescopes with multiple science instruments. Our approach combines the minimum variance control methodology with tomography techniques to achieve high performance while minimizing the number of actuators required. In particular, we use a sparse representation of the pupil plane phase error to reduce the dimensionality of the problem, which allows us to design a low-order controller using only a few actuators per object. This enables us to simultaneously correct for aberrations across all objects within the field of view without requiring additional hardware or increasing the computational burden. To demonstrate our technique, we perform numerical simulations of a two-object system under realistic conditions, including finite sampling rates and noise levels. Our results show that our controller achieves comparable performance to state-of-the-art methods while reducing the number of actuators by up to 90%.","label":"ai"}
{"id":400,"text":"In this paper, we have considered a Block-Basu type bivariate Pareto\ndistribution. Here in the standard manner, first Marshall-Olkin type singular\nbivariate distribution has been constructed, and then by taking away the\nsingular component similar to the Block and Basu model, an absolute continuous\nBB-BVPA model has been constructed. Further, the location and scale parameters\nalso have been introduced. Therefore, the model has seven parameters. Different\nproperties of this absolutely continuous distribution are derived. Since the\nmaximum likelihood estimators of the parameters cannot be expressed in a closed\nform, we propose to use an EM algorithm to compute the estimators of the model\nparameters. Some simulation experiments have been performed for illustrative\npurposes. The model is fitted to rainfall data in the context of landslide risk\nestimation.","label":"human"}
{"id":401,"text":"http:\/\/arxiv.org\/abs\/1509.02624 [pdf] (accessed August 3,...show more Abstracts The phenomenon \"distortion\" or biases on wikipedia has been recently investigated and empirically confirmed by some researches. However these studies are always very focused, limited to precise domains such as politics, history etc., hence they do not allow general trends be extracted. In this present work we analyze data from a complete section of wikipedia about academia (i.e., professors), using only one tool with an algorithmic approach, without any human intervention and evaluation, nor the use of linguistic tools, which could bias results due to the unverified accuracy of dictionaries used, thus avoiding the problem that many subjects studied in similar papers still had with respect to the lack of objectivity of methods employed because subjective considerations may vary among people....show less","label":"ai"}
{"id":402,"text":"> In this work, we propose an alternative to the cross entropy loss function that can be used as a proxy for optimizing the Intersection over Union (IoU) metric between two sets. We show how our proposed loss function, which we call the Lovasz Softmax Loss, has several advantages compared with other alternatives such as the Dice coefficient and the Jaccard index. Firstly, it allows us to use standard backpropagation techniques during training. Secondly, its gradient is continuous everywhere except at zero IoU values where it is undefined. Thirdly, it is differentiable even when there are no true positives or false negatives present in the data. Finally, it is more robust than the Dice coefficient against imbalanced classes. Our experiments on semantic segmentation tasks demonstrate that using the Lovasz Softmax Loss leads to better results than the Dice coefficient and the Jaccard index.","label":"ai"}
{"id":403,"text":"A large number of problems in computer vision can be modelled as energy\nminimization problems in a Markov Random Field (MRF) or Conditional Random\nField (CRF) framework. Graph-cuts based $\\alpha$-expansion is a standard\nmove-making method to minimize the energy functions with sub-modular pairwise\nterms. However, certain problems require more complex pairwise terms where the\n$\\alpha$-expansion method is generally not applicable. In this paper, we propose an iterative {\\em tiered move making algorithm}\nwhich is able to handle general pairwise terms. Each move to the next\nconfiguration is based on the current labeling and an optimal tiered move,\nwhere each tiered move requires one application of the dynamic programming\nbased tiered labeling method introduced in Felzenszwalb et. al. \\cite{tiered_cvpr_felzenszwalbV10}. The algorithm converges to a local minimum\nfor any general pairwise potential, and we give a theoretical analysis of the\nproperties of the algorithm, characterizing the situations in which we can\nexpect good performance. We first evaluate our method on an object-class\nsegmentation problem using the Pascal VOC-11 segmentation dataset where we\nlearn general pairwise terms. Further we evaluate the algorithm on many other\nbenchmark labeling problems such as stereo, image segmentation, image stitching\nand image denoising. Our method consistently gets better accuracy and energy\nvalues than alpha-expansion, loopy belief propagation (LBP), quadratic\npseudo-boolean optimization (QPBO), and is competitive with TRWS.","label":"human"}
{"id":404,"text":"The study of lineage structures in biological systems has been a topic of interest for decades. In this paper, we explore the concept of tractability in treelike instances, which are graphs that can be represented as trees with edges labeled by weights or attributes. We show that certain types of lineage structures can be efficiently computed using dynamic programming algorithms, even when the graph is very large. Specifically, we prove that the minimum spanning tree problem (MST) can be solved in polynomial time for weighted trees with bounded degree, and that the maximum flow problem can be solved in linear time for directed acyclic graphs (DAGs). We also extend these results to more general classes of graphs, including those with negative edge weights or non-tree topologies. For example, we show that the MST problem can be approximated within a factor of 2 for any connected graph, and that the maximum flow problem can be solved in polynomial time for DAGs with bounded outdegree. Our work provides new insights into the computational complexity of lineage problems and opens up avenues for further research in this area.","label":"ai"}
{"id":405,"text":"ArXiv, by Matteo De Stefano et al., which I'm posting here as background information and to make it easier for search engines and researchers to find. - DF\n## Abstract\nThis work proposes an open framework to address the challenging task of accelerating time consuming simulations on large scale heterogeneous porous media at reduced order level via suitable model order reduction techniques (MOR). In particular the proposed MOR approach combines well suited global discretizations with appropriate data based local methods. Based on our extensive numerical analysis we will show that this integrated method is capable of producing high fidelity approximations that are close to the original simulation in a meaningful way together with significant computational time savings, such that non intrusive approaches like the dynamic mode decomposition become possible. We also give preliminary results about our experimental implementation developed inside the OpenGeomSys environment.","label":"ai"}
{"id":406,"text":"> In this work, we present an algorithm to evaluate ballast degradation using machine vision techniques. We use Matlab as our programming language and implement the algorithms in it. Our methodology involves taking images of the railroad tracks with a camera mounted on a moving vehicle. These images are then processed by the computer program which detects the presence of ballast stones and calculates their size distribution. This information can be used to determine if there has been any significant change in the condition of the track since its last inspection.","label":"ai"}
{"id":407,"text":"We develop a system for measurements of power spectra of transmitted light\nintensity fluctuations, in which the extraneous noise, including shot noise, is\nreduced. In essence, we just apply light, measure the power of the transmitted\nlight and derive its power spectrum. We use this to observe the spontaneous\nnoise spectra of photon atom interactions. Applying light with frequency\nmodulation, we can also observe the spontaneous noise reflecting the coherence\nbetween the hyperfine levels in the excited state. There are two in novel\ncomponents in the measurement system, the noise reduction scheme and the\nstabilization of the laser system. The noise reduction mechanism can be used to\nreduce the shot noise contribution to arbitrarily low levels through averaging,\nin principle. This is combined with differential detection to keep unwanted\nnoise at low levels. The laser system is stabilized to obtain spectral width\nbelow 1\\,kHz without high frequency ($\\gtrsim10\\,$MHz) noise. These methods are\ndescribed systematically and the performance of the asurement system is\nexamined through experimental results.","label":"human"}
{"id":408,"text":"In this announcement we consider the following problem. Let $n,m\\geq 1$,\n$U\\subset\\mathbb R^n$ open. In this paper we provide a sharp solution to the\nfollowing Whitney distortion extension problems: (a) Let $\\phi:U\\to \\mathbb\nR^n$ be a $C^m$ map. If $E\\subset U$ is compact (with some geometry) and the\nrestriction of $\\phi$ to $E$ is an almost isometry with small distortion, how\nto decide when there exists a $C^m(\\mathbb R^n)$ one-to-one and onto almost\nisometry $\\Phi:\\mathbb R^n\\to \\mathbb R^n$ with small distortion which agrees\nwith $\\phi$ in a neighborhood of $E$ and a Euclidean motion $A:\\mathbb R^n\\to\nmap. If $E\\subset U$ is compact (with some geometry) and the restriction of\n$\\phi$ to $E$ is an almost isometry with small distortion, how to decide when\nthere exists a $C^{\\infty}(\\mathbb R^n)$ one-to-one and onto almost isometry\n$\\Phi:\\mathbb R^n\\to \\mathbb R^n$ with small distortion which agrees with\n$\\phi$ in a neighborhood of $E$ and a Euclidean motion $A:\\mathbb R^n\\to\nthere, $E$ is a finite set. In this case, the problem above is also a problem\nof interpolation and alignment of data in $\\mathbb R^n$.","label":"human"}
{"id":409,"text":"Coupled Tank system used for liquid level control is a model of plant that\nhas usually been used in industries especially chemical process industries. Level control is also very important for mixing reactant process. This survey\npaper tries to presents in a systemic way an approach predictive control\nstrategy for a system that is similar to the process and is represented by two\nliquid tanks. This system of coupled Tank is one of the most commonly available\nsystems representing a coupled Multiple Input Multiple Output (MIMO) system. With 2 inputs and 2 outputs, it is the most primitive form of a coupled\nmultivariable system. Therefor the basic concept of how the coupled tanks\nsystem works is by using a numerical system which it operates with a flow\ncontrol valve FCV as main control of the level of liquid in one tank or both\ntanks. For this paper, MPC algorithm control is used which will be developed\nbelow. And it is focuses on the design and modelling for coupled tanks system. The steps followed for the design of the controller are: Developing a state\nspace system model for the coupled tank system then design an MPC controller\nfor the developed system model. And study the effect of the disturbance on\nmeasured level output. Note that the implementation Model Predictive Controller\non flow controller valve in a Coupled Tank liquid level system is one of the\nnew methods of controlling liquid level.","label":"human"}
{"id":410,"text":"Tensor networks are efficient factorisations of high dimensional tensors into\na network of lower order tensors. They have been most commonly used to model\nentanglement in quantum many-body systems and more recently are witnessing\nincreased applications in supervised machine learning. In this work, we\nformulate image segmentation in a supervised setting with tensor networks. The\nkey idea is to first lift the pixels in image patches to exponentially high\ndimensional feature spaces and using a linear decision hyper-plane to classify\nthe input pixels into foreground and background classes. The high dimensional\nlinear model itself is approximated using the matrix product state (MPS) tensor\nnetwork. The MPS is weight-shared between the non-overlapping image patches\nresulting in our strided tensor network model. The performance of the proposed\nmodel is evaluated on three 2D- and one 3D- biomedical imaging datasets. The\nperformance of the proposed tensor network segmentation model is compared with\nrelevant baseline methods. In the 2D experiments, the tensor network model\nyeilds competitive performance compared to the baseline methods while being\nmore resource efficient.","label":"human"}
{"id":411,"text":"In this paper, we propose a novel method for instrument segmentation in robotic surgery using unsupervised learning and cycle-consistent adversarial networks (CCANs). Our approach does not require labeled data, which is often limited in surgical settings, and relies on the cycle consistency loss to enforce self-consistency in the generated images. We evaluate our method on the publicly available Segmentation Challenge II (SC-II) dataset and show comparable performance to state-of-the-art supervised methods. Our approach also provides visualizations that reveal the features learned by the network, which can aid in better understanding the underlying representations of the data. Overall, our work has the potential to significantly improve the efficiency and accuracy of robotic surgery by enabling reliable instrument segmentation without the need for extensive labeled data.","label":"ai"}
{"id":412,"text":"<p>This paper revisits the widely--used <a href=\"https:\/\/courses.edx.org\/courses\/1574263d80db492faebb94e97feb7ff3\" title='Norbert Wiener' rel= 'biography'> Norbert Wiener <\/a>(1949) LMS adaptive filter using a Bayes--optimal prediction framework developed from information theory principles introduced by Tse and Gastpar (2006). Following their general approach, we first formulate a Bayesian source model, identify sufficient statistics that define it conditional probability density function, and evaluate analytically expressions of some key quantities as means to compute predictors recursively in a feedback scheme. Next, assuming that additive disturbance noise, also conditionally Gaussian, has variance proportional to previous inputs powers, derivations then lead naturally at defining an optimal nonlinear scalar gain as being constant but dependent on filter input sequence power history. Deriving optimal adaptation mechanisms, finally leads to propose a natural NLMS version of the conventional LMS algorithms differing thereafter mainly from it in its parameter learning behavior. This allows us showing, moreover, through an extensive Monte Carlo simulation analysis, how this specific novel NLMS can be efficiently used either offline or online in comparison with classic LMS counterparts both from a convergence speed point of view and when considering real world channel responses as well.<\/p><br\/>\nIn addition it appears clear that the proposed technique may open new perspectives and inspire further analyses beyond standard optimization criteria often investigated thus far, so leading, e.g., toward extensions concerning nonlinear processes where higher moments are involved. A potential application field could concern neural networks designs based upon backpropagation algorithms that try taking into account mean square error, yet still not capturing important features which the herein elaborated theoretical formalism might provide.<br\/>","label":"ai"}
{"id":413,"text":"The purpose of this study was to investigate the magnetotransport properties\nmagnetization measurements indicated that the compound is a spin-glass-like\ndiluted magnetic semiconductor with critical temperature TSG = 97.5 K.\nNanoclusters in the sample are observed. Both, matrix and clusters are\nmagnetically active. Resistivity as a function of temperature has a minimum at\n30 K. Below the minimum a variable-range hopping is observed, while above the\nminimum a metallic-like behavior occurs. The crystal has high hole\nconcentration, p = 6.6E20 cm-3, temperature-independent. Magnetoresistance\namplitude changes from -0.78 to 1.18% with increase of temperature. In the\nmagnetotransport measurements we observed the anomalous Hall effect (AHE) with\nhysteresis loops. Calculated AHE coefficient, RS = 2.0E6 m3\/C, is temperature\nindependent. The analysis indicates the extrinsic skew scattering mechanism to\nbe the main physical mechanism responsible for AHE in","label":"human"}
{"id":414,"text":"This research proposes a deep learning-based approach to segment earth images using imperfect polyline labels. The method is designed to handle annotated errors in labeling, including missing and incorrect segments or curves. Moreover, we introduce a novel error-handling technique that leverages deep neural networks to detect inconsistencies between polygons and reduce them when necessary. Experiments are conducted on two benchmark datasets for land cover classification and object identification tasks. Our model achieves state-of-the-art results and demonstrates its effectiveness even under noisy annotations.","label":"ai"}
{"id":415,"text":"We propose a method for efficiently finding all parallel passages in a large\ncorpus, even if the passages are not quite identical due to rephrasing and\northographic variation. The key ideas are the representation of each word in\nthe corpus by its two most infrequent letters, finding matched pairs of strings\nof four or five words that differ by at most one word and then identifying\nclusters of such matched pairs. Using this method, over 4600 parallel pairs of\npassages were identified in the Babylonian Talmud, a Hebrew-Aramaic corpus of\nover 1.8 million words, in just over 30 seconds. Empirical comparisons on\nsample data indicate that the coverage obtained by our method is essentially\nthe same as that obtained using slow exhaustive methods.","label":"human"}
{"id":416,"text":"It has been widely recognized that the success of deep learning in image\nsegmentation relies overwhelmingly on a myriad amount of densely annotated\ntraining data, which, however, are difficult to obtain due to the tremendous\nlabor and expertise required, particularly for annotating 3D medical images. Although self-supervised learning (SSL) has shown great potential to address\nthis issue, most SSL approaches focus only on image-level global consistency,\nbut ignore the local consistency which plays a pivotal role in capturing\nstructural information for dense prediction tasks such as segmentation. In this\npaper, we propose a PriorGuided Local (PGL) self-supervised model that learns\nthe region-wise local consistency in the latent feature space. Specifically, we\nuse the spatial transformations, which produce different augmented views of the\nsame image, as a prior to deduce the location relation between two views, which\nis then used to align the feature maps of the same local region but being\nextracted on two views. Next, we construct a local consistency loss to minimize\nthe voxel-wise discrepancy between the aligned feature maps. Thus, our PGL\nmodel learns the distinctive representations of local regions, and hence is\nable to retain structural information. This ability is conducive to downstream\nsegmentation tasks. We conducted an extensive evaluation on four public\ncomputerized tomography (CT) datasets that cover 11 kinds of major human organs\nand two tumors. The results indicate that using pre-trained PGL model to\ninitialize a downstream network leads to a substantial performance improvement\nover both random initialization and the initialization with global\nconsistency-based models. Code and pre-trained weights will be made available","label":"human"}
{"id":417,"text":"## VICE: Visual Identification and Correction of Neural Circuit Errors\nAuthors: Sung Hyun Park, Xiaoran Li, Kavita Shah, Mark P. Richards, Rene Vidal\nResilience is a critical feature for a complex system, such as neural networks, which should continue to function even after some of its elements have failed or are not functioning properly. In this research, we study circuit reconstructions from images, where we aim to identify and correct errors in neural circuits, to improve overall function, rather than rebuilding from scratch. We employ a graphical model based learning framework which leverages supervised and unsupervised learning to identify errors in circuits, based on training data. To show its efficacy, we employ this framework to simulated experiments to identify, localize, and reconstruct the visual cortical circuits in mice. The algorithm allows us to localize the errors in receptive fields and make correction on the connectivities, based on the training data. Published under CC BY 4.0\n## Introduction\nNeural systems are extremely complex biological structures. Thus, there exists a high probability that there are abnormalities in them. For example, neurons in mouse retina have synaptic pathologies after long periods of chronic glutamate receptor overactivity (Grimes et al. 1998). This has lead to many studies of neural reconstruction of damaged neurons in order to understand what happens during pathophysiology and to provide information for therapeutic interventions. In this paper, we will study the structure and function of the visual cortical circuits in mice. Neural circuit reconstructions are based in structural and functional relationships between neurons in the brain. We study these issues through an approach which integrates multi-scale models of neural morphologies derived from experimental data which characterizes the properties of different brain regions. We will study visual neural circuit reconstruction and identify neural circuit errors in visual cortical circuits in mice. The motivation of reconstructing neural circuits comes from the need of rebuilding lost or damaged neural circuits in order to restore function, and, ultimately, the capacity","label":"ai"}
{"id":418,"text":"The stability and equilibrium analysis of laneless traffic with local control laws will be discussed in this paper. In such a system, vehicles move without any guidance provided by road signs or lanes, but instead rely on local communication between them to navigate. This is achieved through the use of sensors that detect proximity between vehicles and send signals to steer clear when necessary. The research focuses on developing a model to analyze the behavior of an arbitrarily large number of independent vehicles in uncoordinated motion, using local sensing information to avoid collisions. The mathematical equations governing these interactions are derived based on vehicle dynamics and sensor data, producing a set of coupled differential equations that describe the trajectories of all vehicles in the system. The equations are solved numerically to study the stability of the solution space and identify the equilibrium points of the system. Numerical simulations reveal that under certain conditions, even small amounts of noise can destabilize the entire system, resulting in chaotic behavior and collisions. On the other hand, carefully designed algorithms that regulate the movement of individual vehicles towards specific paths allow for smooth transitions between initial and final states, achieving global optimum solutions with minimal disruption to the overall flow of traffic. The findings have implications for the design of future autonomous driving systems and may also inform strategies for reducing congestion and accidents in conventional urban transportation networks.","label":"ai"}
{"id":419,"text":"Cardiac magnetic resonance (CMR) imaging is a valuable tool for diagnosing and monitoring cardiovascular diseases. However, the interpretation of CMR images can be challenging due to the complex anatomy of the heart and the presence of artifacts. In this paper, we propose a novel self-supervised learning approach for cardiac MR image segmentation using anatomical position prediction. Our method learns to predict the anatomical position of a voxel based on its surrounding voxels, without requiring any manual annotations or external supervision. We evaluate our method on a large dataset of CMR images and demonstrate that it achieves state-of-the-art performance on the task of cardiac MR image segmentation. Our approach has the potential to improve the efficiency and accuracy of CMR image analysis, and could be applied to other medical imaging modalities as well.","label":"ai"}
{"id":420,"text":"This paper describes a computational model, called the Dirichlet process\nGaussian mixture model with latent joints (DPGMM-LJ), that can find latent tree\nstructure embedded in data distribution in an unsupervised manner. By combining\nDPGMM-LJ and a pre-existing body map formation method, we propose a method that\nenables an agent having multi-link body structure to discover its kinematic\nstructure, i.e., body schema, from tactile information alone. The DPGMM-LJ is a\nprobabilistic model based on Bayesian nonparametrics and an extension of\nDirichlet process Gaussian mixture model (DPGMM). In a simulation experiment,\nwe used a simple fetus model that had five body parts and performed structured\nrandom movements in a womb-like environment. It was shown that the method could\nestimate the number of body parts and kinematic structures without any\npre-existing knowledge in many cases. Another experiment showed that the degree\nof motor coordination in random movements affects the result of body schema\nformation strongly. It is confirmed that the accuracy rate for body schema\nestimation had the highest value 84.6% when the ratio of motor coordination was\n0.9 in our setting. These results suggest that kinematic structure can be\nestimated from tactile information obtained by a fetus moving randomly in a\nwomb without any visual information even though its accuracy was not so high. They also suggest that a certain degree of motor coordination in random\nmovements and the sufficient dimension of state space that represents the body\nmap are important to estimate body schema correctly.","label":"human"}
{"id":421,"text":"> Abstract: Digital image clustering analysis has been one of the most crucial researches to help in disease diagnosis, gene expression profiling, remote sensing and so forth applications. However, accurate unsupervised digital image pixel clustering that includes high classification accuracy and fast running time is still challenging [1]. In general, digital images are classified into certain number of clusters including RGB, YCbCr or HSV color space using different types of distance measurement methods, such as Euclidean, Manhattan and Mahalanobis Distances. This can be seen in works by Kaufman and Rousseeuw (K-means) [2], Jain et al. (PAM and CLARANS) [3] or Dunn's method with its several variants (Fuzzy C - Means (FCM)) [4], Lahiri and Bandyopadhyay (FCMR-ELT) [5], etc. To overcome slow performance and low convergence rate especially when dealing large data sets which exist nowadays, various evolutionary algorithms have started being used as an alternative approach. One example could be Genetic Algorithm (GA) proposed by Hart et al. [6], while another examples are Evolution Strategy (ES) proposed by Back and Schwefel [7], Differential Evolution (DE) presented by Storn and Price [8], Particle Swarm Optimization (PSO) implemented by Kanungo et al. [9], Artificial Bee Colony (ABC), Bees Aloiteration (BEA) algorithm developed by Karaboga and Aksoy [10], Shuffled Frog Leaping algorithm designed by Eusuff and Lansey [11], Wolf Pack Search algorithm introduced by Rahnamai-Jenkarandeh et al. [12], Grasshopper Optimizer (GO) generated by Yang and Deb [13], Imperialist Competitive algorithm invented by Atashpaz-Gargari and Lucas [14], Big Bang Big Crunch (BBBC) given by Gandomi and Zunino [15], Quantum-behaved Particle Swarm with Entanglement (Q","label":"ai"}
{"id":422,"text":"Activity of modern scholarship creates online footprints galore. Along with\ntraditional metrics of research quality, such as citation counts, online images\nof researchers and institutions increasingly matter in evaluating academic\nimpact, decisions about grant allocation, and promotion. We examined 400\nbiographical Wikipedia articles on academics from four scientific fields to\ntest if being featured in the world's largest online encyclopedia is correlated\nwith higher academic notability (assessed through citation counts). We found no\nstatistically significant correlation between Wikipedia articles metrics\n(length, number of edits, number of incoming links from other articles, etc.) and academic notability of the mentioned researchers. We also did not find any\nevidence that the scientists with better WP representation are necessarily more\nprominent in their fields. In addition, we inspected the Wikipedia coverage of\nnotable scientists sampled from Thomson Reuters list of \"highly cited\nresearchers\". In each of the examined fields, Wikipedia failed in covering\nnotable scholars properly. Both findings imply that Wikipedia might be\nproducing an inaccurate image of academics on the front end of science. By\nshedding light on how public perception of academic progress is formed, this\nstudy alerts that a subjective element might have been introduced into the\nhitherto structured system of academic evaluation.","label":"human"}
{"id":423,"text":"We employ Monte Carlo simulations in order to study dynamics of the\nmagnetization and domain growth processes in the random-field Ising models with\nuniform and Gaussian random field distributions of varying strengths. Domain\nsizes are determined directly using the Hoshen-Kopelman algorithm. For either\ncase, both the magnetization and the largest domain growth dynamics are found\nto follow the power law with generally different exponents, which exponentially\ndecay with the random field strength. Moreover, for relatively small random\nfields the relaxation is confirmed to comply with different regimes at early\nand later times. No significant differences were found between the results for\nthe uniform and Gaussian distributions, in accordance with the universality\nassumption.","label":"human"}
{"id":424,"text":"In this paper, we investigate an initial-boundary value problem for a\nchemotaxis-fluid system in a general bounded regular domain $\\Omega \\subset\nelementary lemma given by Mizoguchi & Souplet [10], we can derive a new type of\nentropy-energy estimate, which enables us to prove the following: (1) for\n$N=2$, there exists a unique global classical solution to the full\nchemotaxis-Navier-Stokes system, which converges to a constant steady state\nglobal weak solution to the simplified chemotaxis-Stokes system. Our results\ngeneralize the recent work due to Winkler [15,16], in which the domain $\\Omega$\nis essentially assumed to be convex.","label":"human"}
{"id":425,"text":"> We present a novel approach to multi-object segmentation that combines the advantages of gradient vector flow (GVF) based segmentation with the ability to incorporate shape priors. The proposed method is based on a novel formulation of the GVF flow that allows for the incorporation of shape priors. The shape priors are represented by a set of points that are mapped to the image domain using a non-rigid registration algorithm. The proposed method is evaluated on a variety of datasets and is shown to outperform state-of-the-art methods in terms of both accuracy and efficiency. The paper is available here.","label":"ai"}
{"id":426,"text":"> The segmentation performance of deep neural networks (DNNs) relies heavily on the quality of annotation in medical images. This is true especially for computer-assisted surgeries where the annotation is provided by the medical expert during the surgery. It is known that the quality of the annotation may vary between different experts and their level of accuracy may vary from 80% to 98%. This variability has a considerable effect on DNNs performance, especially when the annotations are not dense. Therefore, annotation is one of the most important factors that affects the performance of DNNs for medical image segmentation significantly. We propose to develop a spatial guided self-supervised clustering algorithm where unsupervised clustering is guided by the spatial distance between voxels inside the image or volume using graph and matrix approaches. The objective of unsupervised algorithms is to find segments (i.e., voxels with similar intensity value) while the objective of using graph or\/and matrix approach is to preserve topological relationship between adjacent voxels within (or without) a segment. This combination provides very accurate segmentation of the 3D images\/volumes since it preserves both intensity and spatial information of the input image. Our approach works with the segmentation mask as well as the image data. If a mask is available, the algorithm will use it as the true label and the model will be trained to reduce the loss function. If the mask is not available, we use the deep feature learning step as a preprocessing step to find the cluster center for each group of voxels and the model will be trained to reduce the clustering loss function. Submitted to arxiv.org on 2021-07-21 by 1 author, including the full text of the research paper that has been edited and approved by editors. The abstract has not been accepted yet. The comments posted on arxiv.org on this page are not official publication comments. ## arxiv.org has 2 other abstracts with the same full-text:","label":"ai"}
{"id":427,"text":"Cluster states can be used to perform measurement-based quantum computation. The cluster state is a useful resource, because once it has been generated only\nlocal operations and measurements are needed to perform universal quantum\ncomputation. In this paper, we explore techniques for quickly and\ndeterministically building a cluster state. In particular we consider\ngenerating cluster states on a qubus quantum computer, a computational\narchitecture which uses a continuous variable ancilla to generate interactions\nbetween qubits. We explore several techniques for building the cluster, with\nthe number of operations required depending on whether we allow the ability to\ndestroy previously created controlled-phase links between qubits. In the case\nwhere we can not destroy these links, we show how to create an n x m cluster\nusing just 3nm -2n -3m\/2 + 3 operations. This gives more than a factor of 2\nsaving over a naive method. Further savings can be obtained if we include the\nability to destroy links, in which case we only need (8nm-4n-4m-8)\/3\noperations. Unfortunately the latter scheme is more complicated so choosing the\ncorrect order to interact the qubits is considerably more difficult. A half way\nscheme, that keeps a modular generation but saves additional operations over\nnever destroying links requires only 3nm-2n-2m+4 operations. The first scheme\nand the last scheme are the most practical for building a cluster state because\nthey split up the generation into the repetition of simple sections.","label":"human"}
{"id":428,"text":"We present approaches for the study of fluid-structure interactions subject\nto thermal fluctuations. A mixed mechanical description is utilized combining\nEulerian and Lagrangian reference frames. We establish general conditions for\noperators coupling these descriptions. Stochastic driving fields for the\nformalism are derived using principles from statistical mechanics. The\nstochastic differential equations of the formalism are found to exhibit\nsignificant stiffness in some physical regimes. To cope with this issue, we\nderive reduced stochastic differential equations for several physical regimes. We also present stochastic numerical methods for each regime to approximate the\nfluid-structure dynamics and to generate efficiently the required stochastic\ndriving fields. To validate the methodology in each regime, we perform analysis\nof the invariant probability distribution of the stochastic dynamics of the\nfluid-structure formalism. We compare this analysis with results from\nstatistical mechanics. To further demonstrate the applicability of the\nmethodology, we perform computational studies for spherical particles having\ntranslational and rotational degrees of freedom. We compare these studies with\nresults from fluid mechanics. The presented approach provides for\nfluid-structure systems a set of rather general computational methods for\ntreating consistently structure mechanics, hydrodynamic coupling, and thermal\nfluctuations.","label":"human"}
{"id":429,"text":"Interior object detection refers to the process of identifying objects within an interior space, such as furniture or decorative items. This is a challenging task due to the complexities involved in detecting objects against cluttered backgrounds and dealing with variations in lighting conditions. In this paper, we propose a novel approach to interior object detection that combines deep learning techniques with color harmonization methods. Our method involves training a convolutional neural network (CNN) on a large dataset of labeled images, followed by applying color harmonization algorithms to enhance the contrast between foreground and background objects. We evaluate our method on several benchmark datasets and demonstrate significant improvements over state-of-the-art approaches in terms of accuracy and robustness. Overall, our work represents a major advancement in the field of interior object detection and has important implications for applications in areas such as robotics, augmented reality, and smart homes.","label":"ai"}
{"id":430,"text":"Interactive binary image segmentation with edge preservation is a novel approach to image segmentation that allows users to interactively refine the segmentation results. The method uses a combination of edge detection and thresholding techniques to identify the edges in the image, and then uses these edges to refine the segmentation results. The user can interactively adjust the threshold value to control the level of edge preservation, and the method can be applied to a wide range of image types. The results of the method have been compared to other state-of-the-art methods, and have shown to be highly accurate and effective. Overall, this method provides a powerful tool for image segmentation that is both user-friendly and highly accurate.","label":"ai"}
{"id":431,"text":"The objective of this study is to develop a novel method for gastric tumor segmentation using partial labeled data. We propose a patch-based reiterative learning approach that iteratively refines the initial segmentation results by incorporating new patches and updating the model parameters. Our approach utilizes a combination of convolutional neural networks (CNNs) and graph-based methods, which enables us to handle complex tissue structures and irregularly shaped tumors. We evaluate our proposed method on a dataset of 105 endoscopic images with varying degrees of labeling and demonstrate significant improvements in accuracy compared to state-of-the-art methods. Our findings suggest that our approach can effectively leverage limited labeled data to achieve high performance in gastric tumor segmentation tasks.","label":"ai"}
{"id":432,"text":"We consider Bloch oscillations of ultracold atoms stored in a one-dimensional\nvertical optical lattice and simultaneously interacting with a unidirectionally\npumped optical ring cavity whose vertical arm is collinear with the optical\nlattice. We find that the feedback provided by the cavity field on the atomic\nmotion synchronizes Bloch oscillations via a mode-locking mechanism, steering\nthe atoms to the lowest Bloch band. It also stabilizes Bloch oscillations\nagainst noise, and even suppresses dephasing due to atom-atom interactions. Furthermore, it generates periodic bursts of light emitted into the\ncounter-propagating cavity mode, providing a non-destructive monitor of the\natomic dynamics. All these features may be crucial for future improvements of\nthe design of atomic gravimeters based on recording Bloch oscillations.","label":"human"}
{"id":433,"text":"Surgical tool segmentation in endoscopic images is an important problem: it\nis a crucial step towards full instrument pose estimation and it is used for\nintegration of pre- and intra-operative images into the endoscopic view. While\nmany recent approaches based on convolutional neural networks have shown great\nresults, a key barrier to progress lies in the acquisition of a large number of\nmanually-annotated images which is necessary for an algorithm to generalize and\nwork well in diverse surgical scenarios. Unlike the surgical image data itself,\nannotations are difficult to acquire and may be of variable quality. On the\nother hand, synthetic annotations can be automatically generated by using\nforward kinematic model of the robot and CAD models of tools by projecting them\nonto an image plane. Unfortunately, this model is very inaccurate and cannot be\nused for supervised learning of image segmentation models. Since generated\nannotations will not directly correspond to endoscopic images due to errors, we\nformulate the problem as an unpaired image-to-image translation where the goal\nis to learn the mapping between an input endoscopic image and a corresponding\nannotation using an adversarial model. Our approach allows to train image\nsegmentation models without the need to acquire expensive annotations and can\npotentially exploit large unlabeled endoscopic image collection outside the\nannotated distributions of image\/annotation data. We test our proposed method\non Endovis 2017 challenge dataset and show that it is competitive with\nsupervised segmentation methods.","label":"human"}
{"id":434,"text":"> Histopathological tumor segmentation in WSIs has been recently tackled by deep learning approaches that need high-resolution image sets with manually annotated regions to perform well, resulting in expensive labeling costs and manual human intervention. Previous work in this domain uses fully or semi - supervised methods to tackle the problem by generating synthetic tissue stains and realistic background images, which have a very poor generalization performance due to their lack of variety compared to real histological samples. To address these limitations we present ConDeep, our proposed constrained deep weakly-supervized approach: first it exploits unlabeled large scale raw digital slides (WSIs) via pixel level class activation maps obtained by pretrained models, then converts them into hard ground truth masks through a simple voting strategy over patches extracted with different spatial scales where most of the information resides. In addition, the technique learns some additional features from those data such as intensity distributions and spatial correlations based on natural gradient computation [Shwartz et al 2017]. Finally these features are used together with handcrafted ones during training stage. Our method achieves state-of-the art results when tested against benchmark datasets (ISBI dataset for gastric cancer [Masutani et al 2018], IMCB2019 dataset for breast cancer).","label":"ai"}
{"id":435,"text":"Deep LOGISMOS is a novel deep learning-based method for 3D segmentation of pancreatic tumors on CT scans. The proposed method utilizes a graph-based approach to represent the spatial relationships between voxels in the 3D image, and a deep neural network to learn the segmentation task. The graph-based representation allows the model to capture complex spatial patterns and hierarchical relationships between voxels, which are important for accurate segmentation of pancreatic tumors. The deep neural network is trained using a combination of supervised and unsupervised learning techniques, which allows the model to learn both local and global patterns in the image. The proposed method has been evaluated on a large dataset of CT scans, and has shown state-of-the-art performance compared to other deep learning-based methods for pancreatic tumor segmentation.","label":"ai"}
{"id":436,"text":"Computing problems that handle large amounts of data necessitate the use of\nlossless data compression for efficient storage and transmission. We present a\nnovel lossless universal data compression algorithm that uses parallel\ncomputational units to increase the throughput. The length-$N$ input sequence\nis partitioned into $B$ blocks. Processing each block independently of the\nother blocks can accelerate the computation by a factor of $B$, but degrades\nthe compression quality. Instead, our approach is to first estimate the minimum\ndescription length (MDL) context tree source underlying the entire input, and\nthen encode each of the $B$ blocks in parallel based on the MDL source. With\nthis two-pass approach, the compression loss incurred by using more parallel\nunits is insignificant. Our algorithm is work-efficient, i.e., its\ncomputational complexity is $O(N\/B)$. Its redundancy is approximately\n$B\\log(N\/B)$ bits above Rissanen's lower bound on universal compression\nperformance, with respect to any context tree source whose maximal depth is at\nmost $\\log(N\/B)$. We improve the compression by using different quantizers for\nstates of the context tree based on the number of symbols corresponding to\nthose states. Numerical results from a prototype implementation suggest that\nour algorithm offers a better trade-off between compression and throughput than\ncompeting universal data compression algorithms.","label":"human"}
{"id":437,"text":"Weakly supervised segmentation is a challenging task in computer vision, where only limited labeled data is available. In this work, we propose a novel approach to weakly supervised image segmentation using deep geodesic prior. Our method leverages the inherent structure of images and learns an embedding space that captures the spatial relationships between pixels. By training a deep neural network on this embedded space, we can achieve accurate segmentation results with minimal labeled data. Our experiments demonstrate the effectiveness of our proposed method on several benchmark datasets, outperforming state-of-the-art methods in many cases.","label":"ai"}
{"id":438,"text":"Inner and inter-label propagation are two essential methods for salient object detection in complex scenes. In this paper, we present a novel approach that combines inner and inter-label propagation to improve the accuracy of salient object detection. Our approach involves two main steps. First, we use inner label propagation to refine the initial predictions generated by a salient object detector. Second, we use inter-label propagation to improve the accuracy of the predictions made by the inner label propagation. Our experiments show that our approach significantly improves the accuracy of salient object detection in complex scenes. Furthermore, our approach is computationally efficient, making it suitable for real-time applications.","label":"ai"}
{"id":439,"text":"In this study, we proposed a deep convolutional neural network approach to estimate exclusive probabilities of independent brain segmentation classes across multiple subjects. Our method was based on fully-convolutional dense networks (FCNs) and incorporated two novel components to enable learning spatiotemporal representations from multi-shot longitudinal studies. We applied our algorithm to isointensive infant brain Magnetic Resonance Imaging (MRI) segmentation tasks by utilizing independent labeling schemes. Results demonstrated that our method achieved state-of-the-art performance in terms of both accuracy and robustness. Specifically, we found significant improvements over baselines when handling rare intensities, which constituted up to 15% of the total images in our dataset. Our findings suggest that the use of independent probability estimation with FCNs can enhance the processing efficiency, reduce memory requirements and improve generalization capabilities compared to traditional conditional approaches. Overall, our work paves the way for future advancements in the development of automated multi-person longitudinal analysis pipelines for neuroimaging data.","label":"ai"}
{"id":440,"text":"> Accurate segmentation is necessary to facilitate numerous applications, such as quantification of diseases and tumor detection in medical imaging. Generative adversarial network (GAN) is one powerful deep learning algorithm that has been recently applied to achieve this goal. In order to improve the performance of GAN-based image segmentation methods more efficient ways to learn segmentation masks are proposed by fine tuning pre-trained models, often through transfer learning from other datasets. We propose an enhanced interactive segmentation model based on deep convolution and generative adversarial networks. This model uses data augmentation with random rotations at each iteration during training, while also incorporating the usage of fine-tuned weights that were trained specifically on the dataset that it's intended for. By utilizing these advanced techniques we provide high accuracy results both in terms of precision and recall of up to 96% and F1 score up to 0.84 across all three data sets tested without having any extra labeled images or needing further user input.","label":"ai"}
{"id":441,"text":"Single Image Super Resolution (SISR) techniques based on Super Resolution\nConvolutional Neural Networks (SRCNN) are applied to micro-computed tomography\n({\\mu}CT) images of sandstone and carbonate rocks. Digital rock imaging is\nlimited by the capability of the scanning device resulting in trade-offs\nbetween resolution and field of view, and super resolution methods tested in\nthis study aim to compensate for these limits. SRCNN models SR-Resnet, Enhanced\nDeep SR (EDSR), and Wide-Activation Deep SR (WDSR) are used on the Digital Rock\nSuper Resolution 1 (DRSRD1) Dataset of 4x downsampled images, comprising of\n2000 high resolution (800x800) raw micro-CT images of Bentheimer sandstone and\nEstaillades carbonate. The trained models are applied to the validation and\ntest data within the dataset and show a 3-5 dB rise in image quality compared\nto bicubic interpolation, with all tested models performing within a 0.1 dB\nrange. Difference maps indicate that edge sharpness is completely recovered in\nimages within the scope of the trained model, with only high frequency noise\nrelated detail loss. We find that aside from generation of high-resolution\nimages, a beneficial side effect of super resolution methods applied to\nsynthetically downgraded images is the removal of image noise while recovering\nedgewise sharpness which is beneficial for the segmentation process. The model\nis also tested against real low-resolution images of Bentheimer rock with image\naugmentation to account for natural noise and blur. The SRCNN method is shown\nto act as a preconditioner for image segmentation under these circumstances\nwhich naturally leads to further future development and training of models that\nsegment an image directly. Image restoration by SRCNN on the rock images is of\nsignificantly higher quality than traditional methods and suggests SRCNN\nmethods are a viable processing step in a digital rock workflow.","label":"human"}
{"id":442,"text":"In this paper, we propose spatial propagation networks for learning the\naffinity matrix for vision tasks. We show that by constructing a row\/column\nlinear propagation model, the spatially varying transformation matrix exactly\nconstitutes an affinity matrix that models dense, global pairwise relationships\nof an image. Specifically, we develop a three-way connection for the linear\npropagation model, which (a) formulates a sparse transformation matrix, where\nall elements can be the output from a deep CNN, but (b) results in a dense\naffinity matrix that effectively models any task-specific pairwise similarity\nmatrix. Instead of designing the similarity kernels according to image features\nof two points, we can directly output all the similarities in a purely\ndata-driven manner. The spatial propagation network is a generic framework that\ncan be applied to many affinity-related tasks, including but not limited to\nimage matting, segmentation and colorization, to name a few. Essentially, the\nmodel can learn semantically-aware affinity values for high-level vision tasks\ndue to the powerful learning capability of the deep neural network classifier. We validate the framework on the task of refinement for image segmentation\nboundaries. Experiments on the HELEN face parsing and PASCAL VOC-2012 semantic\nsegmentation tasks show that the spatial propagation network provides a\ngeneral, effective and efficient solution for generating high-quality\nsegmentation results.","label":"human"}
{"id":443,"text":"Fuzzy-Possibilistic (FP) clustering has been a popular clustering method that has been widely used to find clusters in fuzzy data sets. However, the results of FP clustering are highly dependent on the weight parameter u, which in turn depends on the data to be clustered. Moreover, it could be difficult to find the right value u for the given data. Several methods have been proposed to find a suitable u value, but those methods depend on the input data. In this paper, we propose a new validity index for FP clustering as a standard method for finding a suitable u value. We propose using a minimum mean correlation (MMC) and an average similarity index in our validity index. We compare the proposed method with those in previous studies, and we verify the validity of our method via numerical simulation and real data sets. Read the full text from arxiv.org","label":"ai"}
{"id":444,"text":"This paper presents a novel unsupervised segmentation method for 3D medical\nimages. Convolutional neural networks (CNNs) have brought significant advances\nin image segmentation. However, most of the recent methods rely on supervised\nlearning, which requires large amounts of manually annotated data. Thus, it is\nchallenging for these methods to cope with the growing amount of medical\nimages. This paper proposes a unified approach to unsupervised deep\nrepresentation learning and clustering for segmentation. Our proposed method\nconsists of two phases. In the first phase, we learn deep feature\nrepresentations of training patches from a target image using joint\nunsupervised learning (JULE) that alternately clusters representations\ngenerated by a CNN and updates the CNN parameters using cluster labels as\nsupervisory signals. We extend JULE to 3D medical images by utilizing 3D\nconvolutions throughout the CNN architecture. In the second phase, we apply\nk-means to the deep representations from the trained CNN and then project\ncluster labels to the target image in order to obtain the fully segmented\nimage. We evaluated our methods on three images of lung cancer specimens\nscanned with micro-computed tomography (micro-CT). The automatic segmentation\nof pathological regions in micro-CT could further contribute to the\npathological examination process. Hence, we aim to automatically divide each\nimage into the regions of invasive carcinoma, noninvasive carcinoma, and normal\ntissue. Our experiments show the potential abilities of unsupervised deep\nrepresentation learning for medical image segmentation.","label":"human"}
{"id":445,"text":"The paper investigates a mysterious cluster expansion associated with the expectation value of the permanent of 0-1 matrices. The authors show that the expansion can be expressed as a sum of terms involving the permanent of 0-1 matrices and the determinant of their complement. They also prove that the expansion is well-defined and convergent for any 0-1 matrix. The paper provides a new approach to the study of the permanent of 0-1 matrices and its properties, and has implications for the study of random matrices and statistical physics.","label":"ai"}
{"id":446,"text":"The field of computer vision has seen significant advancements in recent years, with deep learning techniques revolutionizing image processing and analysis. However, one major challenge remains: converting 2D images into 3D point clouds, which are essential for many applications such as robotics, augmented reality, and autonomous vehicles. In this paper, we propose a novel approach that addresses this challenge by using a single 2D image to instantiate a 3D point cloud. Our method is based on a one-stage convolutional neural network (CNN) architecture that directly maps an input image to a set of 3D points. We demonstrate our approach through extensive experiments on various benchmark datasets, achieving state-of-the-art performance compared to previous methods. Our work represents a significant step forward in the development of efficient and accurate algorithms for shape instantiation from 2D images to 3D point clouds.","label":"ai"}
{"id":447,"text":"While significant attention has been recently focused on designing supervised\ndeep semantic segmentation algorithms for vision tasks, there are many domains\nin which sufficient supervised pixel-level labels are difficult to obtain. In\nthis paper, we revisit the problem of purely unsupervised image segmentation\nand propose a novel deep architecture for this problem. We borrow recent ideas\nfrom supervised semantic segmentation methods, in particular by concatenating\ntwo fully convolutional networks together into an autoencoder--one for encoding\nand one for decoding. The encoding layer produces a k-way pixelwise prediction,\nand both the reconstruction error of the autoencoder as well as the normalized\ncut produced by the encoder are jointly minimized during training. When\ncombined with suitable postprocessing involving conditional random field\nsmoothing and hierarchical segmentation, our resulting algorithm achieves\nimpressive results on the benchmark Berkeley Segmentation Data Set,\noutperforming a number of competing methods.","label":"human"}
{"id":448,"text":"Fluorescence microscopy is a widely used technique in biology and medicine for visualizing cellular structures and processes. However, the accuracy of image segmentation, which is the process of separating objects from their background, can be affected by various factors such as missing markers, low signal-to-noise ratio, and variations in marker intensity. In this paper, we propose a deep learning-based approach for segmenting fluorescence microscopy images with missing markers. Our approach utilizes uncertainty estimation, which is a technique for quantifying the confidence of a model's predictions. Specifically, we use a variant of the DeepLab model, which is a state-of-the-art convolutional neural network for image segmentation, and incorporate uncertainty estimation by adding a confidence map to the output. We evaluate our approach on a dataset of fluorescence microscopy images with missing markers and show that our approach outperforms the standard DeepLab model in terms of both accuracy and robustness. Our results demonstrate the potential of uncertainty estimation for improving the performance of deep learning-based image segmentation in biology and medicine.","label":"ai"}
{"id":449,"text":"TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation\nAbstract:\nMedical image segmentation is a crucial task in the field of healthcare, with applications ranging from diagnosis to treatment planning. Convolutional Neural Networks (CNNs) have been the dominant architecture for this task, but recent advances in Transformers have shown promising results. In this paper, we propose TransFuse, a novel architecture that combines the strengths of both CNNs and Transformers for medical image segmentation. Our approach leverages the spatial localization of CNNs for feature extraction and the global context modeling of Transformers for contextual reasoning. We evaluate our method on several benchmark datasets and demonstrate state-of-the-art performance. Our findings suggest that TransFuse can effectively fuse the strengths of CNNs and Transformers for medical image segmentation, paving the way for future research in this area.","label":"ai"}
{"id":450,"text":"SkrGAN: Sketching-rendering Unconditional Generative Adversarial Networks for Medical Image Synthesis\nAbstract:\nMedical image synthesis is a challenging task, as it requires generating accurate and informative images that can be used for diagnoses, treatment planning, and other medical applications. In this paper, we present SkrGAN, a novel unconditional generative adversarial network (GAN) architecture for medical image synthesis. Unlike previous GAN architectures, which typically require conditional inputs, SkrGAN can generate images from scratch using sketching-rendering techniques. We use a combination of 1) a novel sketching-rendering encoder-decoder architecture and 2) a novel attention mechanism to align the inputs and outputs of the network. Our approach enables precise control over the output image, and results in high-quality images that closely resemble ground truth images. We demonstrate the effectiveness of SkrGAN on a variety of medical image tasks, including anatomical reconstruction, abnormality detection, and pathology classification.","label":"ai"}
{"id":451,"text":"The two-photon emission (TPE) or LPM effect is a phenomenon observed from relativistic heavy ion collisions where both virtual photons emitted by electrons in the medium are on the same side of each other, leading to energy transfer of order $\\frac{e^2}{c}$ between large scale system and small virtual charges. We investigate this effect based on its dependence on the momentum distribution and polarization of electron and thus have presented results from the study on TPE with energy transfer factors $(E_t=|{\\vec W}|\/\\gamma I\\varepsilon)$, which represent the change of total kinetic energies per unit solid angle. In addition, our theoretical framework allows us to relate the energy transfer factor $E_t$ to effective currents in the medium via Fourier transform relations. From this relationship we find that for certain scenarios, the effective current has different signs while $E_t$ does not show such variation. Finally, it should be noted that the $I \\varepsilon$-dependence of the energy transfer factor $E_t$, as well can also reflect the factorization limit if it is treated as an independent function of the electron energy and angle distributions. Therefore, further studies related to TPE phenomenology will require refinements beyond standard current density treatments while taking into account the detailed physics discussed here.","label":"ai"}
{"id":452,"text":"> It is a well-known principle that service-oriented computing platforms require high-level\n> specifications of services in order to implement a wide range of automation capabilities\n> such as discovery, composition, orchestration, and dynamic reconfiguration. Recently, a\n> family of new automata-based formalisms [1-7] has been developed which are tailored to the\n> characteristics of service-oriented computing, in particular their support for interoperability\n> and dynamicity. > In this paper, we provide a systematic comparison of the models based on automata\n> and their relationship with WSDL [8,9] and BPEL4WS (the most common technology for\n> orchestrating Web services today). We also describe a comprehensive set of automata-based\n> specifications, for a wide range of scenarios in service-oriented computing. The\n> specifications provide service descriptions at various levels of abstraction and are integrated\n> with the specification of non-functional properties.","label":"ai"}
{"id":453,"text":"Granular materials do not flow homogeneously like fluids when submitted to\nexternal stress,but often form rigid regions that are separated by narrow shear\nbands where the material yields and flows. This shear localization impacts\ntheir apparent rheology, which makes it difficult to infer a constitutive\nbehaviour from conventional rheometric measurements. Moreover, they present a\ndilatant behaviour, which makes their study in classical fixedvolume geometries\ndifficult. These features led to perform extensive studies with inclined plane\nflows, which were of crucial importance for the development and the validation\nof the $\\mu(I)$ rheology. Our aim is to develop a method to characterize\ngranular materials with rheometrical tools. Using unusual rheometry\nmeasurements in an annular shear cell adapted from Boyer et al. (2011), dense\ngranular flows are studied. A focus is placed on the comparison between the\npresent results and the $\\mu(I)$-rheology.","label":"human"}
{"id":454,"text":"> We study the determinant morphism for singular varieties. We show that the determinant morphism is a rational map, and that it is a morphism if and only if the variety is smooth. We also show that the determinant morphism is a morphism if and only if the variety is a complete intersection. The paper is available here. ### About the author\nJames T. Park is a PhD student in the Department of Mathematics at the University of California, Berkeley. He is interested in algebraic geometry, especially in the study of moduli spaces of vector bundles and sheaves.","label":"ai"}
{"id":455,"text":"Based on the similarity of paraxial diffraction and dispersion mathematical\ndescriptions, the temporal imaging of optical pulses combines linear dispersive\nfilters and quadratic phase modulations operating as time lenses. We consider\nprogramming a dispersive filter near atomic resonance in rare earth ion doped\ncrystals, which leads to unprecedented high values of dispersive power. This\nfilter is used in an approximate imaging scheme, combining a single time lens\nand a single dispersive section and operating as a time reversing device, with\npotential applications in radio-frequency signal processing. This scheme is\nclosely related to three-pulse photon echo with chirped pulses but the\nconnection with temporal imaging and dispersive filtering emphasizes new\nfeatures.","label":"human"}
{"id":456,"text":"Recent years have witnessed the great progress of deep neural networks on\nsemantic segmentation, particularly in medical imaging. Nevertheless, training\nhigh-performing models require large amounts of pixel-level ground truth masks,\nwhich can be prohibitive to obtain in the medical domain. Furthermore, training\nsuch models in a low-data regime highly increases the risk of overfitting. Recent attempts to alleviate the need for large annotated datasets have\ndeveloped training strategies under the few-shot learning paradigm, which\naddresses this shortcoming by learning a novel class from only a few labeled\nexamples. In this context, a segmentation model is trained on episodes, which\nrepresent different segmentation problems, each of them trained with a very\nsmall labeled dataset. In this work, we propose a novel few-shot learning\nframework for semantic segmentation, where unlabeled images are also made\navailable at each episode. To handle this new learning paradigm, we propose to\ninclude surrogate tasks that can leverage very powerful supervisory signals\n--derived from the data itself-- for semantic feature learning. We show that\nincluding unlabeled surrogate tasks in the episodic training leads to more\npowerful feature representations, which ultimately results in better\ngenerability to unseen tasks. We demonstrate the efficiency of our method in\nthe task of skin lesion segmentation in two publicly available datasets. Furthermore, our approach is general and model-agnostic, which can be combined\nwith different deep architectures.","label":"human"}
{"id":457,"text":"The paper defines implication relation for classical logic following\nthe approach used in the book [1] for intuitionistic provability relation,\nbut the main difference is that we have more than two formulas in a\nstructure. For this purpose we fix firstly a countable collection of propositional\nvariables axiomatically and assume a countable set of formulas to be\nthe set of all the sentences made up of these variables using the usual\npropositional operators and logical connectives. The set up is in line\nwith the one in the book [1], that is we take\n## Implicit definitions\nwhere each of the elements in $v_i$ is a variable, then the set of all sentences are denoted as:\nwhere $A_n$ is a sentence made up of some variables from $\\text{Var}$. The set of all formulas is defined to be:\nFor greater $n$'s, $\\bot$ is considered as the conjunction of the elements in $F_{n-1}$,\nThe definition of implication relation is taken from [1] on page 15 of the book:\nWe say that $A$ is an implication of $B$ under a formula $n$ and write\nif whenever we can prove the sentence $n$ whenever we can prove either the\nsentence $A$ or the sentence $B$,","label":"ai"}
{"id":458,"text":"> We present a four-dimensional understanding of quantum mechanics and Bell violation. We show that the four-dimensional understanding of quantum mechanics is equivalent to the standard three-dimensional understanding of quantum mechanics. We also show that the four-dimensional understanding of Bell violation is equivalent to the standard three-dimensional understanding of Bell violation. We conclude that the four-dimensional understanding of quantum mechanics and Bell violation is equivalent to the standard three-dimensional understanding of quantum mechanics and Bell violation. The paper is written by a team of researchers from the University of California, Berkeley, and the University of California, Santa Cruz. The paper is available for download here.","label":"ai"}
{"id":459,"text":"> In this work, we propose to use test-time training (TTT) as an effective way to improve deformable multi-scale image registration performance. TTT has been shown to be useful in many computer vision tasks such as object detection and semantic segmentation. However, it remains unclear how to apply TTT to medical imaging applications where there are no ground truth labels available at test time. We show that by using TTT with a simple yet powerful loss function, our method can achieve state-of-the-art results on two challenging datasets without any additional data or model parameters. Our approach also provides a new perspective on how to design better losses for deformable image registration.","label":"ai"}
{"id":460,"text":"In this paper, we propose a novel deep learning approach named Pixel Objectness to learn automatic object segmentation in images and videos. Our method applies convolutional neural networks (CNNs) with carefully designed layers tailored specifically for object segmentation tasks and uses an end-to-end supervised algorithm. We present several experiments demonstrating the effectiveness of our model on various benchmark datasets, including a new dataset called VideoCOCO that includes high resolution video frames. Furthermore, Pixel Objectness can effectively tackle objects at different scales and generate higher quality masks than other state-of-the-art methods due to its ability to segment both foreground and background regions accurately.","label":"ai"}
{"id":461,"text":"Minimal paths are regarded as a powerful and efficient tool for boundary\ndetection and image segmentation due to its global optimality and the\nwell-established numerical solutions such as fast marching method. In this\npaper, we introduce a flexible interactive image segmentation model based on\nthe Eikonal partial differential equation (PDE) framework in conjunction with\nregion-based homogeneity enhancement. A key ingredient in the introduced model\nis the construction of local geodesic metrics, which are capable of integrating\nanisotropic and asymmetric edge features, implicit region-based homogeneity\nfeatures and\/or curvature regularization. The incorporation of the region-based\nhomogeneity features into the metrics considered relies on an implicit\nrepresentation of these features, which is one of the contributions of this\nwork. Moreover, we also introduce a way to build simple closed contours as the\nconcatenation of two disjoint open curves. Experimental results prove that the\nproposed model indeed outperforms state-of-the-art minimal paths-based image\nsegmentation approaches.","label":"human"}
{"id":462,"text":"In this work, we present a simple yet effective framework to address the\ndomain translation problem between different sensor modalities with unique data\nformats. By relying only on the semantics of the scene, our modular generative\nframework can, for the first time, synthesize a panoramic color image from a\ngiven full 3D LiDAR point cloud. The framework starts with semantic\nsegmentation of the point cloud, which is initially projected onto a spherical\nsurface. The same semantic segmentation is applied to the corresponding camera\nimage. Next, our new conditional generative model adversarially learns to\ntranslate the predicted LiDAR segment maps to the camera image counterparts. Finally, generated image segments are processed to render the panoramic scene\nimages. We provide a thorough quantitative evaluation on the SemanticKitti\ndataset and show that our proposed framework outperforms other strong baseline\nmodels. Our source code is available at\nhttps:\/\/github.com\/halmstad-University\/TITAN-NET","label":"human"}
{"id":463,"text":"This paper presents FedDG, a novel approach for medical image segmentation that improves generalization performance by leveraging the continuous frequency space. The method is based on episodic learning, which allows the model to adapt to new, unseen data during training while still maintaining good performance on more general tasks. We show that this approach is effective for domain generalization on medical images, where the training data may differ significantly from the target domain. Our results demonstrate that FedDG outperforms state-of-the-art methods on multiple benchmark datasets. Overall, this work adds to the growing body of research on federalized learning and its applications to healthcare.","label":"ai"}
{"id":464,"text":"Advances in object-centric generative models (OCGMs) have culminated in the\ndevelopment of a broad range of methods for unsupervised object segmentation\nand interpretable object-centric scene generation. These methods, however, are\nlimited to simulated and real-world datasets with limited visual complexity. Moreover, object representations are often inferred using RNNs which do not\nscale well to large images or iterative refinement which avoids imposing an\nunnatural ordering on objects in an image but requires the a priori\ninitialisation of a fixed number of object representations. In contrast to\nestablished paradigms, this work proposes an embedding-based approach in which\nembeddings of pixels are clustered in a differentiable fashion using a\nstochastic, non-parametric stick-breaking process. Similar to iterative\nrefinement, this clustering procedure also leads to randomly ordered object\nrepresentations, but without the need of initialising a fixed number of\nclusters a priori. This is used to develop a new model, GENESIS-V2, which can\ninfer a variable number of object representations without using RNNs or\niterative refinement. We show that GENESIS-V2 outperforms previous methods for\nunsupervised image segmentation and object-centric scene generation on\nestablished synthetic datasets as well as more complex real-world datasets.","label":"human"}
{"id":465,"text":"> In this work, we propose to use image segmentation as a tool to detect driver distractions. We present a novel method that uses the Histogram of Depth (HoD) descriptor to perform image segmentation. HoD is computed by using the distance between each pixel and its nearest neighboring pixels. This allows us to obtain a representation of the scene which can be used to distinguish foreground objects from background ones. Our approach does not require any training data or prior knowledge about the environment. It only requires a single RGB-D camera placed inside the vehicle cabin. Experiments are conducted with real world driving videos captured under different lighting conditions and at various distances from the camera. Results show that our proposed method outperforms state-of-the-art methods such as GrabCut [1] and Mean Shift [2].","label":"ai"}
{"id":466,"text":"We study the structure of multiple correlation sequences defined by measure\npreserving actions of commuting transformations. When the iterates of the\ntransformations are integer polynomials we prove that any such correlation\nsequence is the sum of a nilsequence and an error term that is small in uniform\ndensity; this was previously known only for measure preserving actions of a\nsingle transformation. We then use this decomposition result to give\nconvergence criteria for multiple ergodic averages involving iterates that grow\nlinearly, and prove the rather surprising fact that for such sequences,\nconvergence results for actions of commuting transformations follow\nautomatically from the special case of actions of a single transformation. Our\nproof of the decomposition result differs from previous works of V. Bergelson,\nB. Host, B. Kra, and A. Leibman, as it does not rely on the theory of\ncharacteristic factors. It consists of a simple orthogonality argument and the\nmain tool is an inverse theorem of B. Host and B. Kra for general bounded\nsequences.","label":"human"}
{"id":467,"text":"This paper presents a study on the differences between high contrast grating reflectors for transverse magnetic (TM) and transverse electric (TE) polarizations and their impact on vertical cavity surface-emitting lasers (VCSELs). The study aimed to investigate the performance of VCSELs with different grating reflectors for TM and TE polarizations. The results showed that the grating reflector for TM polarization had a higher reflectivity than that for TE polarization, which led to a higher output power and a narrower linewidth for TM polarization. The study also found that the choice of grating reflector for TM polarization had a significant impact on the VCSEL design, as it affected the resonator length and the cavity mode spacing. The findings of this study have important implications for the design and optimization of VCSELs for specific applications.","label":"ai"}
{"id":468,"text":"Psi-Net is a novel deep learning architecture designed specifically for medical image segmentation tasks. It utilizes shape and boundary awareness to improve performance on complex images with varying shapes, sizes, and boundaries. The model consists of multiple subnetworks that are trained simultaneously to perform different segmentation tasks, such as tumor detection and lesion classification. These subnetworks share common features and learn from each other through a joint training process. Additionally, Psi-Net incorporates attention mechanisms to focus on important regions in the input image and adaptively adjust the level of detail based on the task at hand. Overall, Psi-Net demonstrates state-of-the-art performance on several benchmark datasets and offers a flexible framework for customizing the model to specific clinical needs.","label":"ai"}
{"id":469,"text":"This paper presents a multidimensional variant of Szemeredi's theorem, which is a fundamental result in combinatorial number theory. It demonstrates that if $k$ and $\\ell$ are positive integers with $2\\leq k, \\ell < n$, then there is always an integer subset $A$ of $\\{1,\\dots,n\\}$ such that $|A|\\geq (1-o(1))k^2\/(\\log k)^\\ell$. This strengthens the original Szemeredi theorem by showing its applicability to higher dimensional sets. The proof relies on modern analytic techniques such as harmonic analysis and probabilistic methods.","label":"ai"}
{"id":470,"text":"> In meta-analysis, the effect size of a treatment is often estimated by a weighted average of the effect sizes of the studies. The weights are usually chosen to be inversely proportional to the variance of the effect size. However, in some cases, the variance of the effect size is not known and the weights are chosen to be inversely proportional to the standard error of the effect size. In this paper, we propose a new class of selection models with monotone weight functions. We show that the proposed class of selection models is a generalization of the existing selection models with monotone weight functions. We also show that the proposed class of selection models is a generalization of the existing selection models with non-monotone weight functions. We provide a general method for constructing the selection models with monotone weight functions. We also provide a general method for constructing the selection models with non-monotone weight functions. We show that the proposed class of selection models is a generalization of the existing selection models with non-monotone weight functions. We also show that the proposed class of selection models is a generalization of the existing selection models with monotone weight functions. We provide a general method for constructing the selection models with monotone weight functions. We also provide a general method for constructing the selection models with non-monotone weight functions. We show that the proposed class of selection models is a generalization of the existing selection models with non-monotone weight functions. We also show that the proposed class of selection models is a generalization of the existing selection models with monotone weight functions. We provide a general method for constructing the selection models with monotone weight functions. We also provide a general method for constructing the selection models with non-monotone weight functions. We show that the proposed class of selection models is a generalization of the existing selection models with non-monotone weight functions. We also show that the proposed class of selection models is a generalization of the existing selection models with monotone weight functions. We provide a general method for constructing the selection models with monotone weight functions. We also provide a general method for constructing the selection models with non-monotone weight functions. We show that the","label":"ai"}
{"id":471,"text":"Convolutional neural networks have been applied to a wide variety of computer\nvision tasks. Recent advances in semantic segmentation have enabled their\napplication to medical image segmentation. While most CNNs use two-dimensional\nkernels, recent CNN-based publications on medical image segmentation featured\nthree-dimensional kernels, allowing full access to the three-dimensional\nstructure of medical images. Though closely related to semantic segmentation,\nmedical image segmentation includes specific challenges that need to be\naddressed, such as the scarcity of labelled data, the high class imbalance\nfound in the ground truth and the high memory demand of three-dimensional\nimages. In this work, a CNN-based method with three-dimensional filters is\ndemonstrated and applied to hand and brain MRI. Two modifications to an\nexisting CNN architecture are discussed, along with methods on addressing the\naforementioned challenges. While most of the existing literature on medical\nimage segmentation focuses on soft tissue and the major organs, this work is\nvalidated on data both from the central nervous system as well as the bones of\nthe hand.","label":"human"}
{"id":472,"text":"> Parity games are a well-studied model of alternating\ngames. They are used to model many problems in computer\nscience, such as model checking, program verification,\nand synthesis. In this paper, we study parity games with\ncosts, a generalization of parity games where the players\nare not only interested in winning, but also in minimizing\nthe cost of the winning strategy. We show that the problem\nof computing the cost of a winning strategy is NP-hard,\nand we present a polynomial-time algorithm for computing\nthe cost of a winning strategy in parity games with\ncosts. We also show that the problem of computing the\ncost of a winning strategy is NP-hard, and we present a\npolynomial-time algorithm for computing the cost of a\nwinning strategy in parity games with costs.","label":"ai"}
{"id":473,"text":"The Whitney distortion extension problem is a fundamental question in analysis that asks whether it is possible to extend a smooth function from a smaller domain to a larger one while preserving certain properties such as Lipschitz continuity or differentiability. In this paper, we study the Whitney distortion extension problem for $C^m(\\mathbb{R}^n)$ and $C^\\infty(\\mathbb{R}^n)$. We prove that there exists an extension operator with optimal distortion for both spaces, which has important implications for interpolation and alignment of data in $\\mathbb{R}^n$. Specifically, our results show that it is possible to reconstruct high-resolution images from low-resolution ones using techniques based on the Whitney distortion extension problem. Our work extends previous results by providing explicit formulas for the extension operators and analyzing their performance under various conditions.","label":"ai"}
{"id":474,"text":"The ability to accurately segment images is a critical task in many computer vision applications, including medical imaging and object recognition. However, obtaining high-quality labels for image segmentation can be time-consuming and expensive, and sometimes labels may be misaligned or partial. In this paper, we present a novel approach to training deep neural networks for image segmentation using misaligned and partial labels. Our method leverages the structure of the label hierarchy and incorporates a joint loss function that combines the segmentation objective with a consistency constraint to ensure that the predicted segments are in agreement with the supervision at different levels of precision. We evaluate our method on several benchmark datasets and demonstrate that it can improve performance even when labels are of very low quality.","label":"ai"}
{"id":475,"text":"We introduce a new multi-dimensional nonlinear embedding -- Piecewise Flat\nEmbedding (PFE) -- for image segmentation. Based on the theory of sparse signal\nrecovery, piecewise flat embedding with diverse channels attempts to recover a\npiecewise constant image representation with sparse region boundaries and\nsparse cluster value scattering. The resultant piecewise flat embedding\nexhibits interesting properties such as suppressing slowly varying signals, and\noffers an image representation with higher region identifiability which is\ndesirable for image segmentation or high-level semantic analysis tasks. We\nformulate our embedding as a variant of the Laplacian Eigenmap embedding with\nan $L_{1,p} (0<p\\leq1)$ regularization term to promote sparse solutions. First,\nwe devise a two-stage numerical algorithm based on Bregman iterations to\ncompute $L_{1,1}$-regularized piecewise flat embeddings. We further generalize\nthis algorithm through iterative reweighting to solve the general\n$L_{1,p}$-regularized problem. To demonstrate its efficacy, we integrate PFE\ninto two existing image segmentation frameworks, segmentation based on\nclustering and hierarchical segmentation based on contour detection. Experiments on four major benchmark datasets, BSDS500, MSRC, Stanford\nBackground Dataset, and PASCAL Context, show that segmentation algorithms\nincorporating our embedding achieve significantly improved results.","label":"human"}
{"id":476,"text":"Twitter is one of the most prominent Online Social Networks. It covers a\nsignificant part of the online worldwide population~20% and has impressive\ngrowth rates. The social graph of Twitter has been the subject of numerous\nstudies since it can reveal the intrinsic properties of large and complex\nonline communities. Despite the plethora of these studies, there is a limited\ncover on the properties of the social graph while they evolve over time. Moreover, due to the extreme size of this social network (millions of nodes,\nbillions of edges), there is a small subset of possible graph properties that\ncan be efficiently measured in a reasonable timescale. In this paper we propose\na sampling framework that allows the estimation of graph properties on large\nsocial networks. We apply this framework to a subset of Twitter's social\nnetwork that has 13.2 million users, 8.3 billion edges and covers the complete\nTwitter timeline (from April 2006 to January 2015). We derive estimation on the\ntime evolution of 24 graph properties many of which have never been measured on\nlarge social networks. We further discuss how these estimations shed more light\non the inner structure and growth dynamics of Twitter's social network.","label":"human"}
{"id":477,"text":"It is well-known that the formation of amyloid fiber may cause invertible\ndamage to cells, while the underlying mechanism has not been fully uncovered. In this paper, we construct a mathematical model, consisting of infinite ODEs\nin the form of mass-action equations together with two reaction-convection\nPDEs, and then simplify it to a system of 5 ODEs by using the maximum entropy\nprinciple. This model is based on four simple assumptions, one of which is that\ncell damage is raised by oligomers rather than mature fibrils. With the\nsimplified model, the effects of nucleation and elongation, fragmentation,\nprotein and seeds concentrations on amyloid formation and cell damage are\nextensively explored and compared with experiments. We hope that our results\ncan provide a valuable insight into the processes of amyloid formation and cell\ndamage thus raised.","label":"human"}
{"id":478,"text":"Clothing co-parsing is a challenging task in computer vision that involves identifying clothing items within an image, such as pants, shirts, and dresses. In this study, we propose a novel approach to clothing co-parsing using joint image segmentation and labeling techniques. Our method first segments the image into regions of interest (ROIs) based on color and texture features. Then, it uses deep learning algorithms to classify each ROI into one of several predefined categories, such as pants or shirt. Finally, our method combines the results from both image segmentation and labeling tasks to produce a more accurate representation of clothing items within the image. We evaluate our method on several benchmark datasets and demonstrate significant improvements over state-of-the-art methods.","label":"ai"}
{"id":479,"text":"> We study the geometry of subriemannian manifolds from the point of view of algebraic geometry. We show that the subriemannian structure of a manifold can be encoded in a certain algebraic variety, called the subriemannian variety. We show that the subriemannian variety is a projective variety, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its defining equations. We show that the subriemannian variety is a complete intersection, and we give a geometric interpretation of its","label":"ai"}
{"id":480,"text":"The study of large scale asymptotics of velocity-jump processes is a fundamental problem in stochastic mechanics. In this paper, we investigate the behavior of such systems as the size of the system approaches infinity. We focus on the case where the jump process has a finite mean free path, which leads to a non-local Hamiltonian equation that describes the dynamics of the system. Our main result is an explicit expression for the solution to this equation in terms of the initial conditions and the parameters of the system. This expression allows us to analyze the long time behavior of the system and make predictions about its statistical properties. We also discuss some applications of our results to problems in physics and engineering.","label":"ai"}
{"id":481,"text":"Abstract: We give an explicit description of the structure constants of any finite dimensional algebra over a field, in terms of its generators and relations. This allows us to prove that if $k$ is a field of characteristic zero or positive characteristic greater than $\\dim(V)$, then the structure constants of the tensor product $U\\otimes V$, where $U$ and $V$ are two representations of a Lie algebra $L$, are polynomials in the structure constants of $L$. In particular, this implies that the structure constants of the universal enveloping algebra of $L$ are also polynomials in those of $L$.","label":"ai"}
{"id":482,"text":"In this work, we develop new bounds on some topological invariants of supergravity theories by using information-theoretical principles. We show that constraints from conformal field theory and black hole physics can be used to constrain these invariants, leading to significant reductions in their allowed values for generic supergravity solutions. Our approach provides a powerful tool for constraining the behavior of gravitational systems at ultra-short distances, where other methods may become less reliable. Specifically, we use information-theoretic techniques such as entropy and holography to derive upper bounds on various superconformal quantities relevant to quantum gravity and cosmology. These results demonstrate the potential impact of recent developments in both supersymmetry and gravity on our understanding of the universe.","label":"ai"}
{"id":483,"text":"In this academic paper, we propose an adaptive weighting multi-field-of-view convolutional neural network (CNN) model to improve the performance of semantic segmentation in medical pathology images. Our proposed model utilizes multiple input fields-of-view at different scales and weights them adaptively during training based on their contribution to the overall prediction. The use of multiple inputs enhances the model's ability to capture local contextual information while considering the spatial relationships among different regions within the image. We evaluate our model on a large dataset of medical pathology images, demonstrating state-of-the-art results in comparison to other models with similar architectures. Overall, our proposed model has significant potential for improving the accuracy of automated semantic segmentation in pathology, which could lead to improved diagnosis and treatment strategies.","label":"ai"}
{"id":484,"text":"> In this work, we present an uncertainty-based human-in-the-loop system that can be used to analyze tool wear in industrial applications. We use a Bayesian framework and Gaussian Processes (GPs) to model the relationship between tool wear and cutting forces. GPs are well suited for modeling such relationships because they allow us to incorporate prior knowledge about the problem domain into our models. This allows us to make more accurate predictions even when data is limited. Additionally, GPs provide us with measures of uncertainty which can be used to quantify how confident we are in our predictions. These measures of uncertainty can then be used by humans to guide their decision making process. Our approach has been validated on real world data collected from a machining center at the University of Michigan's Advanced Manufacturing Research Facility.","label":"ai"}
{"id":485,"text":"This image segmentation method is based on non-reversible affinity fusion graph framework which can simultaneously segment text, image and artifacts of backgrounds. By using a novel fusion graph, we integrate two kinds of color features in the segmentation process to better enhance the features of objects. The proposed method is different from the previous graph-based segmentation and clustering methods. In the process of initial segmentation, the similar pixels are segmented from the initial region, and then the dissimilar pixels are fused into the local cluster. By using a graph-based segmentation approach with a different graph-based algorithm, we segment images with different texture characteristics and colors in text and images. We show that the proposed approach is effective in distinguishing between textures and colors in images, while the proposed method is also robust to noise.","label":"ai"}
{"id":486,"text":"Spleen volume estimation using automated image segmentation technique may be\nused to detect splenomegaly (abnormally enlarged spleen) on Magnetic Resonance\nImaging (MRI) scans. In recent years, Deep Convolutional Neural Networks (DCNN)\nsegmentation methods have demonstrated advantages for abdominal organ\nsegmentation. However, variations in both size and shape of the spleen on MRI\nimages may result in large false positive and false negative labeling when\ndeploying DCNN based methods. In this paper, we propose the Splenomegaly\nSegmentation Network (SSNet) to address spatial variations when segmenting\nextraordinarily large spleens. SSNet was designed based on the framework of\nimage-to-image conditional generative adversarial networks (cGAN). Specifically, the Global Convolutional Network (GCN) was used as the generator\nto reduce false negatives, while the Markovian discriminator (PatchGAN) was\nused to alleviate false positives. A cohort of clinically acquired 3D MRI scans\n(both T1 weighted and T2 weighted) from patients with splenomegaly were used to\ntrain and test the networks. The experimental results demonstrated that a mean\nDice coefficient of 0.9260 and a median Dice coefficient of 0.9262 using SSNet\non independently tested MRI volumes of patients with splenomegaly.","label":"human"}
{"id":487,"text":"Convolutional Networks (ConvNets) excel at semantic segmentation and have\nbecome a vital component for perception in autonomous driving. Enabling an\nall-encompassing view of street-scenes, omnidirectional cameras present\nthemselves as a perfect fit in such systems. Most segmentation models for\nparsing urban environments operate on common, narrow Field of View (FoV)\nimages. Transferring these models from the domain they were designed for to\n360-degree perception, their performance drops dramatically, e.g., by an\nabsolute 30.0% (mIoU) on established test-beds. To bridge the gap in terms of\nFoV and structural distribution between the imaging domains, we introduce\nEfficient Concurrent Attention Networks (ECANets), directly capturing the\ninherent long-range dependencies in omnidirectional imagery. In addition to the\nlearned attention-based contextual priors that can stretch across 360-degree\nimages, we upgrade model training by leveraging multi-source and\nomni-supervised learning, taking advantage of both: Densely labeled and\nunlabeled data originating from multiple datasets. To foster progress in\npanoramic image segmentation, we put forward and extensively evaluate models on\nWild PAnoramic Semantic Segmentation (WildPASS), a dataset designed to capture\ndiverse scenes from all around the globe. Our novel model, training regimen and\nmulti-source prediction fusion elevate the performance (mIoU) to new\nstate-of-the-art results on the public PASS (60.2%) and the fresh WildPASS","label":"human"}
{"id":488,"text":"> Abstract: We present graphical structures that can be used to design quantum error correction codes, as well as to verify their correctness. These are based on the notion of stabilizer code, which has been widely studied in recent years. Our approach uses a generalization of the concept of tensor product of graphs, called the direct sum of graphs, which allows us to construct new graphs by combining existing ones. This construction provides an intuitive way to understand how different parts of a quantum system interact with each other, and it also enables us to build more complex systems out of simpler components. In addition, we introduce a method for verifying whether or not a given set of generators forms a valid stabilizer group. This verification process involves checking certain properties of the associated graph structure, such as its connectivity and degree distribution. By using these tools, we demonstrate how they can be applied to design and analyze various types of quantum error correction codes, including those based on the surface code and the toric code.","label":"ai"}
{"id":489,"text":"The purpose of this study is to develop a mathematical model that describes how oligomers form and cause damage in cells. A kinetic model was developed using chemical reaction equations to describe the polymerization process and its effects on the cell. The model takes into account various parameters, including the concentration of monomers, time, temperature, and pH, as well as the structure and composition of the polymerizing molecules. The results of the modeling showed that under certain conditions, such as high temperatures or low concentrations, rapid oligomer formation can occur leading to significant cellular damage. Additionally, it was found that specific types of monomers were more likely to participate in cross-linking reactions, resulting in even greater toxicity. The implications of these findings are important for understanding the mechanisms underlying neurological disorders caused by protein misfolding and aggregation. Overall, this research provides a valuable tool for predicting and preventing cell damage due to oligomer formation.","label":"ai"}
{"id":490,"text":"The GraphBLAS standard (GraphBlas.org) is being developed to bring the\npotential of matrix based graph algorithms to the broadest possible audience. Mathematically the Graph- BLAS defines a core set of matrix-based graph\noperations that can be used to implement a wide class of graph algorithms in a\nwide range of programming environments. This paper provides an introduction to\nthe mathematics of the GraphBLAS. Graphs represent connections between vertices\nwith edges. Matrices can represent a wide range of graphs using adjacency\nmatrices or incidence matrices. Adjacency matrices are often easier to analyze\nwhile incidence matrices are often better for representing data. Fortunately,\nthe two are easily connected by matrix mul- tiplication. A key feature of\nmatrix mathematics is that a very small number of matrix operations can be used\nto manipulate a very wide range of graphs. This composability of small number\nof operations is the foundation of the GraphBLAS. A standard such as the\nGraphBLAS can only be effective if it has low performance overhead. Performance\nmeasurements of prototype GraphBLAS implementations indicate that the overhead\nis low.","label":"human"}
{"id":491,"text":"> Nuclei segmentation is a crucial step in digital pathology, which is a key component of cancer diagnosis. However, the segmentation of nuclei is a challenging task due to the high variability of nuclei shapes and sizes. In this paper, we propose a novel approach to improve the performance of nuclei segmentation by generating synthetic images using label-to-image translation. Our approach consists of two main steps: (1) training a label-to-image translation model using a large dataset of labeled images, and (2) generating synthetic images using the trained model and applying them to the segmentation task. We evaluate our approach on the Camelyon16 dataset and show that it significantly improves the performance of the segmentation model. Our approach is a promising solution for improving the performance of nuclei segmentation in digital pathology. The following is the full text of the abstract for a research paper titled \"Generative Synthetic Augmentation using Label-to-Image Translation for Nuclei Image Segmentation\" from arxiv.org:\n> Nuclei segmentation is a crucial step in digital pathology, which is a key component of cancer diagnosis. However, the segmentation of nuclei is a challenging task due to the high variability of nuclei shapes and sizes. In this paper, we propose a novel approach to improve the performance of nuclei segmentation by generating synthetic images using label-to-image translation. Our approach consists of two main steps: (1) training a label-to-image translation model using a large dataset of labeled images, and (2) generating synthetic images using the trained model and applying them to the segmentation task. We evaluate our approach on the Camelyon16 dataset and show that it significantly improves the performance of the segmentation model. Our approach is a promising solution for improving the performance of nuclei segmentation in digital pathology. The following is the full text of the abstract for a research paper titled \"Generative Synthetic Augmentation using Label-to-Image Translation for Nuclei Image Segmentation\" from arxiv.org:\n> Nuclei segmentation","label":"ai"}
{"id":492,"text":"In recent years, action\/object segmentation has emerged as a critical challenge in the field of computer vision, with numerous applications such as video surveillance, robotics, and autonomous driving. To address this challenge, researchers have developed several deep learning-based methods to segment actions\/objects in videos. Among these methods, 3D convolutional neural networks (CNNs) have shown significant promise due to their ability to capture the spatial and temporal relationships among pixels and capture the motion of objects across frames. In this paper, we present an efficient 3D CNN architecture for action\/object segmentation in videos that is based on a novel feature extraction strategy and a cascaded processing pipeline. The proposed architecture combines 3D convolutional layers with pooling and attention mechanisms to extract spatial and temporal features from input videos. The attention mechanism is used to focus on relevant regions in the video frames, while the pooling operation reduces the dimensionality of the feature maps. We also introduce a novel training strategy, which is based on a combination of multi-task learning, adversarial training, and data augmentation. In experiments conducted on various benchmark datasets, we demonstrate the effectiveness of our proposed 3D CNN architecture in terms of segmentation accuracy and efficiency, outperforming state-of-the-art methods.","label":"ai"}
{"id":493,"text":"In this paper, we propose a Customizable Architecture Search (CAS) approach\nto automatically generate a network architecture for semantic image\nsegmentation. The generated network consists of a sequence of stacked\ncomputation cells. A computation cell is represented as a directed acyclic\ngraph, in which each node is a hidden representation (i.e., feature map) and\neach edge is associated with an operation (e.g., convolution and pooling),\nwhich transforms data to a new layer. During the training, the CAS algorithm\nexplores the search space for an optimized computation cell to build a network. The cells of the same type share one architecture but with different weights. In real applications, however, an optimization may need to be conducted under\nsome constraints such as GPU time and model size. To this end, a cost\ncorresponding to the constraint will be assigned to each operation. When an\noperation is selected during the search, its associated cost will be added to\nthe objective. As a result, our CAS is able to search an optimized architecture\nwith customized constraints. The approach has been thoroughly evaluated on\nCityscapes and CamVid datasets, and demonstrates superior performance over\nseveral state-of-the-art techniques. More remarkably, our CAS achieves 72.3%\nmIoU on the Cityscapes dataset with speed of 108 FPS on an Nvidia TitanXp GPU.","label":"human"}
{"id":494,"text":"> We present an approach to detect missing method calls in object-oriented programs, based on the observation that such violations are often caused by changes in the program's control flow. Our technique uses static analysis and machine learning to identify methods whose invocation has been removed or added due to a change in the control flow. It then compares this set with the actual list of changed methods reported by a version control system (VCS). If there is a mismatch between these two sets, it reports a potential violation of the majority rule. In our evaluation we show that our approach can successfully find 90% of all missing method call violations in a large open source project.","label":"ai"}
{"id":495,"text":"Barrett, Hardy, and Kent have shown in 2005 that protocols for quantum key\nagreement exist the security of which can be proven under the assumption that\nquantum or relativity theory is correct. More precisely, this is based on the\nnon-local behavior of certain quantum systems, combined with the non-signaling\npostulate from relativity. An advantage is that the resulting security is\nindependent of what (quantum) systems the legitimate parties' devices operate\non: they do not have to be trusted. Unfortunately, the protocol proposed by\nBarrett et al. cannot tolerate any errors caused by noise in the quantum\nchannel. Furthermore, even in the error-free case it is inefficient: its\ncommunication complexity is Theta(1\/epsilon) when forcing the attacker's\ninformation below epsilon, even if only a single key bit is generated. Potentially, the problem can be solved by privacy amplification of relativistic\n- or non-signaling - secrecy. We show, however, that such privacy amplification\nis impossible with respect to the most important form of non-local behavior,\nand application of arbitrary hash functions.","label":"human"}
{"id":496,"text":"Two-dimensional (2D) topological insulators (TIs), also known as quantum spin\nHall (QSH) insulators, are excellent candidates for coherent spin transport\nrelated applications because the edge states of 2D TIs are robust against\nnonmagnetic impurities since the only available backscattering channel is\nforbidden. Currently, most known 2D TIs are based on a hexagonal (specifically,\nhoneycomb) lattice. Here, we propose that there exists the quantum spin Hall\neffect (QSHE) in a buckled square lattice. Through performing global structure\noptimization, we predict a new three-layer quasi-2D (Q2D) structure which has\nthe lowest energy among all structures with the thickness less than 6.0 {\\AA}\nfor the BiF system. It is identified to be a Q2D TI with a large band gap (0.69\neV). The electronic states of the Q2D BiF system near the Fermi level are\nmainly contributed by the middle Bi square lattice, which are sandwiched by two\ninert BiF2 layers. This is beneficial since the interaction between a substrate\nand the Q2D material may not change the topological properties of the system,\nas we demonstrate in the case of the NaF substrate. Finally, we come up with a\nnew tight-binding model for a two-orbital system with the buckled square\nlattice to explain the low-energy physics of the Q2D BiF material. Our study\nnot only predicts a QSH insulator for realistic room temperature applications,\nbut also provides a new lattice system for engineering topological states such\nas quantum anomalous Hall effect.","label":"human"}
{"id":497,"text":"Radiological imaging offers effective measurement of anatomy, which is useful\nin disease diagnosis and assessment. Previous study has shown that the left\natrial wall remodeling can provide information to predict treatment outcome in\natrial fibrillation. Nevertheless, the segmentation of the left atrial\nstructures from medical images is still very time-consuming. Current advances\nin neural network may help creating automatic segmentation models that reduce\nthe workload for clinicians. In this preliminary study, we propose automated,\ntwo-stage, three-dimensional U-Nets with convolutional neural network, for the\nchallenging task of left atrial segmentation. Unlike previous two-dimensional\nimage segmentation methods, we use 3D U-Nets to obtain the heart cavity\ndirectly in 3D. The dual 3D U-Net structure consists of, a first U-Net to\ncoarsely segment and locate the left atrium, and a second U-Net to accurately\nsegment the left atrium under higher resolution. In addition, we introduce a\nContour loss based on additional distance information to adjust the final\nsegmentation. We randomly split the data into training datasets (80 subjects)\nand validation datasets (20 subjects) to train multiple models, with different\naugmentation setting. Experiments show that the average Dice coefficients for\nand the specificity 0.99. Compared with traditional Dice loss, models trained\nwith Contour loss in general offer smaller Hausdorff distance with similar Dice\ncoefficient, and have less connected components in predictions. Finally, we\nintegrate several trained models in an ensemble prediction to segment testing\ndatasets.","label":"human"}
{"id":498,"text":"Recently, there has been focus on penalized log-likelihood covariance\nestimation for sparse inverse covariance (precision) matrices. The penalty is\nresponsible for inducing sparsity, and a very common choice is the convex $l_1$\nnorm. However, the best estimator performance is not always achieved with this\npenalty. The most natural sparsity promoting \"norm\" is the non-convex $l_0$\npenalty but its lack of convexity has deterred its use in sparse maximum\nlikelihood estimation. In this paper we consider non-convex $l_0$ penalized\nlog-likelihood inverse covariance estimation and present a novel cyclic descent\nalgorithm for its optimization. Convergence to a local minimizer is proved,\nwhich is highly non-trivial, and we demonstrate via simulations the reduced\nbias and superior quality of the $l_0$ penalty as compared to the $l_1$\npenalty.","label":"human"}
{"id":499,"text":"As a natural way for human-computer interaction, fixation provides a\npromising solution for interactive image segmentation. In this paper, we focus\non Personal Fixations-based Object Segmentation (PFOS) to address issues in\nprevious studies, such as the lack of appropriate dataset and the ambiguity in\nfixations-based interaction. In particular, we first construct a new PFOS\ndataset by carefully collecting pixel-level binary annotation data over an\nexisting fixation prediction dataset, such dataset is expected to greatly\nfacilitate the study along the line. Then, considering characteristics of\npersonal fixations, we propose a novel network based on Object Localization and\nBoundary Preservation (OLBP) to segment the gazed objects. Specifically, the\nOLBP network utilizes an Object Localization Module (OLM) to analyze personal\nfixations and locates the gazed objects based on the interpretation. Then, a\nBoundary Preservation Module (BPM) is designed to introduce additional boundary\ninformation to guard the completeness of the gazed objects. Moreover, OLBP is\norganized in the mixed bottom-up and top-down manner with multiple types of\ndeep supervision. Extensive experiments on the constructed PFOS dataset show\nthe superiority of the proposed OLBP network over 17 state-of-the-art methods,\nand demonstrate the effectiveness of the proposed OLM and BPM components. The\nconstructed PFOS dataset and the proposed OLBP network are available at\nhttps:\/\/github.com\/MathLee\/OLBPNet4PFOS.","label":"human"}
